{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79f8984",
   "metadata": {},
   "source": [
    "## Setup encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac991311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/mmsign/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import torch.nn as nn\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.utils import _BatchNorm\n",
    "from torch.nn.modules.utils import _ntuple, _triple\n",
    "import torch.utils.checkpoint as cp\n",
    "from mmcv.cnn import (ConvModule, NonLocal3d, build_activation_layer,\n",
    "                      constant_init, kaiming_init)\n",
    "from mmcv.runner import _load_checkpoint, load_checkpoint\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "from mmcv.utils import get_logger\n",
    "\n",
    "\n",
    "def get_root_logger(log_file=None, log_level=logging.INFO):\n",
    "    \"\"\"Use ``get_logger`` method in mmcv to get the root logger.\n",
    "\n",
    "    The logger will be initialized if it has not been initialized. By default a\n",
    "    StreamHandler will be added. If ``log_file`` is specified, a FileHandler\n",
    "    will also be added. The name of the root logger is the top-level package\n",
    "    name, e.g., \"mmaction\".\n",
    "\n",
    "    Args:\n",
    "        log_file (str | None): The log filename. If specified, a FileHandler\n",
    "            will be added to the root logger.\n",
    "        log_level (int): The root logger level. Note that only the process of\n",
    "            rank 0 is affected, while other processes will set the level to\n",
    "            \"Error\" and be silent most of the time.\n",
    "\n",
    "    Returns:\n",
    "        :obj:`logging.Logger`: The root logger.\n",
    "    \"\"\"\n",
    "    return get_logger(__name__.split('.')[0], log_file, log_level)\n",
    "\n",
    "\n",
    "class BasicBlock3d(nn.Module):\n",
    "    \"\"\"BasicBlock 3d block for ResNet3D.\n",
    "\n",
    "    Args:\n",
    "        inplanes (int): Number of channels for the input in first conv3d layer.\n",
    "        planes (int): Number of channels produced by some norm/conv3d layers.\n",
    "        spatial_stride (int): Spatial stride in the conv3d layer. Default: 1.\n",
    "        temporal_stride (int): Temporal stride in the conv3d layer. Default: 1.\n",
    "        dilation (int): Spacing between kernel elements. Default: 1.\n",
    "        downsample (nn.Module | None): Downsample layer. Default: None.\n",
    "        style (str): ``pytorch`` or ``caffe``. If set to \"pytorch\", the\n",
    "            stride-two layer is the 3x3 conv layer, otherwise the stride-two\n",
    "            layer is the first 1x1 conv layer. Default: 'pytorch'.\n",
    "        inflate (bool): Whether to inflate kernel. Default: True.\n",
    "        non_local (bool): Determine whether to apply non-local module in this\n",
    "            block. Default: False.\n",
    "        non_local_cfg (dict): Config for non-local module. Default: ``dict()``.\n",
    "        conv_cfg (dict): Config dict for convolution layer.\n",
    "            Default: ``dict(type='Conv3d')``.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are ``type``,\n",
    "            Default: ``dict(type='BN3d')``.\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: ``dict(type='ReLU')``.\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "            memory while slowing down the training speed. Default: False.\n",
    "    \"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 inplanes,\n",
    "                 planes,\n",
    "                 spatial_stride=1,\n",
    "                 temporal_stride=1,\n",
    "                 dilation=1,\n",
    "                 downsample=None,\n",
    "                 style='pytorch',\n",
    "                 inflate=True,\n",
    "                 non_local=False,\n",
    "                 non_local_cfg=dict(),\n",
    "                 conv_cfg=dict(type='Conv3d'),\n",
    "                 norm_cfg=dict(type='BN3d'),\n",
    "                 act_cfg=dict(type='ReLU'),\n",
    "                 with_cp=False,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        assert style in ['pytorch', 'caffe']\n",
    "        # make sure that only ``inflate_style`` is passed into kwargs\n",
    "        assert set(kwargs).issubset(['inflate_style'])\n",
    "\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.spatial_stride = spatial_stride\n",
    "        self.temporal_stride = temporal_stride\n",
    "        self.dilation = dilation\n",
    "        self.style = style\n",
    "        self.inflate = inflate\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.with_cp = with_cp\n",
    "        self.non_local = non_local\n",
    "        self.non_local_cfg = non_local_cfg\n",
    "\n",
    "        self.conv1_stride_s = spatial_stride\n",
    "        self.conv2_stride_s = 1\n",
    "        self.conv1_stride_t = temporal_stride\n",
    "        self.conv2_stride_t = 1\n",
    "\n",
    "        if self.inflate:\n",
    "            conv1_kernel_size = (3, 3, 3)\n",
    "            conv1_padding = (1, dilation, dilation)\n",
    "            conv2_kernel_size = (3, 3, 3)\n",
    "            conv2_padding = (1, 1, 1)\n",
    "        else:\n",
    "            conv1_kernel_size = (1, 3, 3)\n",
    "            conv1_padding = (0, dilation, dilation)\n",
    "            conv2_kernel_size = (1, 3, 3)\n",
    "            conv2_padding = (0, 1, 1)\n",
    "\n",
    "        self.conv1 = ConvModule(\n",
    "            inplanes,\n",
    "            planes,\n",
    "            conv1_kernel_size,\n",
    "            stride=(self.conv1_stride_t, self.conv1_stride_s,\n",
    "                    self.conv1_stride_s),\n",
    "            padding=conv1_padding,\n",
    "            dilation=(1, dilation, dilation),\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg)\n",
    "\n",
    "        self.conv2 = ConvModule(\n",
    "            planes,\n",
    "            planes * self.expansion,\n",
    "            conv2_kernel_size,\n",
    "            stride=(self.conv2_stride_t, self.conv2_stride_s,\n",
    "                    self.conv2_stride_s),\n",
    "            padding=conv2_padding,\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=None)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.relu = build_activation_layer(self.act_cfg)\n",
    "\n",
    "        if self.non_local:\n",
    "            self.non_local_block = NonLocal3d(self.conv2.norm.num_features,\n",
    "                                              **self.non_local_cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
    "\n",
    "        def _inner_forward(x):\n",
    "            \"\"\"Forward wrapper for utilizing checkpoint.\"\"\"\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.conv2(out)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            out = out + identity\n",
    "            return out\n",
    "\n",
    "        if self.with_cp and x.requires_grad:\n",
    "            out = cp.checkpoint(_inner_forward, x)\n",
    "        else:\n",
    "            out = _inner_forward(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.non_local:\n",
    "            out = self.non_local_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck3d(nn.Module):\n",
    "    \"\"\"Bottleneck 3d block for ResNet3D.\n",
    "\n",
    "    Args:\n",
    "        inplanes (int): Number of channels for the input in first conv3d layer.\n",
    "        planes (int): Number of channels produced by some norm/conv3d layers.\n",
    "        spatial_stride (int): Spatial stride in the conv3d layer. Default: 1.\n",
    "        temporal_stride (int): Temporal stride in the conv3d layer. Default: 1.\n",
    "        dilation (int): Spacing between kernel elements. Default: 1.\n",
    "        downsample (nn.Module | None): Downsample layer. Default: None.\n",
    "        style (str): ``pytorch`` or ``caffe``. If set to \"pytorch\", the\n",
    "            stride-two layer is the 3x3 conv layer, otherwise the stride-two\n",
    "            layer is the first 1x1 conv layer. Default: 'pytorch'.\n",
    "        inflate (bool): Whether to inflate kernel. Default: True.\n",
    "        inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines the\n",
    "            kernel sizes and padding strides for conv1 and conv2 in each block.\n",
    "            Default: '3x1x1'.\n",
    "        non_local (bool): Determine whether to apply non-local module in this\n",
    "            block. Default: False.\n",
    "        non_local_cfg (dict): Config for non-local module. Default: ``dict()``.\n",
    "        conv_cfg (dict): Config dict for convolution layer.\n",
    "            Default: ``dict(type='Conv3d')``.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are ``type``,\n",
    "            Default: ``dict(type='BN3d')``.\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: ``dict(type='ReLU')``.\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "            memory while slowing down the training speed. Default: False.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 inplanes,\n",
    "                 planes,\n",
    "                 spatial_stride=1,\n",
    "                 temporal_stride=1,\n",
    "                 dilation=1,\n",
    "                 downsample=None,\n",
    "                 style='pytorch',\n",
    "                 inflate=True,\n",
    "                 inflate_style='3x1x1',\n",
    "                 non_local=False,\n",
    "                 non_local_cfg=dict(),\n",
    "                 conv_cfg=dict(type='Conv3d'),\n",
    "                 norm_cfg=dict(type='BN3d'),\n",
    "                 act_cfg=dict(type='ReLU'),\n",
    "                 with_cp=False):\n",
    "        super().__init__()\n",
    "        assert style in ['pytorch', 'caffe']\n",
    "        assert inflate_style in ['3x1x1', '3x3x3']\n",
    "\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.spatial_stride = spatial_stride\n",
    "        self.temporal_stride = temporal_stride\n",
    "        self.dilation = dilation\n",
    "        self.style = style\n",
    "        self.inflate = inflate\n",
    "        self.inflate_style = inflate_style\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.with_cp = with_cp\n",
    "        self.non_local = non_local\n",
    "        self.non_local_cfg = non_local_cfg\n",
    "\n",
    "        if self.style == 'pytorch':\n",
    "            self.conv1_stride_s = 1\n",
    "            self.conv2_stride_s = spatial_stride\n",
    "            self.conv1_stride_t = 1\n",
    "            self.conv2_stride_t = temporal_stride\n",
    "        else:\n",
    "            self.conv1_stride_s = spatial_stride\n",
    "            self.conv2_stride_s = 1\n",
    "            self.conv1_stride_t = temporal_stride\n",
    "            self.conv2_stride_t = 1\n",
    "\n",
    "        if self.inflate:\n",
    "            if inflate_style == '3x1x1':\n",
    "                conv1_kernel_size = (3, 1, 1)\n",
    "                conv1_padding = (1, 0, 0)\n",
    "                conv2_kernel_size = (1, 3, 3)\n",
    "                conv2_padding = (0, dilation, dilation)\n",
    "            else:\n",
    "                conv1_kernel_size = (1, 1, 1)\n",
    "                conv1_padding = (0, 0, 0)\n",
    "                conv2_kernel_size = (3, 3, 3)\n",
    "                conv2_padding = (1, dilation, dilation)\n",
    "        else:\n",
    "            conv1_kernel_size = (1, 1, 1)\n",
    "            conv1_padding = (0, 0, 0)\n",
    "            conv2_kernel_size = (1, 3, 3)\n",
    "            conv2_padding = (0, dilation, dilation)\n",
    "\n",
    "        self.conv1 = ConvModule(\n",
    "            inplanes,\n",
    "            planes,\n",
    "            conv1_kernel_size,\n",
    "            stride=(self.conv1_stride_t, self.conv1_stride_s,\n",
    "                    self.conv1_stride_s),\n",
    "            padding=conv1_padding,\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg)\n",
    "\n",
    "        self.conv2 = ConvModule(\n",
    "            planes,\n",
    "            planes,\n",
    "            conv2_kernel_size,\n",
    "            stride=(self.conv2_stride_t, self.conv2_stride_s,\n",
    "                    self.conv2_stride_s),\n",
    "            padding=conv2_padding,\n",
    "            dilation=(1, dilation, dilation),\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg)\n",
    "\n",
    "        self.conv3 = ConvModule(\n",
    "            planes,\n",
    "            planes * self.expansion,\n",
    "            1,\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            # No activation in the third ConvModule for bottleneck\n",
    "            act_cfg=None)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.relu = build_activation_layer(self.act_cfg)\n",
    "\n",
    "        if self.non_local:\n",
    "            self.non_local_block = NonLocal3d(self.conv3.norm.num_features,\n",
    "                                              **self.non_local_cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\"\"\"\n",
    "\n",
    "        def _inner_forward(x):\n",
    "            \"\"\"Forward wrapper for utilizing checkpoint.\"\"\"\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.conv2(out)\n",
    "            out = self.conv3(out)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            out = out + identity\n",
    "            return out\n",
    "\n",
    "        if self.with_cp and x.requires_grad:\n",
    "            out = cp.checkpoint(_inner_forward, x)\n",
    "        else:\n",
    "            out = _inner_forward(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.non_local:\n",
    "            out = self.non_local_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet3d(nn.Module):\n",
    "    \"\"\"ResNet 3d backbone.\n",
    "\n",
    "    Args:\n",
    "        depth (int): Depth of resnet, from {18, 34, 50, 101, 152}.\n",
    "        pretrained (str | None): Name of pretrained model.\n",
    "        stage_blocks (tuple | None): Set number of stages for each res layer.\n",
    "            Default: None.\n",
    "        pretrained2d (bool): Whether to load pretrained 2D model.\n",
    "            Default: True.\n",
    "        in_channels (int): Channel num of input features. Default: 3.\n",
    "        base_channels (int): Channel num of stem output features. Default: 64.\n",
    "        out_indices (Sequence[int]): Indices of output feature. Default: (3, ).\n",
    "        num_stages (int): Resnet stages. Default: 4.\n",
    "        spatial_strides (Sequence[int]):\n",
    "            Spatial strides of residual blocks of each stage.\n",
    "            Default: ``(1, 2, 2, 2)``.\n",
    "        temporal_strides (Sequence[int]):\n",
    "            Temporal strides of residual blocks of each stage.\n",
    "            Default: ``(1, 1, 1, 1)``.\n",
    "        dilations (Sequence[int]): Dilation of each stage.\n",
    "            Default: ``(1, 1, 1, 1)``.\n",
    "        conv1_kernel (Sequence[int]): Kernel size of the first conv layer.\n",
    "            Default: ``(3, 7, 7)``.\n",
    "        conv1_stride_s (int): Spatial stride of the first conv layer.\n",
    "            Default: 2.\n",
    "        conv1_stride_t (int): Temporal stride of the first conv layer.\n",
    "            Default: 1.\n",
    "        pool1_stride_s (int): Spatial stride of the first pooling layer.\n",
    "            Default: 2.\n",
    "        pool1_stride_t (int): Temporal stride of the first pooling layer.\n",
    "            Default: 1.\n",
    "        with_pool2 (bool): Whether to use pool2. Default: True.\n",
    "        style (str): `pytorch` or `caffe`. If set to \"pytorch\", the stride-two\n",
    "            layer is the 3x3 conv layer, otherwise the stride-two layer is\n",
    "            the first 1x1 conv layer. Default: 'pytorch'.\n",
    "        frozen_stages (int): Stages to be frozen (all param fixed). -1 means\n",
    "            not freezing any parameters. Default: -1.\n",
    "        inflate (Sequence[int]): Inflate Dims of each block.\n",
    "            Default: (1, 1, 1, 1).\n",
    "        inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines the\n",
    "            kernel sizes and padding strides for conv1 and conv2 in each block.\n",
    "            Default: '3x1x1'.\n",
    "        conv_cfg (dict): Config for conv layers. required keys are ``type``\n",
    "            Default: ``dict(type='Conv3d')``.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are ``type`` and\n",
    "            ``requires_grad``.\n",
    "            Default: ``dict(type='BN3d', requires_grad=True)``.\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: ``dict(type='ReLU', inplace=True)``.\n",
    "        norm_eval (bool): Whether to set BN layers to eval mode, namely, freeze\n",
    "            running stats (mean and var). Default: False.\n",
    "        with_cp (bool): Use checkpoint or not. Using checkpoint will save some\n",
    "            memory while slowing down the training speed. Default: False.\n",
    "        non_local (Sequence[int]): Determine whether to apply non-local module\n",
    "            in the corresponding block of each stages. Default: (0, 0, 0, 0).\n",
    "        non_local_cfg (dict): Config for non-local module. Default: ``dict()``.\n",
    "        zero_init_residual (bool):\n",
    "            Whether to use zero initialization for residual block,\n",
    "            Default: True.\n",
    "        kwargs (dict, optional): Key arguments for \"make_res_layer\".\n",
    "    \"\"\"\n",
    "\n",
    "    arch_settings = {\n",
    "        18: (BasicBlock3d, (2, 2, 2, 2)),\n",
    "        34: (BasicBlock3d, (3, 4, 6, 3)),\n",
    "        50: (Bottleneck3d, (3, 4, 6, 3)),\n",
    "        101: (Bottleneck3d, (3, 4, 23, 3)),\n",
    "        152: (Bottleneck3d, (3, 8, 36, 3))\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 depth,\n",
    "                 pretrained,\n",
    "                 stage_blocks=None,\n",
    "                 pretrained2d=True,\n",
    "                 in_channels=3,\n",
    "                 num_stages=4,\n",
    "                 base_channels=64,\n",
    "                 out_indices=(3, ),\n",
    "                 spatial_strides=(1, 2, 2, 2),\n",
    "                 temporal_strides=(1, 1, 1, 1),\n",
    "                 dilations=(1, 1, 1, 1),\n",
    "                 conv1_kernel=(3, 7, 7),\n",
    "                 conv1_stride_s=2,\n",
    "                 conv1_stride_t=1,\n",
    "                 pool1_stride_s=2,\n",
    "                 pool1_stride_t=1,\n",
    "                 with_pool1=True,\n",
    "                 with_pool2=True,\n",
    "                 style='pytorch',\n",
    "                 frozen_stages=-1,\n",
    "                 inflate=(1, 1, 1, 1),\n",
    "                 inflate_style='3x1x1',\n",
    "                 conv_cfg=dict(type='Conv3d'),\n",
    "                 norm_cfg=dict(type='BN3d', requires_grad=True),\n",
    "                 act_cfg=dict(type='ReLU', inplace=True),\n",
    "                 norm_eval=False,\n",
    "                 with_cp=False,\n",
    "                 non_local=(0, 0, 0, 0),\n",
    "                 non_local_cfg=dict(),\n",
    "                 zero_init_residual=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if depth not in self.arch_settings:\n",
    "            raise KeyError(f'invalid depth {depth} for resnet')\n",
    "        self.depth = depth\n",
    "        self.pretrained = pretrained\n",
    "        self.pretrained2d = pretrained2d\n",
    "        self.in_channels = in_channels\n",
    "        self.base_channels = base_channels\n",
    "        self.num_stages = num_stages\n",
    "        assert 1 <= num_stages <= 4\n",
    "        self.stage_blocks = stage_blocks\n",
    "        self.out_indices = out_indices\n",
    "        assert max(out_indices) < num_stages\n",
    "        self.spatial_strides = spatial_strides\n",
    "        self.temporal_strides = temporal_strides\n",
    "        self.dilations = dilations\n",
    "        assert len(spatial_strides) == len(temporal_strides) == len(\n",
    "            dilations) == num_stages\n",
    "        if self.stage_blocks is not None:\n",
    "            assert len(self.stage_blocks) == num_stages\n",
    "\n",
    "        self.conv1_kernel = conv1_kernel\n",
    "        self.conv1_stride_s = conv1_stride_s\n",
    "        self.conv1_stride_t = conv1_stride_t\n",
    "        self.pool1_stride_s = pool1_stride_s\n",
    "        self.pool1_stride_t = pool1_stride_t\n",
    "        self.with_pool1 = with_pool1\n",
    "        self.with_pool2 = with_pool2\n",
    "        self.style = style\n",
    "        self.frozen_stages = frozen_stages\n",
    "        self.stage_inflations = _ntuple(num_stages)(inflate)\n",
    "        self.non_local_stages = _ntuple(num_stages)(non_local)\n",
    "        self.inflate_style = inflate_style\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.norm_eval = norm_eval\n",
    "        self.with_cp = with_cp\n",
    "        self.zero_init_residual = zero_init_residual\n",
    "\n",
    "        self.block, stage_blocks = self.arch_settings[depth]\n",
    "\n",
    "        if self.stage_blocks is None:\n",
    "            self.stage_blocks = stage_blocks[:num_stages]\n",
    "\n",
    "        self.inplanes = self.base_channels\n",
    "\n",
    "        self.non_local_cfg = non_local_cfg\n",
    "\n",
    "        self._make_stem_layer()\n",
    "\n",
    "        self.res_layers = []\n",
    "        for i, num_blocks in enumerate(self.stage_blocks):\n",
    "            spatial_stride = spatial_strides[i]\n",
    "            temporal_stride = temporal_strides[i]\n",
    "            dilation = dilations[i]\n",
    "            planes = self.base_channels * 2**i\n",
    "            res_layer = self.make_res_layer(\n",
    "                self.block,\n",
    "                self.inplanes,\n",
    "                planes,\n",
    "                num_blocks,\n",
    "                spatial_stride=spatial_stride,\n",
    "                temporal_stride=temporal_stride,\n",
    "                dilation=dilation,\n",
    "                style=self.style,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                conv_cfg=self.conv_cfg,\n",
    "                act_cfg=self.act_cfg,\n",
    "                non_local=self.non_local_stages[i],\n",
    "                non_local_cfg=self.non_local_cfg,\n",
    "                inflate=self.stage_inflations[i],\n",
    "                inflate_style=self.inflate_style,\n",
    "                with_cp=with_cp,\n",
    "                **kwargs)\n",
    "            self.inplanes = planes * self.block.expansion\n",
    "            layer_name = f'layer{i + 1}'\n",
    "            self.add_module(layer_name, res_layer)\n",
    "            self.res_layers.append(layer_name)\n",
    "\n",
    "        self.feat_dim = self.block.expansion * self.base_channels * 2**(\n",
    "            len(self.stage_blocks) - 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_res_layer(block,\n",
    "                       inplanes,\n",
    "                       planes,\n",
    "                       blocks,\n",
    "                       spatial_stride=1,\n",
    "                       temporal_stride=1,\n",
    "                       dilation=1,\n",
    "                       style='pytorch',\n",
    "                       inflate=1,\n",
    "                       inflate_style='3x1x1',\n",
    "                       non_local=0,\n",
    "                       non_local_cfg=dict(),\n",
    "                       norm_cfg=None,\n",
    "                       act_cfg=None,\n",
    "                       conv_cfg=None,\n",
    "                       with_cp=False,\n",
    "                       **kwargs):\n",
    "        \"\"\"Build residual layer for ResNet3D.\n",
    "\n",
    "        Args:\n",
    "            block (nn.Module): Residual module to be built.\n",
    "            inplanes (int): Number of channels for the input feature\n",
    "                in each block.\n",
    "            planes (int): Number of channels for the output feature\n",
    "                in each block.\n",
    "            blocks (int): Number of residual blocks.\n",
    "            spatial_stride (int | Sequence[int]): Spatial strides in\n",
    "                residual and conv layers. Default: 1.\n",
    "            temporal_stride (int | Sequence[int]): Temporal strides in\n",
    "                residual and conv layers. Default: 1.\n",
    "            dilation (int): Spacing between kernel elements. Default: 1.\n",
    "            style (str): ``pytorch`` or ``caffe``. If set to ``pytorch``,\n",
    "                the stride-two layer is the 3x3 conv layer, otherwise\n",
    "                the stride-two layer is the first 1x1 conv layer.\n",
    "                Default: ``pytorch``.\n",
    "            inflate (int | Sequence[int]): Determine whether to inflate\n",
    "                for each block. Default: 1.\n",
    "            inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines\n",
    "                the kernel sizes and padding strides for conv1 and conv2\n",
    "                in each block. Default: '3x1x1'.\n",
    "            non_local (int | Sequence[int]): Determine whether to apply\n",
    "                non-local module in the corresponding block of each stages.\n",
    "                Default: 0.\n",
    "            non_local_cfg (dict): Config for non-local module.\n",
    "                Default: ``dict()``.\n",
    "            conv_cfg (dict | None): Config for norm layers. Default: None.\n",
    "            norm_cfg (dict | None): Config for norm layers. Default: None.\n",
    "            act_cfg (dict | None): Config for activate layers. Default: None.\n",
    "            with_cp (bool | None): Use checkpoint or not. Using checkpoint\n",
    "                will save some memory while slowing down the training speed.\n",
    "                Default: False.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module: A residual layer for the given config.\n",
    "        \"\"\"\n",
    "        inflate = inflate if not isinstance(inflate,\n",
    "                                            int) else (inflate, ) * blocks\n",
    "        non_local = non_local if not isinstance(\n",
    "            non_local, int) else (non_local, ) * blocks\n",
    "        assert len(inflate) == blocks and len(non_local) == blocks\n",
    "        downsample = None\n",
    "        if spatial_stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = ConvModule(\n",
    "                inplanes,\n",
    "                planes * block.expansion,\n",
    "                kernel_size=1,\n",
    "                stride=(temporal_stride, spatial_stride, spatial_stride),\n",
    "                bias=False,\n",
    "                conv_cfg=conv_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                act_cfg=None)\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                inplanes,\n",
    "                planes,\n",
    "                spatial_stride=spatial_stride,\n",
    "                temporal_stride=temporal_stride,\n",
    "                dilation=dilation,\n",
    "                downsample=downsample,\n",
    "                style=style,\n",
    "                inflate=(inflate[0] == 1),\n",
    "                inflate_style=inflate_style,\n",
    "                non_local=(non_local[0] == 1),\n",
    "                non_local_cfg=non_local_cfg,\n",
    "                norm_cfg=norm_cfg,\n",
    "                conv_cfg=conv_cfg,\n",
    "                act_cfg=act_cfg,\n",
    "                with_cp=with_cp,\n",
    "                **kwargs))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    inplanes,\n",
    "                    planes,\n",
    "                    spatial_stride=1,\n",
    "                    temporal_stride=1,\n",
    "                    dilation=dilation,\n",
    "                    style=style,\n",
    "                    inflate=(inflate[i] == 1),\n",
    "                    inflate_style=inflate_style,\n",
    "                    non_local=(non_local[i] == 1),\n",
    "                    non_local_cfg=non_local_cfg,\n",
    "                    norm_cfg=norm_cfg,\n",
    "                    conv_cfg=conv_cfg,\n",
    "                    act_cfg=act_cfg,\n",
    "                    with_cp=with_cp,\n",
    "                    **kwargs))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inflate_conv_params(conv3d, state_dict_2d, module_name_2d,\n",
    "                             inflated_param_names):\n",
    "        \"\"\"Inflate a conv module from 2d to 3d.\n",
    "\n",
    "        Args:\n",
    "            conv3d (nn.Module): The destination conv3d module.\n",
    "            state_dict_2d (OrderedDict): The state dict of pretrained 2d model.\n",
    "            module_name_2d (str): The name of corresponding conv module in the\n",
    "                2d model.\n",
    "            inflated_param_names (list[str]): List of parameters that have been\n",
    "                inflated.\n",
    "        \"\"\"\n",
    "        weight_2d_name = module_name_2d + '.weight'\n",
    "\n",
    "        conv2d_weight = state_dict_2d[weight_2d_name]\n",
    "        kernel_t = conv3d.weight.data.shape[2]\n",
    "\n",
    "        new_weight = conv2d_weight.data.unsqueeze(2).expand_as(\n",
    "            conv3d.weight) / kernel_t\n",
    "        conv3d.weight.data.copy_(new_weight)\n",
    "        inflated_param_names.append(weight_2d_name)\n",
    "\n",
    "        if getattr(conv3d, 'bias') is not None:\n",
    "            bias_2d_name = module_name_2d + '.bias'\n",
    "            conv3d.bias.data.copy_(state_dict_2d[bias_2d_name])\n",
    "            inflated_param_names.append(bias_2d_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inflate_bn_params(bn3d, state_dict_2d, module_name_2d,\n",
    "                           inflated_param_names):\n",
    "        \"\"\"Inflate a norm module from 2d to 3d.\n",
    "\n",
    "        Args:\n",
    "            bn3d (nn.Module): The destination bn3d module.\n",
    "            state_dict_2d (OrderedDict): The state dict of pretrained 2d model.\n",
    "            module_name_2d (str): The name of corresponding bn module in the\n",
    "                2d model.\n",
    "            inflated_param_names (list[str]): List of parameters that have been\n",
    "                inflated.\n",
    "        \"\"\"\n",
    "        for param_name, param in bn3d.named_parameters():\n",
    "            param_2d_name = f'{module_name_2d}.{param_name}'\n",
    "            param_2d = state_dict_2d[param_2d_name]\n",
    "            if param.data.shape != param_2d.shape:\n",
    "                warnings.warn(f'The parameter of {module_name_2d} is not'\n",
    "                              'loaded due to incompatible shapes. ')\n",
    "                return\n",
    "\n",
    "            param.data.copy_(param_2d)\n",
    "            inflated_param_names.append(param_2d_name)\n",
    "\n",
    "        for param_name, param in bn3d.named_buffers():\n",
    "            param_2d_name = f'{module_name_2d}.{param_name}'\n",
    "            # some buffers like num_batches_tracked may not exist in old\n",
    "            # checkpoints\n",
    "            if param_2d_name in state_dict_2d:\n",
    "                param_2d = state_dict_2d[param_2d_name]\n",
    "                param.data.copy_(param_2d)\n",
    "                inflated_param_names.append(param_2d_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inflate_weights(self, logger):\n",
    "        \"\"\"Inflate the resnet2d parameters to resnet3d.\n",
    "\n",
    "        The differences between resnet3d and resnet2d mainly lie in an extra\n",
    "        axis of conv kernel. To utilize the pretrained parameters in 2d model,\n",
    "        the weight of conv2d models should be inflated to fit in the shapes of\n",
    "        the 3d counterpart.\n",
    "\n",
    "        Args:\n",
    "            logger (logging.Logger): The logger used to print\n",
    "                debugging information.\n",
    "        \"\"\"\n",
    "\n",
    "        state_dict_r2d = _load_checkpoint(self.pretrained)\n",
    "        if 'state_dict' in state_dict_r2d:\n",
    "            state_dict_r2d = state_dict_r2d['state_dict']\n",
    "\n",
    "        inflated_param_names = []\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, ConvModule):\n",
    "                # we use a ConvModule to wrap conv+bn+relu layers, thus the\n",
    "                # name mapping is needed\n",
    "                if 'downsample' in name:\n",
    "                    # layer{X}.{Y}.downsample.conv->layer{X}.{Y}.downsample.0\n",
    "                    original_conv_name = name + '.0'\n",
    "                    # layer{X}.{Y}.downsample.bn->layer{X}.{Y}.downsample.1\n",
    "                    original_bn_name = name + '.1'\n",
    "                else:\n",
    "                    # layer{X}.{Y}.conv{n}.conv->layer{X}.{Y}.conv{n}\n",
    "                    original_conv_name = name\n",
    "                    # layer{X}.{Y}.conv{n}.bn->layer{X}.{Y}.bn{n}\n",
    "                    original_bn_name = name.replace('conv', 'bn')\n",
    "                if original_conv_name + '.weight' not in state_dict_r2d:\n",
    "                    logger.warning(f'Module not exist in the state_dict_r2d'\n",
    "                                   f': {original_conv_name}')\n",
    "                else:\n",
    "                    shape_2d = state_dict_r2d[original_conv_name +\n",
    "                                              '.weight'].shape\n",
    "                    shape_3d = module.conv.weight.data.shape\n",
    "                    if shape_2d != shape_3d[:2] + shape_3d[3:]:\n",
    "                        logger.warning(f'Weight shape mismatch for '\n",
    "                                       f': {original_conv_name} : '\n",
    "                                       f'3d weight shape: {shape_3d}; '\n",
    "                                       f'2d weight shape: {shape_2d}. ')\n",
    "                    else:\n",
    "                        self._inflate_conv_params(module.conv, state_dict_r2d,\n",
    "                                                  original_conv_name,\n",
    "                                                  inflated_param_names)\n",
    "\n",
    "                if original_bn_name + '.weight' not in state_dict_r2d:\n",
    "                    logger.warning(f'Module not exist in the state_dict_r2d'\n",
    "                                   f': {original_bn_name}')\n",
    "                else:\n",
    "                    self._inflate_bn_params(module.bn, state_dict_r2d,\n",
    "                                            original_bn_name,\n",
    "                                            inflated_param_names)\n",
    "\n",
    "        # check if any parameters in the 2d checkpoint are not loaded\n",
    "        remaining_names = set(\n",
    "            state_dict_r2d.keys()) - set(inflated_param_names)\n",
    "        if remaining_names:\n",
    "            logger.info(f'These parameters in the 2d checkpoint are not loaded'\n",
    "                        f': {remaining_names}')\n",
    "\n",
    "    def inflate_weights(self, logger):\n",
    "        self._inflate_weights(self, logger)\n",
    "\n",
    "    def _make_stem_layer(self):\n",
    "        \"\"\"Construct the stem layers consists of a conv+norm+act module and a\n",
    "        pooling layer.\"\"\"\n",
    "        self.conv1 = ConvModule(\n",
    "            self.in_channels,\n",
    "            self.base_channels,\n",
    "            kernel_size=self.conv1_kernel,\n",
    "            stride=(self.conv1_stride_t, self.conv1_stride_s,\n",
    "                    self.conv1_stride_s),\n",
    "            padding=tuple([(k - 1) // 2 for k in _triple(self.conv1_kernel)]),\n",
    "            bias=False,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg)\n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(\n",
    "            kernel_size=(1, 3, 3),\n",
    "            stride=(self.pool1_stride_t, self.pool1_stride_s,\n",
    "                    self.pool1_stride_s),\n",
    "            padding=(0, 1, 1))\n",
    "\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
    "\n",
    "    def _freeze_stages(self):\n",
    "        \"\"\"Prevent all the parameters from being optimized before\n",
    "        ``self.frozen_stages``.\"\"\"\n",
    "        if self.frozen_stages >= 0:\n",
    "            self.conv1.eval()\n",
    "            for param in self.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        for i in range(1, self.frozen_stages + 1):\n",
    "            m = getattr(self, f'layer{i}')\n",
    "            m.eval()\n",
    "            for param in m.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weights(self, pretrained=None):\n",
    "        \"\"\"Initiate the parameters either from existing checkpoint or from\n",
    "        scratch.\n",
    "\n",
    "        Args:\n",
    "            pretrained (str | None): The path of the pretrained weight. Will\n",
    "                override the original `pretrained` if set. The arg is added to\n",
    "                be compatible with mmdet. Default: None.\n",
    "        \"\"\"\n",
    "        if pretrained:\n",
    "            self.pretrained = pretrained\n",
    "        if isinstance(self.pretrained, str):\n",
    "            logger = get_root_logger()\n",
    "            logger.info(f'load model from: {self.pretrained}')\n",
    "\n",
    "            if self.pretrained2d:\n",
    "                # Inflate 2D model into 3D model.\n",
    "                self.inflate_weights(logger)\n",
    "\n",
    "            else:\n",
    "                # Directly load 3D model.\n",
    "                load_checkpoint(\n",
    "                    self, self.pretrained, strict=False, logger=logger)\n",
    "\n",
    "        elif self.pretrained is None:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv3d):\n",
    "                    kaiming_init(m)\n",
    "                elif isinstance(m, _BatchNorm):\n",
    "                    constant_init(m, 1)\n",
    "\n",
    "            if self.zero_init_residual:\n",
    "                for m in self.modules():\n",
    "                    if isinstance(m, Bottleneck3d):\n",
    "                        constant_init(m.conv3.bn, 0)\n",
    "                    elif isinstance(m, BasicBlock3d):\n",
    "                        constant_init(m.conv2.bn, 0)\n",
    "        else:\n",
    "            raise TypeError('pretrained must be a str or None')\n",
    "\n",
    "    def init_weights(self, pretrained=None):\n",
    "        self._init_weights(self, pretrained)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the computation performed at every call.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The feature of the input\n",
    "            samples extracted by the backbone.\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        if self.with_pool1:\n",
    "            x = self.maxpool(x)\n",
    "        outs = []\n",
    "        for i, layer_name in enumerate(self.res_layers):\n",
    "            res_layer = getattr(self, layer_name)\n",
    "            x = res_layer(x)\n",
    "            if i == 0 and self.with_pool2:\n",
    "                x = self.pool2(x)\n",
    "            if i in self.out_indices:\n",
    "                outs.append(x)\n",
    "        if len(outs) == 1:\n",
    "            return outs[0]\n",
    "\n",
    "        return tuple(outs)\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        \"\"\"Set the optimization status when training.\"\"\"\n",
    "        super().train(mode)\n",
    "        self._freeze_stages()\n",
    "        if mode and self.norm_eval:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, _BatchNorm):\n",
    "                    m.eval()\n",
    "\n",
    "\n",
    "class CSNBottleneck3d(Bottleneck3d):\n",
    "    \"\"\"Channel-Separated Bottleneck Block.\n",
    "\n",
    "    This module is proposed in\n",
    "    \"Video Classification with Channel-Separated Convolutional Networks\"\n",
    "    Link: https://arxiv.org/pdf/1711.11248.pdf\n",
    "\n",
    "    Args:\n",
    "        inplanes (int): Number of channels for the input in first conv3d layer.\n",
    "        planes (int): Number of channels produced by some norm/conv3d layers.\n",
    "        bottleneck_mode (str): Determine which ways to factorize a 3D\n",
    "            bottleneck block using channel-separated convolutional networks.\n",
    "                If set to 'ip', it will replace the 3x3x3 conv2 layer with a\n",
    "                1x1x1 traditional convolution and a 3x3x3 depthwise\n",
    "                convolution, i.e., Interaction-preserved channel-separated\n",
    "                bottleneck block.\n",
    "                If set to 'ir', it will replace the 3x3x3 conv2 layer with a\n",
    "                3x3x3 depthwise convolution, which is derived from preserved\n",
    "                bottleneck block by removing the extra 1x1x1 convolution,\n",
    "                i.e., Interaction-reduced channel-separated bottleneck block.\n",
    "            Default: 'ir'.\n",
    "        args (position arguments): Position arguments for Bottleneck.\n",
    "        kwargs (dict, optional): Keyword arguments for Bottleneck.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 inplanes,\n",
    "                 planes,\n",
    "                 *args,\n",
    "                 bottleneck_mode='ir',\n",
    "                 **kwargs):\n",
    "        super(CSNBottleneck3d, self).__init__(inplanes, planes, *args,\n",
    "                                              **kwargs)\n",
    "        self.bottleneck_mode = bottleneck_mode\n",
    "        conv2 = []\n",
    "        if self.bottleneck_mode == 'ip':\n",
    "            conv2.append(\n",
    "                ConvModule(\n",
    "                    planes,\n",
    "                    planes,\n",
    "                    1,\n",
    "                    stride=1,\n",
    "                    bias=False,\n",
    "                    conv_cfg=self.conv_cfg,\n",
    "                    norm_cfg=self.norm_cfg,\n",
    "                    act_cfg=None))\n",
    "        conv2_kernel_size = self.conv2.conv.kernel_size\n",
    "        conv2_stride = self.conv2.conv.stride\n",
    "        conv2_padding = self.conv2.conv.padding\n",
    "        conv2_dilation = self.conv2.conv.dilation\n",
    "        conv2_bias = bool(self.conv2.conv.bias)\n",
    "        self.conv2 = ConvModule(\n",
    "            planes,\n",
    "            planes,\n",
    "            conv2_kernel_size,\n",
    "            stride=conv2_stride,\n",
    "            padding=conv2_padding,\n",
    "            dilation=conv2_dilation,\n",
    "            bias=conv2_bias,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            norm_cfg=self.norm_cfg,\n",
    "            act_cfg=self.act_cfg,\n",
    "            groups=planes)\n",
    "        conv2.append(self.conv2)\n",
    "        self.conv2 = nn.Sequential(*conv2)\n",
    "\n",
    "\n",
    "class ResNet3dCSN(ResNet3d):\n",
    "    \"\"\"ResNet backbone for CSN.\n",
    "\n",
    "    Args:\n",
    "        depth (int): Depth of ResNetCSN, from {18, 34, 50, 101, 152}.\n",
    "        pretrained (str | None): Name of pretrained model.\n",
    "        temporal_strides (tuple[int]):\n",
    "            Temporal strides of residual blocks of each stage.\n",
    "            Default: (1, 2, 2, 2).\n",
    "        conv1_kernel (tuple[int]): Kernel size of the first conv layer.\n",
    "            Default: (3, 7, 7).\n",
    "        conv1_stride_t (int): Temporal stride of the first conv layer.\n",
    "            Default: 1.\n",
    "        pool1_stride_t (int): Temporal stride of the first pooling layer.\n",
    "            Default: 1.\n",
    "        norm_cfg (dict): Config for norm layers. required keys are `type` and\n",
    "            `requires_grad`.\n",
    "            Default: dict(type='BN3d', requires_grad=True, eps=1e-3).\n",
    "        inflate_style (str): `3x1x1` or `3x3x3`. which determines the kernel\n",
    "            sizes and padding strides for conv1 and conv2 in each block.\n",
    "            Default: '3x3x3'.\n",
    "        bottleneck_mode (str): Determine which ways to factorize a 3D\n",
    "            bottleneck block using channel-separated convolutional networks.\n",
    "                If set to 'ip', it will replace the 3x3x3 conv2 layer with a\n",
    "                1x1x1 traditional convolution and a 3x3x3 depthwise\n",
    "                convolution, i.e., Interaction-preserved channel-separated\n",
    "                bottleneck block.\n",
    "                If set to 'ir', it will replace the 3x3x3 conv2 layer with a\n",
    "                3x3x3 depthwise convolution, which is derived from preserved\n",
    "                bottleneck block by removing the extra 1x1x1 convolution,\n",
    "                i.e., Interaction-reduced channel-separated bottleneck block.\n",
    "            Default: 'ip'.\n",
    "        kwargs (dict, optional): Key arguments for \"make_res_layer\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 depth,\n",
    "                 pretrained,\n",
    "                 temporal_strides=(1, 2, 2, 2),\n",
    "                 conv1_kernel=(3, 7, 7),\n",
    "                 conv1_stride_t=1,\n",
    "                 pool1_stride_t=1,\n",
    "                 norm_cfg=dict(type='BN3d', requires_grad=True, eps=1e-3),\n",
    "                 inflate_style='3x3x3',\n",
    "                 bottleneck_mode='ir',\n",
    "                 bn_frozen=False,\n",
    "                 **kwargs):\n",
    "        self.arch_settings = {\n",
    "            # 18: (BasicBlock3d, (2, 2, 2, 2)),\n",
    "            # 34: (BasicBlock3d, (3, 4, 6, 3)),\n",
    "            50: (CSNBottleneck3d, (3, 4, 6, 3)),\n",
    "            101: (CSNBottleneck3d, (3, 4, 23, 3)),\n",
    "            152: (CSNBottleneck3d, (3, 8, 36, 3))\n",
    "        }\n",
    "        self.bn_frozen = bn_frozen\n",
    "        if bottleneck_mode not in ['ip', 'ir']:\n",
    "            raise ValueError(f'Bottleneck mode must be \"ip\" or \"ir\",'\n",
    "                             f'but got {bottleneck_mode}.')\n",
    "        super(ResNet3dCSN, self).__init__(\n",
    "            depth,\n",
    "            pretrained,\n",
    "            temporal_strides=temporal_strides,\n",
    "            conv1_kernel=conv1_kernel,\n",
    "            conv1_stride_t=conv1_stride_t,\n",
    "            pool1_stride_t=pool1_stride_t,\n",
    "            norm_cfg=norm_cfg,\n",
    "            inflate_style=inflate_style,\n",
    "            bottleneck_mode=bottleneck_mode,\n",
    "            **kwargs)\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        super(ResNet3d, self).train(mode)\n",
    "        self._freeze_stages()\n",
    "        if mode and self.norm_eval:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, _BatchNorm):\n",
    "                    m.eval()\n",
    "                    if self.bn_frozen:\n",
    "                        for param in m.parameters():\n",
    "                            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0764922",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ResNet3dCSN(\n",
    "    depth=50,\n",
    "    pretrained='./ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    temporal_strides=(1, 2, 2, 2),\n",
    "    conv1_kernel=(3, 7, 7),\n",
    "    conv1_stride_t=1,\n",
    "    pool1_stride_t=1,\n",
    "    norm_cfg={'type': 'BN3d', 'requires_grad': True, 'eps': 0.001},\n",
    "    inflate_style='3x3x3',\n",
    "    bottleneck_mode='ir',\n",
    "    bn_frozen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55122abe",
   "metadata": {},
   "source": [
    "## Decoder Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7eb311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, in_features=2048, num_classes=400):\n",
    "        super(ClassifierHead, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.avg_pool(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0c277",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbaf24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x):\n",
    "        code = self.encoder(x)\n",
    "        return self.decoder(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae268c2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f3188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "# import wandb\n",
    "from torchvision import transforms\n",
    "from video_dataset import VideoFrameDataset, ImglistToTensor\n",
    "\n",
    "# wandb.init(entity=\"cares\", project=\"autoencoder-experiments\", group=\"pytorch-csn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1cad2",
   "metadata": {},
   "source": [
    "## Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1125627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "except:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e41de",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d97582",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.join(os.getcwd(), 'data/autsl/rawframes') \n",
    "ann_file_train = os.path.join(os.getcwd(), 'data/autsl/train_annotations.txt') \n",
    "ann_file_test = os.path.join(os.getcwd(), 'data/autsl/test_annotations.txt')\n",
    "batch_size = 20\n",
    "\n",
    "# Setting up data augments\n",
    "train_pipeline = transforms.Compose([\n",
    "        ImglistToTensor(), # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "        transforms.Resize(256), # image batch, resize smaller edge to 256\n",
    "        transforms.RandomResizedCrop((224, 224)), # image batch, center crop to square 224x224\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "test_pipeline = transforms.Compose([\n",
    "        ImglistToTensor(), # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "        transforms.Resize(256),  # image batch, resize smaller edge to 256\n",
    "        transforms.CenterCrop((224, 224)),  # image batch, center crop to square 224x224\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "# Setting up datasets\n",
    "train_dataset = VideoFrameDataset(\n",
    "    root_path=data_root,\n",
    "    annotationfile_path=ann_file_train,\n",
    "    num_segments=5,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='img_{:05d}.jpg',\n",
    "    transform=train_pipeline,\n",
    "    test_mode=False\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = VideoFrameDataset(\n",
    "    root_path=data_root,\n",
    "    annotationfile_path=ann_file_test,\n",
    "    num_segments=5,\n",
    "    frames_per_segment=1,\n",
    "    imagefile_template='img_{:05d}.jpg',\n",
    "    transform=test_pipeline,\n",
    "    test_mode=True\n",
    ")\n",
    "\n",
    "# Setting up dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                    batch_size=2,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6850b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "get = next(dataiter)\n",
    "get[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ee481c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 5, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape = get[0].permute(0,2,1,3,4)\n",
    "reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372fee22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2048, 1, 7, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = encoder(reshape)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9152cae",
   "metadata": {},
   "source": [
    "## Set up model, loss and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b4d4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSN model\n",
    "encoder = ResNet3dCSN(\n",
    "    depth=50,\n",
    "    pretrained='./ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    temporal_strides=(1, 2, 2, 2),\n",
    "    conv1_kernel=(3, 7, 7),\n",
    "    conv1_stride_t=1,\n",
    "    pool1_stride_t=1,\n",
    "    norm_cfg={'type': 'BN3d', 'requires_grad': True, 'eps': 0.001},\n",
    "    inflate_style='3x3x3',\n",
    "    bottleneck_mode='ir',\n",
    "    bn_frozen=True)\n",
    "\n",
    "decoder = ClassifierHead()\n",
    "\n",
    "model = EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "# Specify learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[12,16])\n",
    "\n",
    "# Setup wandb\n",
    "# wandb.watch(csn, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8e23889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5, 3, 224, 224])\n",
      "tensor([ 41, 104, 205,  26, 191, 140, 139, 225, 102,  19, 160, 143, 215, 130,\n",
      "        166,   5,  28, 162, 202,  76])\n"
     ]
    }
   ],
   "source": [
    "for video_batch, targets in train_loader:\n",
    "    print(video_batch.size())\n",
    "    print(targets)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f63b2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 400])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = model(video_batch.permute(0,2,1,3,4))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccf0daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 6.102520\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "interval = 1 # For checkpoints and validation\n",
    "\n",
    "losses = []\n",
    "eval_accu = []\n",
    "eval_losses=[]\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Reset train loss\n",
    "    train_loss = 0.0\n",
    "    for video_batch, targets in train_loader:\n",
    "        # Move data to device\n",
    "        video_batch, targets = video_batch.to(device), targets.to(device)\n",
    "        \n",
    "        # batch_size, n_frames, channels, h, w -> previous doesn't work\n",
    "        # batch_size, channels, n_frames, h, w -> current\n",
    "        predictions = model(video_batch.permute(0,2,1,3,4))\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate batch loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    \n",
    "#     # Check for interval to validate and save checkpoints\n",
    "#     if interval!=0 and epoch%interval==0:\n",
    "#         running_loss=0\n",
    "#         correct=0\n",
    "#         total=0\n",
    "#         with torch.no_grad():\n",
    "#             for video_batch, targets in test_loader:\n",
    "#                 video_batch, targets = video_batch.to(device), targets.to(device)\n",
    "\n",
    "#                 predictions = model(video_batch.permute(0,2,1,3,4))\n",
    "#                 x = predictions\n",
    "                \n",
    "#                 loss = loss_fn(predictions, targets)\n",
    "#                 running_loss += loss.item()\n",
    "\n",
    "#                 _, predicted = predictions.max(1)\n",
    "#                 total += targets.size(0)\n",
    "#                 correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#         test_loss=running_loss/len(test_loader)\n",
    "#         accu=100.*correct/total\n",
    "\n",
    "#         eval_losses.append(test_loss)\n",
    "#         eval_accu.append(accu)\n",
    "#         print('Test Loss: %.3f | Accuracy: %.3f'%(test_loss,accu)) \n",
    "\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    losses.append(train_loss)\n",
    "    print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss:.6f}')\n",
    "    \n",
    "    # Wandb Log\n",
    "#     wandb.log({\"loss\": loss,\n",
    "#               \"val/top_1_acc\": accu})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82185ad",
   "metadata": {},
   "source": [
    "## Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8127831f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CSN model\n",
    "csn = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "torch.save(csn.state_dict(), 'csn_pytorch.pth')\n",
    "csn_checkpoint = torch.load('csn_pytorch.pth')\n",
    "csn_checkpoint['conv1.bn.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b824b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 13:31:13,596 - __main__ - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n",
      "2023-01-25 13:31:13,597 - __main__ - INFO - load checkpoint from http path: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\n"
     ]
    }
   ],
   "source": [
    "csn.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa8e439b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1484,  0.1335,  0.1338, -0.0662,  0.0816,  0.2584,  0.3668,  0.0220,\n",
       "         0.0340,  0.1519,  0.2983,  0.1960,  0.1252, -0.1946,  0.1251,  0.1744,\n",
       "        -0.1176,  0.0552,  0.2115,  0.1147,  0.1512,  0.0100,  0.1139, -0.1167,\n",
       "        -0.3074,  0.3505,  0.1095,  0.1350,  0.0070,  0.0912,  0.0391, -0.0301,\n",
       "         0.0594,  0.4528,  0.1496,  0.0821,  0.1459,  0.0975,  0.0762,  0.1379,\n",
       "         0.1202,  0.0490,  0.1243, -0.2907,  0.1372,  0.0622,  0.0415, -0.0024,\n",
       "         0.0536,  0.1500,  0.1832, -0.2792,  0.3292,  0.0187,  0.2583,  0.0424,\n",
       "         0.1285,  0.1322,  0.0591,  0.2062,  0.2182,  0.1271,  0.5645,  0.1426])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(csn.state_dict(), 'csn_pytorch.pth')\n",
    "csn_checkpoint = torch.load('csn_pytorch.pth')\n",
    "list(csn_checkpoint.keys())\n",
    "csn_checkpoint['conv1.bn.bias']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsign",
   "language": "python",
   "name": "mmsign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
