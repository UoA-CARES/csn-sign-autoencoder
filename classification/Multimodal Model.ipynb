{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0845abc0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e353a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba1256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myuser1/miniconda3/envs/wlasl/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "from mmcv_csn import ResNet3dCSN\n",
    "from cls_head import ClassifierHead\n",
    "from cls_autoencoder import EncoderDecoder\n",
    "from scheduler import GradualWarmupScheduler\n",
    "from mmaction.datasets import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a692e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc31acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "except:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = 'work_dirs/wlasl-dataset/'\n",
    "batch_size = 2\n",
    "\n",
    "os.makedirs(work_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the datasets\n",
    "train_dataset = build_dataset(train_cfg)\n",
    "test_dataset = build_dataset(test_cfg)\n",
    "\n",
    "# Setting up dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                    batch_size=1,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class PoseEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PoseEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 1024)\n",
    "        self.fc6 = nn.Linear(1024, 1024)\n",
    "        self.fc7 = nn.Linear(1024, out_channels)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55201c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63eb380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2048, 4, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18a25326",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a285b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.concat((z,y), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe3e3c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1204224])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiModalNeck(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiModalNeck, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "\n",
    "    def forward(self,\n",
    "                rgb=None,\n",
    "                depth=None,\n",
    "                flow=None,\n",
    "                face=None,\n",
    "                left_hand=None,\n",
    "                right_hand=None,\n",
    "                pose=None):\n",
    "        \n",
    "        out = torch.tensor([])\n",
    "        \n",
    "        if rgb is not None:\n",
    "            rgb = torch.flatten(self.avg_pool(rgb))\n",
    "            out = torch.concat((out, rgb), dim=0)\n",
    "        \n",
    "        if depth is not None:\n",
    "            depth = torch.flatten(self.avg_pool(depth))\n",
    "            out = torch.concat((out, depth), dim=0)\n",
    "\n",
    "        if flow is not None:\n",
    "            flow = torch.flatten(self.avg_pool(flow))\n",
    "            out = torch.concat((out, flow), dim=0)\n",
    "\n",
    "        if face is not None:\n",
    "            face = torch.flatten(self.avg_pool(face))\n",
    "            out = torch.concat((out, face), dim=0)\n",
    "\n",
    "        if left_hand is not None:\n",
    "            left_hand = torch.flatten(self.avg_pool(left_hand))\n",
    "            out = torch.concat((out, left_hand), dim=0)\n",
    "\n",
    "        if right_hand is not None:\n",
    "            right_hand = torch.flatten(self.avg_pool(right_hand))\n",
    "            out = torch.concat((out, right_hand), dim=0)\n",
    "            \n",
    "        if pose is not None:\n",
    "            out = torch.concat((out, pose), dim=0)\n",
    "            \n",
    "        return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf8804d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ResNet3dCSN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a CSN model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rgb_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mResNet3dCSN\u001b[49m(\n\u001b[1;32m      3\u001b[0m     pretrained2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# pretrained=None,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      7\u001b[0m     with_pool2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     bottleneck_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mir\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     norm_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     zero_init_residual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     bn_frozen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create a CSN model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m flow_encoder \u001b[38;5;241m=\u001b[39m ResNet3dCSN(\n\u001b[1;32m     16\u001b[0m     pretrained2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# pretrained=None,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     bn_frozen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ResNet3dCSN' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a CSN model for rgb\n",
    "rgb_encoder = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    # pretrained=None,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "# Create a CSN model for flow\n",
    "flow_encoder = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    # pretrained=None,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "# Create a CSN model for depth\n",
    "depth_encoder = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    # pretrained=None,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "# Create a CSN model for left hand\n",
    "lhand_encoder = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    # pretrained=None,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "# Create a CSN model for right hand\n",
    "rhand_encoder = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    # pretrained=None,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "# Create a CSN model for face\n",
    "face_encoder = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    # pretrained=None,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "# Add the dimensions here\n",
    "pose_encoder = PoseEncoder(# dimensions go here)\n",
    "\n",
    "rgb_encoder.init_weights()\n",
    "depth_encoder.init_weights()\n",
    "flow_encoder.init_weights()\n",
    "rhand_encoder.init_weights()\n",
    "lhand_encoder.init_weights()\n",
    "face_encoder.init_weights()\n",
    "\n",
    "neck = MultiModalNeck()\n",
    "\n",
    "# TODO: Classification Head change in_features\n",
    "\n",
    "head = ClassifierHead(num_classes=400,\n",
    "                 in_features=2048,\n",
    "                 dropout_ratio=0.5,\n",
    "                 init_std=0.01)\n",
    "\n",
    "head.init_weights()\n",
    "\n",
    "model = EncoderDecoder(encoder, decoder, reconstruct_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd1c689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class PoseEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PoseEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 1024)\n",
    "        self.fc6 = nn.Linear(1024, 1024)\n",
    "        self.fc7 = nn.Linear(1024, out_channels)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5d873a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poseencoder = PoseEncoder(2, 4)\n",
    "x = torch.tensor([1.0,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54139f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0026, 0.0408], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poseencoder(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wlasl)",
   "language": "python",
   "name": "wlasl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
