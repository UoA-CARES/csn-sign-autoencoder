{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff55122",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e609b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/dataloader/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sadat/miniconda3/envs/dataloader/lib/python3.8/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torchvision.transforms\n",
    "\n",
    "from mmcv_csn import ResNet3dCSN\n",
    "from csn import csn50\n",
    "from i3d_head import I3DHead\n",
    "from autoencoder import EncoderDecoder\n",
    "from depth_head import DepthHead\n",
    "from scheduler import GradualWarmupScheduler\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1f6232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msttaseen\u001b[0m (\u001b[33mcares\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sadat/Desktop/csn-sign-autoencoder/wandb/run-20230205_181914-3arddnds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cares/autoencoder/runs/3arddnds\" target=\"_blank\">depth</a></strong> to <a href=\"https://wandb.ai/cares/autoencoder\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/cares/autoencoder/runs/3arddnds?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9d91b00400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(entity=\"cares\", project=\"autoencoder\",\n",
    "           group=\"wlasl-10\", name=\"depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da63075",
   "metadata": {},
   "source": [
    "## Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcbb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device agnostic code\n",
    "try:\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "except:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b938a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8426ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg=dict(\n",
    "    type='RawframeDataset',\n",
    "    ann_file='data/wlasl10/train_annotations.txt',\n",
    "    data_prefix='data/wlasl10/rawframes',\n",
    "    pipeline=[\n",
    "        dict(\n",
    "            type='SampleFrames',\n",
    "            clip_len=32,\n",
    "            frame_interval=2,\n",
    "            num_clips=1),\n",
    "        dict(type='RawFrameDecode'),\n",
    "        dict(type='Resize', scale=(-1, 256)),\n",
    "        dict(type='RandomResizedCrop'),\n",
    "        dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "        dict(type='Flip', flip_ratio=0.5),\n",
    "        dict(\n",
    "            type='Normalize',\n",
    "            mean=[123.675, 116.28, 103.53],\n",
    "            std=[58.395, 57.12, 57.375],\n",
    "            to_bgr=False),\n",
    "        dict(type='FormatShape', input_format='NCTHW'),\n",
    "        dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "        dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "    ])\n",
    "\n",
    "\n",
    "test_cfg=dict(\n",
    "        type='RawframeDataset',\n",
    "        ann_file='data/wlasl10/test_annotations.txt',\n",
    "        data_prefix='data/wlasl10/rawframes',\n",
    "        pipeline=[\n",
    "            dict(\n",
    "                type='SampleFrames',\n",
    "                clip_len=32,\n",
    "                frame_interval=2,\n",
    "                num_clips=1,\n",
    "                test_mode=True),\n",
    "            dict(type='RawFrameDecode'),\n",
    "            dict(type='Resize', scale=(-1, 256)),\n",
    "            dict(type='CenterCrop', crop_size=224),\n",
    "            dict(\n",
    "                type='Normalize',\n",
    "                mean=[123.675, 116.28, 103.53],\n",
    "                std=[58.395, 57.12, 57.375],\n",
    "                to_bgr=False),\n",
    "            dict(type='FormatShape', input_format='NCTHW'),\n",
    "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "            dict(type='ToTensor', keys=['imgs'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946a5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = 'work_dirs/wlasl10-depth-dataset/'\n",
    "\n",
    "os.makedirs(work_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d33be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the datasets\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = build_dataset(train_cfg)\n",
    "test_dataset = build_dataset(test_cfg)\n",
    "\n",
    "# Setting up dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                    batch_size=1,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=4,\n",
    "                                    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99287401",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82eff841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSN model\n",
    "encoder = ResNet3dCSN(\n",
    "    pretrained2d=False,\n",
    "    # pretrained=None,\n",
    "    pretrained='https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r50_ig65m_20210617-ce545a37.pth',\n",
    "    depth=50,\n",
    "    with_pool2=False,\n",
    "    bottleneck_mode='ir',\n",
    "    norm_eval=True,\n",
    "    zero_init_residual=False,\n",
    "    bn_frozen=True\n",
    ")\n",
    "\n",
    "encoder.init_weights()\n",
    "\n",
    "depth_head = DepthHead()\n",
    "\n",
    "decoder = I3DHead(num_classes=400,\n",
    "                 in_channels=2048,\n",
    "                 spatial_type='avg',\n",
    "                 dropout_ratio=0.5,\n",
    "                 init_std=0.01)\n",
    "\n",
    "decoder.init_weights()\n",
    "\n",
    "model = EncoderDecoder(encoder, decoder, depth_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cfe34e",
   "metadata": {},
   "source": [
    "### Setup MiDaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02459afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sadat/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DPTDepthModel(\n",
       "  (pretrained): Module(\n",
       "    (model): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (fc_norm): Identity()\n",
       "      (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "    )\n",
       "    (act_postprocess1): Sequential(\n",
       "      (0): ProjectReadout(\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Transpose()\n",
       "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
       "      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "    )\n",
       "    (act_postprocess2): Sequential(\n",
       "      (0): ProjectReadout(\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Transpose()\n",
       "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
       "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (act_postprocess3): Sequential(\n",
       "      (0): ProjectReadout(\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Transpose()\n",
       "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (act_postprocess4): Sequential(\n",
       "      (0): ProjectReadout(\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Transpose()\n",
       "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (scratch): Module(\n",
       "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (refinenet1): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (refinenet2): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (refinenet3): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (refinenet4): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Interpolate()\n",
       "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up MiDaS depth model\n",
    "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "# model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
    "# model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
    "\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "midas.to(device)\n",
    "midas.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f489c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_depth(images):\n",
    "    with torch.no_grad():\n",
    "        depth = midas(images.permute(0,2,1,3,4).reshape(-1,3,224,224))\n",
    "\n",
    "        depth = torch.nn.functional.interpolate(\n",
    "            depth.unsqueeze(1),\n",
    "            size=(224,224),\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "        \n",
    "    return depth.reshape(-1, 1, 32, 224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7c5e9",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43494dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): ResNet3dCSN(\n",
       "    (conv1): ConvModule(\n",
       "      (conv): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
       "      (bn): BatchNorm3d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "    (pool2): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)\n",
       "            (bn): BatchNorm3d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)\n",
       "            (bn): BatchNorm3d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=64, bias=False)\n",
       "            (bn): BatchNorm3d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=256, bias=False)\n",
       "            (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (bn): BatchNorm3d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)\n",
       "            (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)\n",
       "            (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)\n",
       "            (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)\n",
       "            (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256, bias=False)\n",
       "            (bn): BatchNorm3d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), groups=512, bias=False)\n",
       "            (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (bn): BatchNorm3d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)\n",
       "            (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): CSNBottleneck3d(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): ConvModule(\n",
       "            (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512, bias=False)\n",
       "            (bn): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activate): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (bn): BatchNorm3d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls_head): I3DHead(\n",
       "    (loss_cls): CrossEntropyLoss()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc_cls): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    (avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "  )\n",
       "  (depth_head): DepthHead(\n",
       "    (decoder1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv3d(2048, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): ConvTranspose3d(2048, 1024, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "    (decoder2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv3d(2048, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv3d(1024, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (2): ConvTranspose3d(1024, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "    (decoder3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv3d(512, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (2): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "    (decoder4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): ConvTranspose3d(256, 64, kernel_size=(3, 2, 2), stride=(1, 2, 2), padding=(1, 0, 0))\n",
       "    )\n",
       "    (outc): ConvTranspose3d(128, 1, kernel_size=(3, 2, 2), stride=(1, 2, 2), padding=(1, 0, 0))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify optimizer\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.000125, momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "# Specify Loss\n",
    "loss_cls = nn.CrossEntropyLoss()\n",
    "loss_depth = nn.MSELoss()\n",
    "\n",
    "# Specify total epochs\n",
    "epochs = 100\n",
    "\n",
    "# Specify learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=120, gamma=0.1)\n",
    "\n",
    "scheduler_steplr = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[34, 84], gamma=0.1)\n",
    "scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=16, after_scheduler=scheduler_steplr)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a7f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0=torch.rand((1,64,32,112,112)).to(device)\n",
    "# x1=torch.rand((1,256,32,56,56)).to(device)\n",
    "# x2=torch.rand((1,512,16,28,28)).to(device)\n",
    "# x3=torch.rand((1,1024,8,14,14)).to(device)\n",
    "# x4=torch.rand((1,2048,4,7,7)).to(device)\n",
    "# x = (x0,x1,x2,x3,x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeefe494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_head(x).squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a246d",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "847f4470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1][5/100], loss_cls: 5.957, depth_loss: 185.78 lr: 0.00000e+00, loss: 61.723\n",
      "Epoch [1][10/100], loss_cls: 6.0782, depth_loss: 247.7 lr: 0.00000e+00, loss: 49.425\n",
      "Epoch [1][15/100], loss_cls: 6.0302, depth_loss: 149.94 lr: 0.00000e+00, loss: 60.489\n",
      "Epoch [1][20/100], loss_cls: 5.8484, depth_loss: 188.43 lr: 0.00000e+00, loss: 53.803\n",
      "Epoch [1][25/100], loss_cls: 6.1516, depth_loss: 315.83 lr: 0.00000e+00, loss: 65.932\n",
      "Epoch [1][30/100], loss_cls: 6.1372, depth_loss: 263.03 lr: 0.00000e+00, loss: 64.128\n",
      "Epoch [1][35/100], loss_cls: 6.1178, depth_loss: 199.56 lr: 0.00000e+00, loss: 59.029\n",
      "Epoch [1][40/100], loss_cls: 5.7811, depth_loss: 298.41 lr: 0.00000e+00, loss: 63.43\n",
      "Epoch [1][45/100], loss_cls: 5.9172, depth_loss: 311.47 lr: 0.00000e+00, loss: 70.877\n",
      "Epoch [1][50/100], loss_cls: 5.9634, depth_loss: 166.38 lr: 0.00000e+00, loss: 49.024\n",
      "Epoch [1][55/100], loss_cls: 5.9322, depth_loss: 218.07 lr: 0.00000e+00, loss: 62.312\n",
      "Epoch [1][60/100], loss_cls: 6.1725, depth_loss: 334.26 lr: 0.00000e+00, loss: 58.516\n",
      "Epoch [1][65/100], loss_cls: 6.0256, depth_loss: 463.34 lr: 0.00000e+00, loss: 66.818\n",
      "Epoch [1][70/100], loss_cls: 6.0385, depth_loss: 207.47 lr: 0.00000e+00, loss: 65.025\n",
      "Epoch [1][75/100], loss_cls: 6.0516, depth_loss: 333.72 lr: 0.00000e+00, loss: 68.725\n",
      "Epoch [1][80/100], loss_cls: 5.9701, depth_loss: 234.22 lr: 0.00000e+00, loss: 62.177\n",
      "Epoch [1][85/100], loss_cls: 5.8726, depth_loss: 383.92 lr: 0.00000e+00, loss: 55.855\n",
      "Epoch [1][90/100], loss_cls: 6.0687, depth_loss: 292.67 lr: 0.00000e+00, loss: 63.613\n",
      "Epoch [1][95/100], loss_cls: 5.9073, depth_loss: 318.51 lr: 0.00000e+00, loss: 62.835\n",
      "Epoch [1][100/100], loss_cls: 5.8759, depth_loss: 261.24 lr: 0.00000e+00, loss: 59.928\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.0, top5_acc: 0.0, train_loss: 59.928, val_loss: 44.919\n",
      "Saving checkpoint at 1 epochs...\n",
      "Epoch [2][5/100], loss_cls: 5.8064, depth_loss: 209.52 lr: 7.81250e-06, loss: 67.4\n",
      "Epoch [2][10/100], loss_cls: 5.9042, depth_loss: 327.36 lr: 7.81250e-06, loss: 66.902\n",
      "Epoch [2][15/100], loss_cls: 6.1104, depth_loss: 222.64 lr: 7.81250e-06, loss: 54.594\n",
      "Epoch [2][20/100], loss_cls: 6.1047, depth_loss: 339.05 lr: 7.81250e-06, loss: 60.283\n",
      "Epoch [2][25/100], loss_cls: 5.7952, depth_loss: 227.67 lr: 7.81250e-06, loss: 49.399\n",
      "Epoch [2][30/100], loss_cls: 6.0649, depth_loss: 201.07 lr: 7.81250e-06, loss: 52.006\n",
      "Epoch [2][35/100], loss_cls: 6.1362, depth_loss: 304.11 lr: 7.81250e-06, loss: 61.449\n",
      "Epoch [2][40/100], loss_cls: 5.9812, depth_loss: 285.21 lr: 7.81250e-06, loss: 55.254\n",
      "Epoch [2][45/100], loss_cls: 5.8712, depth_loss: 224.77 lr: 7.81250e-06, loss: 50.18\n",
      "Epoch [2][50/100], loss_cls: 5.9184, depth_loss: 217.21 lr: 7.81250e-06, loss: 46.855\n",
      "Epoch [2][55/100], loss_cls: 5.8238, depth_loss: 276.45 lr: 7.81250e-06, loss: 54.497\n",
      "Epoch [2][60/100], loss_cls: 5.7413, depth_loss: 140.14 lr: 7.81250e-06, loss: 46.577\n",
      "Epoch [2][65/100], loss_cls: 6.201, depth_loss: 267.86 lr: 7.81250e-06, loss: 58.418\n",
      "Epoch [2][70/100], loss_cls: 6.306, depth_loss: 248.98 lr: 7.81250e-06, loss: 57.89\n",
      "Epoch [2][75/100], loss_cls: 5.8559, depth_loss: 240.98 lr: 7.81250e-06, loss: 47.382\n",
      "Epoch [2][80/100], loss_cls: 5.9077, depth_loss: 153.59 lr: 7.81250e-06, loss: 41.906\n",
      "Epoch [2][85/100], loss_cls: 5.9062, depth_loss: 200.77 lr: 7.81250e-06, loss: 51.172\n",
      "Epoch [2][90/100], loss_cls: 6.0574, depth_loss: 191.61 lr: 7.81250e-06, loss: 47.2\n",
      "Epoch [2][95/100], loss_cls: 5.8934, depth_loss: 129.03 lr: 7.81250e-06, loss: 58.035\n",
      "Epoch [2][100/100], loss_cls: 5.9048, depth_loss: 218.39 lr: 7.81250e-06, loss: 56.968\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.0, top5_acc: 0.1429, train_loss: 56.968, val_loss: 35.44\n",
      "Saving checkpoint at 2 epochs...\n",
      "Epoch [3][5/100], loss_cls: 5.8626, depth_loss: 191.67 lr: 1.56250e-05, loss: 46.923\n",
      "Epoch [3][10/100], loss_cls: 5.6832, depth_loss: 236.88 lr: 1.56250e-05, loss: 44.788\n",
      "Epoch [3][15/100], loss_cls: 5.4554, depth_loss: 232.39 lr: 1.56250e-05, loss: 52.948\n",
      "Epoch [3][20/100], loss_cls: 6.0547, depth_loss: 202.3 lr: 1.56250e-05, loss: 44.33\n",
      "Epoch [3][25/100], loss_cls: 5.7233, depth_loss: 231.44 lr: 1.56250e-05, loss: 49.724\n",
      "Epoch [3][30/100], loss_cls: 5.6163, depth_loss: 268.23 lr: 1.56250e-05, loss: 57.134\n",
      "Epoch [3][35/100], loss_cls: 5.8399, depth_loss: 187.54 lr: 1.56250e-05, loss: 45.404\n",
      "Epoch [3][40/100], loss_cls: 6.0196, depth_loss: 229.65 lr: 1.56250e-05, loss: 45.1\n",
      "Epoch [3][45/100], loss_cls: 5.5729, depth_loss: 237.11 lr: 1.56250e-05, loss: 42.24\n",
      "Epoch [3][50/100], loss_cls: 5.584, depth_loss: 157.31 lr: 1.56250e-05, loss: 40.803\n",
      "Epoch [3][55/100], loss_cls: 5.3874, depth_loss: 257.16 lr: 1.56250e-05, loss: 39.804\n",
      "Epoch [3][60/100], loss_cls: 5.2052, depth_loss: 184.57 lr: 1.56250e-05, loss: 35.63\n",
      "Epoch [3][65/100], loss_cls: 5.6122, depth_loss: 159.93 lr: 1.56250e-05, loss: 38.416\n",
      "Epoch [3][70/100], loss_cls: 5.1812, depth_loss: 150.77 lr: 1.56250e-05, loss: 40.564\n",
      "Epoch [3][75/100], loss_cls: 5.3313, depth_loss: 164.92 lr: 1.56250e-05, loss: 39.798\n",
      "Epoch [3][80/100], loss_cls: 4.9065, depth_loss: 170.28 lr: 1.56250e-05, loss: 32.605\n",
      "Epoch [3][85/100], loss_cls: 5.3648, depth_loss: 155.73 lr: 1.56250e-05, loss: 30.033\n",
      "Epoch [3][90/100], loss_cls: 4.411, depth_loss: 149.11 lr: 1.56250e-05, loss: 30.376\n",
      "Epoch [3][95/100], loss_cls: 4.4214, depth_loss: 169.08 lr: 1.56250e-05, loss: 39.731\n",
      "Epoch [3][100/100], loss_cls: 4.8029, depth_loss: 87.537 lr: 1.56250e-05, loss: 37.119\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.1429, top5_acc: 0.5429, train_loss: 37.119, val_loss: 22.697\n",
      "Saving checkpoint at 3 epochs...\n",
      "Epoch [4][5/100], loss_cls: 4.3066, depth_loss: 99.459 lr: 2.34375e-05, loss: 32.791\n",
      "Epoch [4][10/100], loss_cls: 3.3448, depth_loss: 198.3 lr: 2.34375e-05, loss: 34.487\n",
      "Epoch [4][15/100], loss_cls: 3.9468, depth_loss: 211.7 lr: 2.34375e-05, loss: 41.3\n",
      "Epoch [4][20/100], loss_cls: 3.3333, depth_loss: 88.627 lr: 2.34375e-05, loss: 31.756\n",
      "Epoch [4][25/100], loss_cls: 4.228, depth_loss: 155.56 lr: 2.34375e-05, loss: 31.709\n",
      "Epoch [4][30/100], loss_cls: 2.2632, depth_loss: 123.81 lr: 2.34375e-05, loss: 33.363\n",
      "Epoch [4][35/100], loss_cls: 3.389, depth_loss: 155.37 lr: 2.34375e-05, loss: 34.452\n",
      "Epoch [4][40/100], loss_cls: 2.8278, depth_loss: 100.43 lr: 2.34375e-05, loss: 29.279\n",
      "Epoch [4][45/100], loss_cls: 3.0505, depth_loss: 139.17 lr: 2.34375e-05, loss: 31.06\n",
      "Epoch [4][50/100], loss_cls: 3.6774, depth_loss: 80.989 lr: 2.34375e-05, loss: 34.203\n",
      "Epoch [4][55/100], loss_cls: 2.5946, depth_loss: 157.13 lr: 2.34375e-05, loss: 34.661\n",
      "Epoch [4][60/100], loss_cls: 2.5413, depth_loss: 89.893 lr: 2.34375e-05, loss: 23.788\n",
      "Epoch [4][65/100], loss_cls: 2.8261, depth_loss: 147.48 lr: 2.34375e-05, loss: 32.911\n",
      "Epoch [4][70/100], loss_cls: 2.768, depth_loss: 91.405 lr: 2.34375e-05, loss: 33.375\n",
      "Epoch [4][75/100], loss_cls: 2.8699, depth_loss: 148.25 lr: 2.34375e-05, loss: 28.238\n",
      "Epoch [4][80/100], loss_cls: 3.216, depth_loss: 214.98 lr: 2.34375e-05, loss: 27.357\n",
      "Epoch [4][85/100], loss_cls: 2.3992, depth_loss: 145.5 lr: 2.34375e-05, loss: 31.71\n",
      "Epoch [4][90/100], loss_cls: 3.7526, depth_loss: 58.797 lr: 2.34375e-05, loss: 30.011\n",
      "Epoch [4][95/100], loss_cls: 2.3417, depth_loss: 99.863 lr: 2.34375e-05, loss: 24.151\n",
      "Epoch [4][100/100], loss_cls: 3.1518, depth_loss: 98.786 lr: 2.34375e-05, loss: 30.918\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.1143, top5_acc: 0.4857, train_loss: 30.918, val_loss: 18.8\n",
      "Saving checkpoint at 4 epochs...\n",
      "Epoch [5][5/100], loss_cls: 4.1863, depth_loss: 275.26 lr: 3.12500e-05, loss: 36.353\n",
      "Epoch [5][10/100], loss_cls: 5.4003, depth_loss: 127.67 lr: 3.12500e-05, loss: 27.483\n",
      "Epoch [5][15/100], loss_cls: 2.844, depth_loss: 118.09 lr: 3.12500e-05, loss: 27.492\n",
      "Epoch [5][20/100], loss_cls: 2.3301, depth_loss: 91.433 lr: 3.12500e-05, loss: 22.258\n",
      "Epoch [5][25/100], loss_cls: 2.293, depth_loss: 90.579 lr: 3.12500e-05, loss: 23.787\n",
      "Epoch [5][30/100], loss_cls: 2.3892, depth_loss: 62.456 lr: 3.12500e-05, loss: 20.967\n",
      "Epoch [5][35/100], loss_cls: 3.7159, depth_loss: 191.06 lr: 3.12500e-05, loss: 24.113\n",
      "Epoch [5][40/100], loss_cls: 2.2644, depth_loss: 103.55 lr: 3.12500e-05, loss: 22.437\n",
      "Epoch [5][45/100], loss_cls: 1.143, depth_loss: 102.2 lr: 3.12500e-05, loss: 19.747\n",
      "Epoch [5][50/100], loss_cls: 2.6926, depth_loss: 106.67 lr: 3.12500e-05, loss: 21.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5][55/100], loss_cls: 3.2985, depth_loss: 121.6 lr: 3.12500e-05, loss: 23.588\n",
      "Epoch [5][60/100], loss_cls: 3.2606, depth_loss: 101.36 lr: 3.12500e-05, loss: 21.682\n",
      "Epoch [5][65/100], loss_cls: 2.7699, depth_loss: 64.207 lr: 3.12500e-05, loss: 21.874\n",
      "Epoch [5][70/100], loss_cls: 2.3693, depth_loss: 87.796 lr: 3.12500e-05, loss: 19.021\n",
      "Epoch [5][75/100], loss_cls: 2.1037, depth_loss: 49.692 lr: 3.12500e-05, loss: 15.965\n",
      "Epoch [5][80/100], loss_cls: 2.4505, depth_loss: 93.658 lr: 3.12500e-05, loss: 20.284\n",
      "Epoch [5][85/100], loss_cls: 4.1476, depth_loss: 44.358 lr: 3.12500e-05, loss: 20.281\n",
      "Epoch [5][90/100], loss_cls: 2.4698, depth_loss: 34.601 lr: 3.12500e-05, loss: 12.501\n",
      "Epoch [5][95/100], loss_cls: 3.0408, depth_loss: 66.134 lr: 3.12500e-05, loss: 17.334\n",
      "Epoch [5][100/100], loss_cls: 1.7856, depth_loss: 46.679 lr: 3.12500e-05, loss: 14.633\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.1143, top5_acc: 0.6286, train_loss: 14.633, val_loss: 11.365\n",
      "Saving checkpoint at 5 epochs...\n",
      "Epoch [6][5/100], loss_cls: 5.5295, depth_loss: 119.26 lr: 3.90625e-05, loss: 25.613\n",
      "Epoch [6][10/100], loss_cls: 3.1611, depth_loss: 54.879 lr: 3.90625e-05, loss: 17.912\n",
      "Epoch [6][15/100], loss_cls: 4.1616, depth_loss: 47.533 lr: 3.90625e-05, loss: 14.213\n",
      "Epoch [6][20/100], loss_cls: 3.6759, depth_loss: 23.503 lr: 3.90625e-05, loss: 11.727\n",
      "Epoch [6][25/100], loss_cls: 2.4653, depth_loss: 129.32 lr: 3.90625e-05, loss: 13.531\n",
      "Epoch [6][30/100], loss_cls: 2.9984, depth_loss: 30.09 lr: 3.90625e-05, loss: 15.153\n",
      "Epoch [6][35/100], loss_cls: 2.784, depth_loss: 48.489 lr: 3.90625e-05, loss: 14.797\n",
      "Epoch [6][40/100], loss_cls: 3.2611, depth_loss: 55.216 lr: 3.90625e-05, loss: 16.363\n",
      "Epoch [6][45/100], loss_cls: 4.1732, depth_loss: 47.722 lr: 3.90625e-05, loss: 12.825\n",
      "Epoch [6][50/100], loss_cls: 2.964, depth_loss: 54.728 lr: 3.90625e-05, loss: 14.754\n",
      "Epoch [6][55/100], loss_cls: 3.8649, depth_loss: 57.323 lr: 3.90625e-05, loss: 12.815\n",
      "Epoch [6][60/100], loss_cls: 2.7385, depth_loss: 53.677 lr: 3.90625e-05, loss: 14.26\n",
      "Epoch [6][65/100], loss_cls: 2.4703, depth_loss: 61.355 lr: 3.90625e-05, loss: 12.972\n",
      "Epoch [6][70/100], loss_cls: 2.5121, depth_loss: 40.338 lr: 3.90625e-05, loss: 13.517\n",
      "Epoch [6][75/100], loss_cls: 2.4887, depth_loss: 26.774 lr: 3.90625e-05, loss: 11.444\n",
      "Epoch [6][80/100], loss_cls: 2.4007, depth_loss: 84.343 lr: 3.90625e-05, loss: 13.45\n",
      "Epoch [6][85/100], loss_cls: 2.8453, depth_loss: 13.049 lr: 3.90625e-05, loss: 8.1221\n",
      "Epoch [6][90/100], loss_cls: 3.5085, depth_loss: 44.62 lr: 3.90625e-05, loss: 12.861\n",
      "Epoch [6][95/100], loss_cls: 1.7075, depth_loss: 25.774 lr: 3.90625e-05, loss: 9.5978\n",
      "Epoch [6][100/100], loss_cls: 1.2681, depth_loss: 26.922 lr: 3.90625e-05, loss: 9.6517\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.08571, top5_acc: 0.6286, train_loss: 9.6517, val_loss: 7.1407\n",
      "Saving checkpoint at 6 epochs...\n",
      "Epoch [7][5/100], loss_cls: 2.1728, depth_loss: 38.244 lr: 4.68750e-05, loss: 10.312\n",
      "Epoch [7][10/100], loss_cls: 2.6115, depth_loss: 24.082 lr: 4.68750e-05, loss: 10.418\n",
      "Epoch [7][15/100], loss_cls: 1.9732, depth_loss: 31.138 lr: 4.68750e-05, loss: 13.203\n",
      "Epoch [7][20/100], loss_cls: 2.1597, depth_loss: 19.209 lr: 4.68750e-05, loss: 11.083\n",
      "Epoch [7][25/100], loss_cls: 2.5335, depth_loss: 46.863 lr: 4.68750e-05, loss: 13.565\n",
      "Epoch [7][30/100], loss_cls: 2.5182, depth_loss: 53.045 lr: 4.68750e-05, loss: 9.0014\n",
      "Epoch [7][35/100], loss_cls: 1.476, depth_loss: 48.372 lr: 4.68750e-05, loss: 9.7396\n",
      "Epoch [7][40/100], loss_cls: 2.2407, depth_loss: 42.158 lr: 4.68750e-05, loss: 9.5668\n",
      "Epoch [7][45/100], loss_cls: 2.8425, depth_loss: 40.281 lr: 4.68750e-05, loss: 11.072\n",
      "Epoch [7][50/100], loss_cls: 2.9867, depth_loss: 34.036 lr: 4.68750e-05, loss: 11.356\n",
      "Epoch [7][55/100], loss_cls: 2.1812, depth_loss: 45.068 lr: 4.68750e-05, loss: 9.4984\n",
      "Epoch [7][60/100], loss_cls: 3.0347, depth_loss: 34.218 lr: 4.68750e-05, loss: 10.492\n",
      "Epoch [7][65/100], loss_cls: 2.6295, depth_loss: 70.081 lr: 4.68750e-05, loss: 9.8131\n",
      "Epoch [7][70/100], loss_cls: 3.1038, depth_loss: 18.358 lr: 4.68750e-05, loss: 7.3583\n",
      "Epoch [7][75/100], loss_cls: 3.1437, depth_loss: 26.173 lr: 4.68750e-05, loss: 7.5126\n",
      "Epoch [7][80/100], loss_cls: 3.7821, depth_loss: 36.739 lr: 4.68750e-05, loss: 8.8752\n",
      "Epoch [7][85/100], loss_cls: 3.0962, depth_loss: 15.645 lr: 4.68750e-05, loss: 8.9968\n",
      "Epoch [7][90/100], loss_cls: 3.6147, depth_loss: 26.753 lr: 4.68750e-05, loss: 7.7069\n",
      "Epoch [7][95/100], loss_cls: 0.93101, depth_loss: 38.601 lr: 4.68750e-05, loss: 7.0348\n",
      "Epoch [7][100/100], loss_cls: 3.4281, depth_loss: 38.076 lr: 4.68750e-05, loss: 8.3602\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.1143, top5_acc: 0.6, train_loss: 8.3602, val_loss: 6.2673\n",
      "Saving checkpoint at 7 epochs...\n",
      "Epoch [8][5/100], loss_cls: 2.6913, depth_loss: 36.87 lr: 5.46875e-05, loss: 7.0915\n",
      "Epoch [8][10/100], loss_cls: 2.2413, depth_loss: 36.083 lr: 5.46875e-05, loss: 7.3403\n",
      "Epoch [8][15/100], loss_cls: 2.2028, depth_loss: 15.207 lr: 5.46875e-05, loss: 7.9721\n",
      "Epoch [8][20/100], loss_cls: 4.5328, depth_loss: 64.276 lr: 5.46875e-05, loss: 13.406\n",
      "Epoch [8][25/100], loss_cls: 1.6822, depth_loss: 21.867 lr: 5.46875e-05, loss: 6.5833\n",
      "Epoch [8][30/100], loss_cls: 2.0631, depth_loss: 26.651 lr: 5.46875e-05, loss: 8.1265\n",
      "Epoch [8][35/100], loss_cls: 3.4424, depth_loss: 22.884 lr: 5.46875e-05, loss: 7.1929\n",
      "Epoch [8][40/100], loss_cls: 3.5903, depth_loss: 27.646 lr: 5.46875e-05, loss: 7.4948\n",
      "Epoch [8][45/100], loss_cls: 2.9259, depth_loss: 38.084 lr: 5.46875e-05, loss: 8.3719\n",
      "Epoch [8][50/100], loss_cls: 3.2942, depth_loss: 27.958 lr: 5.46875e-05, loss: 8.0653\n",
      "Epoch [8][55/100], loss_cls: 2.2889, depth_loss: 24.051 lr: 5.46875e-05, loss: 7.5134\n",
      "Epoch [8][60/100], loss_cls: 2.7717, depth_loss: 40.838 lr: 5.46875e-05, loss: 6.5937\n",
      "Epoch [8][65/100], loss_cls: 1.7754, depth_loss: 26.765 lr: 5.46875e-05, loss: 11.373\n",
      "Epoch [8][70/100], loss_cls: 2.5038, depth_loss: 28.588 lr: 5.46875e-05, loss: 7.005\n",
      "Epoch [8][75/100], loss_cls: 0.76226, depth_loss: 24.969 lr: 5.46875e-05, loss: 7.5918\n",
      "Epoch [8][80/100], loss_cls: 3.1717, depth_loss: 27.733 lr: 5.46875e-05, loss: 8.1424\n",
      "Epoch [8][85/100], loss_cls: 1.6354, depth_loss: 21.709 lr: 5.46875e-05, loss: 6.6565\n",
      "Epoch [8][90/100], loss_cls: 1.6752, depth_loss: 41.51 lr: 5.46875e-05, loss: 6.8627\n",
      "Epoch [8][95/100], loss_cls: 2.2457, depth_loss: 14.851 lr: 5.46875e-05, loss: 6.6089\n",
      "Epoch [8][100/100], loss_cls: 1.1414, depth_loss: 61.338 lr: 5.46875e-05, loss: 8.5413\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.2, top5_acc: 0.6, train_loss: 8.5413, val_loss: 6.5688\n",
      "Epoch [9][5/100], loss_cls: 1.921, depth_loss: 18.007 lr: 6.25000e-05, loss: 7.6889\n",
      "Epoch [9][10/100], loss_cls: 1.8688, depth_loss: 37.174 lr: 6.25000e-05, loss: 8.0084\n",
      "Epoch [9][15/100], loss_cls: 2.8567, depth_loss: 22.139 lr: 6.25000e-05, loss: 6.6815\n",
      "Epoch [9][20/100], loss_cls: 2.084, depth_loss: 22.827 lr: 6.25000e-05, loss: 6.4904\n",
      "Epoch [9][25/100], loss_cls: 2.8383, depth_loss: 43.807 lr: 6.25000e-05, loss: 6.3599\n",
      "Epoch [9][30/100], loss_cls: 2.7333, depth_loss: 18.503 lr: 6.25000e-05, loss: 8.0287\n",
      "Epoch [9][35/100], loss_cls: 1.3295, depth_loss: 42.631 lr: 6.25000e-05, loss: 8.9463\n",
      "Epoch [9][40/100], loss_cls: 3.5572, depth_loss: 28.747 lr: 6.25000e-05, loss: 6.526\n",
      "Epoch [9][45/100], loss_cls: 2.454, depth_loss: 37.452 lr: 6.25000e-05, loss: 7.9942\n",
      "Epoch [9][50/100], loss_cls: 2.1109, depth_loss: 31.695 lr: 6.25000e-05, loss: 7.1903\n",
      "Epoch [9][55/100], loss_cls: 4.2124, depth_loss: 35.34 lr: 6.25000e-05, loss: 7.2331\n",
      "Epoch [9][60/100], loss_cls: 2.6861, depth_loss: 17.654 lr: 6.25000e-05, loss: 7.2048\n",
      "Epoch [9][65/100], loss_cls: 2.2106, depth_loss: 18.959 lr: 6.25000e-05, loss: 8.3237\n",
      "Epoch [9][70/100], loss_cls: 3.3715, depth_loss: 30.977 lr: 6.25000e-05, loss: 6.7117\n",
      "Epoch [9][75/100], loss_cls: 3.2092, depth_loss: 19.052 lr: 6.25000e-05, loss: 7.031\n",
      "Epoch [9][80/100], loss_cls: 2.7601, depth_loss: 28.07 lr: 6.25000e-05, loss: 8.0651\n",
      "Epoch [9][85/100], loss_cls: 1.5361, depth_loss: 29.599 lr: 6.25000e-05, loss: 6.6463\n",
      "Epoch [9][90/100], loss_cls: 0.91249, depth_loss: 17.239 lr: 6.25000e-05, loss: 5.1481\n",
      "Epoch [9][95/100], loss_cls: 1.3834, depth_loss: 25.967 lr: 6.25000e-05, loss: 5.7376\n",
      "Epoch [9][100/100], loss_cls: 2.8594, depth_loss: 16.209 lr: 6.25000e-05, loss: 6.8287\n",
      "Evaluating top_k_accuracy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1_acc: 0.1429, top5_acc: 0.4857, train_loss: 6.8287, val_loss: 5.8968\n",
      "Saving checkpoint at 9 epochs...\n",
      "Epoch [10][5/100], loss_cls: 1.5058, depth_loss: 24.909 lr: 7.03125e-05, loss: 5.9367\n",
      "Epoch [10][10/100], loss_cls: 1.5175, depth_loss: 29.17 lr: 7.03125e-05, loss: 6.1134\n",
      "Epoch [10][15/100], loss_cls: 2.2007, depth_loss: 33.926 lr: 7.03125e-05, loss: 7.8609\n",
      "Epoch [10][20/100], loss_cls: 2.9843, depth_loss: 15.989 lr: 7.03125e-05, loss: 7.2094\n",
      "Epoch [10][25/100], loss_cls: 2.7221, depth_loss: 39.553 lr: 7.03125e-05, loss: 6.7311\n",
      "Epoch [10][30/100], loss_cls: 2.4088, depth_loss: 17.656 lr: 7.03125e-05, loss: 5.8487\n",
      "Epoch [10][35/100], loss_cls: 3.2663, depth_loss: 26.673 lr: 7.03125e-05, loss: 8.4801\n",
      "Epoch [10][40/100], loss_cls: 1.906, depth_loss: 24.622 lr: 7.03125e-05, loss: 6.7431\n",
      "Epoch [10][45/100], loss_cls: 2.8371, depth_loss: 23.992 lr: 7.03125e-05, loss: 6.9391\n",
      "Epoch [10][50/100], loss_cls: 0.71914, depth_loss: 23.455 lr: 7.03125e-05, loss: 6.2521\n",
      "Epoch [10][55/100], loss_cls: 1.8622, depth_loss: 21.121 lr: 7.03125e-05, loss: 5.8668\n",
      "Epoch [10][60/100], loss_cls: 2.6619, depth_loss: 16.001 lr: 7.03125e-05, loss: 7.0954\n",
      "Epoch [10][65/100], loss_cls: 1.4912, depth_loss: 29.569 lr: 7.03125e-05, loss: 5.974\n",
      "Epoch [10][70/100], loss_cls: 2.2775, depth_loss: 16.163 lr: 7.03125e-05, loss: 5.8504\n",
      "Epoch [10][75/100], loss_cls: 2.9528, depth_loss: 49.978 lr: 7.03125e-05, loss: 8.4997\n",
      "Epoch [10][80/100], loss_cls: 2.2388, depth_loss: 29.142 lr: 7.03125e-05, loss: 7.5658\n",
      "Epoch [10][85/100], loss_cls: 2.5477, depth_loss: 29.529 lr: 7.03125e-05, loss: 7.2972\n",
      "Epoch [10][90/100], loss_cls: 2.2542, depth_loss: 18.439 lr: 7.03125e-05, loss: 6.6841\n",
      "Epoch [10][95/100], loss_cls: 2.0069, depth_loss: 22.086 lr: 7.03125e-05, loss: 6.1472\n",
      "Epoch [10][100/100], loss_cls: 1.6595, depth_loss: 22.188 lr: 7.03125e-05, loss: 6.6233\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.2571, top5_acc: 0.8286, train_loss: 6.6233, val_loss: 5.4127\n",
      "Saving checkpoint at 10 epochs...\n",
      "Epoch [11][5/100], loss_cls: 2.5208, depth_loss: 26.151 lr: 7.81250e-05, loss: 6.4494\n",
      "Epoch [11][10/100], loss_cls: 2.71, depth_loss: 14.286 lr: 7.81250e-05, loss: 7.6396\n",
      "Epoch [11][15/100], loss_cls: 2.3834, depth_loss: 26.148 lr: 7.81250e-05, loss: 6.4852\n",
      "Epoch [11][20/100], loss_cls: 2.7408, depth_loss: 16.771 lr: 7.81250e-05, loss: 5.6499\n",
      "Epoch [11][25/100], loss_cls: 2.7396, depth_loss: 15.662 lr: 7.81250e-05, loss: 7.9624\n",
      "Epoch [11][30/100], loss_cls: 2.2971, depth_loss: 43.478 lr: 7.81250e-05, loss: 12.206\n",
      "Epoch [11][35/100], loss_cls: 2.3388, depth_loss: 44.273 lr: 7.81250e-05, loss: 7.4349\n",
      "Epoch [11][40/100], loss_cls: 2.1897, depth_loss: 31.352 lr: 7.81250e-05, loss: 6.4708\n",
      "Epoch [11][45/100], loss_cls: 2.4252, depth_loss: 27.052 lr: 7.81250e-05, loss: 5.9047\n",
      "Epoch [11][50/100], loss_cls: 1.9587, depth_loss: 20.856 lr: 7.81250e-05, loss: 5.5791\n",
      "Epoch [11][55/100], loss_cls: 2.9637, depth_loss: 22.325 lr: 7.81250e-05, loss: 6.4017\n",
      "Epoch [11][60/100], loss_cls: 2.0258, depth_loss: 14.613 lr: 7.81250e-05, loss: 6.417\n",
      "Epoch [11][65/100], loss_cls: 1.3779, depth_loss: 14.142 lr: 7.81250e-05, loss: 5.8157\n",
      "Epoch [11][70/100], loss_cls: 1.8216, depth_loss: 27.607 lr: 7.81250e-05, loss: 7.766\n",
      "Epoch [11][75/100], loss_cls: 0.76415, depth_loss: 17.165 lr: 7.81250e-05, loss: 5.7749\n",
      "Epoch [11][80/100], loss_cls: 2.5696, depth_loss: 17.667 lr: 7.81250e-05, loss: 5.9452\n",
      "Epoch [11][85/100], loss_cls: 3.1098, depth_loss: 18.823 lr: 7.81250e-05, loss: 8.7695\n",
      "Epoch [11][90/100], loss_cls: 1.8714, depth_loss: 18.6 lr: 7.81250e-05, loss: 5.9587\n",
      "Epoch [11][95/100], loss_cls: 2.8752, depth_loss: 19.172 lr: 7.81250e-05, loss: 6.0748\n",
      "Epoch [11][100/100], loss_cls: 2.0395, depth_loss: 39.969 lr: 7.81250e-05, loss: 7.0462\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.2571, top5_acc: 0.8286, train_loss: 7.0462, val_loss: 5.0602\n",
      "Saving checkpoint at 11 epochs...\n",
      "Epoch [12][5/100], loss_cls: 1.4269, depth_loss: 33.853 lr: 8.59375e-05, loss: 6.5349\n",
      "Epoch [12][10/100], loss_cls: 1.1014, depth_loss: 23.641 lr: 8.59375e-05, loss: 6.3048\n",
      "Epoch [12][15/100], loss_cls: 1.7181, depth_loss: 30.531 lr: 8.59375e-05, loss: 6.1502\n",
      "Epoch [12][20/100], loss_cls: 0.87441, depth_loss: 14.172 lr: 8.59375e-05, loss: 5.6227\n",
      "Epoch [12][25/100], loss_cls: 3.621, depth_loss: 18.384 lr: 8.59375e-05, loss: 6.7899\n",
      "Epoch [12][30/100], loss_cls: 1.3339, depth_loss: 13.669 lr: 8.59375e-05, loss: 6.6993\n",
      "Epoch [12][35/100], loss_cls: 2.065, depth_loss: 40.22 lr: 8.59375e-05, loss: 7.8441\n",
      "Epoch [12][40/100], loss_cls: 2.7416, depth_loss: 15.317 lr: 8.59375e-05, loss: 4.8312\n",
      "Epoch [12][45/100], loss_cls: 1.6954, depth_loss: 14.108 lr: 8.59375e-05, loss: 4.9924\n",
      "Epoch [12][50/100], loss_cls: 1.4071, depth_loss: 20.344 lr: 8.59375e-05, loss: 6.7356\n",
      "Epoch [12][55/100], loss_cls: 1.921, depth_loss: 29.118 lr: 8.59375e-05, loss: 6.9231\n",
      "Epoch [12][60/100], loss_cls: 1.5158, depth_loss: 29.83 lr: 8.59375e-05, loss: 6.9888\n",
      "Epoch [12][65/100], loss_cls: 2.7592, depth_loss: 14.591 lr: 8.59375e-05, loss: 6.3608\n",
      "Epoch [12][70/100], loss_cls: 2.5854, depth_loss: 27.721 lr: 8.59375e-05, loss: 6.7232\n",
      "Epoch [12][75/100], loss_cls: 1.9182, depth_loss: 14.736 lr: 8.59375e-05, loss: 5.9656\n",
      "Epoch [12][80/100], loss_cls: 3.1598, depth_loss: 23.36 lr: 8.59375e-05, loss: 5.9315\n",
      "Epoch [12][85/100], loss_cls: 1.4413, depth_loss: 56.054 lr: 8.59375e-05, loss: 7.7603\n",
      "Epoch [12][90/100], loss_cls: 0.96233, depth_loss: 15.92 lr: 8.59375e-05, loss: 4.6462\n",
      "Epoch [12][95/100], loss_cls: 2.5729, depth_loss: 25.518 lr: 8.59375e-05, loss: 7.0808\n",
      "Epoch [12][100/100], loss_cls: 1.2358, depth_loss: 17.236 lr: 8.59375e-05, loss: 5.4248\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.2571, top5_acc: 0.8286, train_loss: 5.4248, val_loss: 4.8008\n",
      "Saving checkpoint at 12 epochs...\n",
      "Epoch [13][5/100], loss_cls: 2.5544, depth_loss: 21.839 lr: 9.37500e-05, loss: 6.5506\n",
      "Epoch [13][10/100], loss_cls: 0.6469, depth_loss: 37.272 lr: 9.37500e-05, loss: 6.6272\n",
      "Epoch [13][15/100], loss_cls: 2.186, depth_loss: 13.849 lr: 9.37500e-05, loss: 5.1414\n",
      "Epoch [13][20/100], loss_cls: 1.1847, depth_loss: 34.064 lr: 9.37500e-05, loss: 8.1242\n",
      "Epoch [13][25/100], loss_cls: 0.80836, depth_loss: 22.209 lr: 9.37500e-05, loss: 5.9007\n",
      "Epoch [13][30/100], loss_cls: 1.3532, depth_loss: 36.038 lr: 9.37500e-05, loss: 6.7801\n",
      "Epoch [13][35/100], loss_cls: 2.0813, depth_loss: 16.83 lr: 9.37500e-05, loss: 5.2683\n",
      "Epoch [13][40/100], loss_cls: 0.76104, depth_loss: 18.222 lr: 9.37500e-05, loss: 6.3522\n",
      "Epoch [13][45/100], loss_cls: 2.5036, depth_loss: 25.915 lr: 9.37500e-05, loss: 6.1998\n",
      "Epoch [13][50/100], loss_cls: 1.9762, depth_loss: 16.726 lr: 9.37500e-05, loss: 5.637\n",
      "Epoch [13][55/100], loss_cls: 0.30655, depth_loss: 15.077 lr: 9.37500e-05, loss: 6.2871\n",
      "Epoch [13][60/100], loss_cls: 0.74196, depth_loss: 13.703 lr: 9.37500e-05, loss: 5.4239\n",
      "Epoch [13][65/100], loss_cls: 2.7626, depth_loss: 38.909 lr: 9.37500e-05, loss: 6.9449\n",
      "Epoch [13][70/100], loss_cls: 1.0166, depth_loss: 23.7 lr: 9.37500e-05, loss: 6.4169\n",
      "Epoch [13][75/100], loss_cls: 1.1237, depth_loss: 19.57 lr: 9.37500e-05, loss: 6.7065\n",
      "Epoch [13][80/100], loss_cls: 0.15656, depth_loss: 12.298 lr: 9.37500e-05, loss: 4.0728\n",
      "Epoch [13][85/100], loss_cls: 3.2608, depth_loss: 24.611 lr: 9.37500e-05, loss: 7.8206\n",
      "Epoch [13][90/100], loss_cls: 0.5719, depth_loss: 31.562 lr: 9.37500e-05, loss: 7.098\n",
      "Epoch [13][95/100], loss_cls: 1.702, depth_loss: 19.022 lr: 9.37500e-05, loss: 7.2337\n",
      "Epoch [13][100/100], loss_cls: 1.3507, depth_loss: 20.361 lr: 9.37500e-05, loss: 5.4324\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.3143, top5_acc: 0.8286, train_loss: 5.4324, val_loss: 5.4926\n",
      "Epoch [14][5/100], loss_cls: 2.5587, depth_loss: 14.625 lr: 1.01563e-04, loss: 4.825\n",
      "Epoch [14][10/100], loss_cls: 2.2545, depth_loss: 13.977 lr: 1.01563e-04, loss: 5.5316\n",
      "Epoch [14][15/100], loss_cls: 1.3259, depth_loss: 28.107 lr: 1.01563e-04, loss: 5.4918\n",
      "Epoch [14][20/100], loss_cls: 2.145, depth_loss: 13.921 lr: 1.01563e-04, loss: 5.504\n",
      "Epoch [14][25/100], loss_cls: 2.5104, depth_loss: 36.829 lr: 1.01563e-04, loss: 8.4679\n",
      "Epoch [14][30/100], loss_cls: 2.1792, depth_loss: 14.611 lr: 1.01563e-04, loss: 5.727\n",
      "Epoch [14][35/100], loss_cls: 2.3637, depth_loss: 16.821 lr: 1.01563e-04, loss: 6.0649\n",
      "Epoch [14][40/100], loss_cls: 0.79562, depth_loss: 18.936 lr: 1.01563e-04, loss: 5.8713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14][45/100], loss_cls: 1.6939, depth_loss: 11.77 lr: 1.01563e-04, loss: 6.3929\n",
      "Epoch [14][50/100], loss_cls: 3.3997, depth_loss: 31.633 lr: 1.01563e-04, loss: 6.9439\n",
      "Epoch [14][55/100], loss_cls: 2.132, depth_loss: 14.638 lr: 1.01563e-04, loss: 6.5775\n",
      "Epoch [14][60/100], loss_cls: 1.5259, depth_loss: 55.927 lr: 1.01563e-04, loss: 7.6575\n",
      "Epoch [14][65/100], loss_cls: 0.0015866, depth_loss: 19.757 lr: 1.01563e-04, loss: 5.9938\n",
      "Epoch [14][70/100], loss_cls: 4.3467, depth_loss: 11.743 lr: 1.01563e-04, loss: 5.0883\n",
      "Epoch [14][75/100], loss_cls: 4.1739, depth_loss: 26.133 lr: 1.01563e-04, loss: 8.1704\n",
      "Epoch [14][80/100], loss_cls: 1.5411, depth_loss: 41.423 lr: 1.01563e-04, loss: 5.7956\n",
      "Epoch [14][85/100], loss_cls: 2.4287, depth_loss: 43.748 lr: 1.01563e-04, loss: 9.3122\n",
      "Epoch [14][90/100], loss_cls: 1.0251, depth_loss: 27.085 lr: 1.01563e-04, loss: 5.0756\n",
      "Epoch [14][95/100], loss_cls: 5.7041, depth_loss: 34.195 lr: 1.01563e-04, loss: 7.5132\n",
      "Epoch [14][100/100], loss_cls: 1.5301, depth_loss: 21.448 lr: 1.01563e-04, loss: 5.6421\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.4286, top5_acc: 0.9429, train_loss: 5.6421, val_loss: 4.5286\n",
      "Saving checkpoint at 14 epochs...\n",
      "Epoch [15][5/100], loss_cls: 2.2391, depth_loss: 25.534 lr: 1.09375e-04, loss: 4.3799\n",
      "Epoch [15][10/100], loss_cls: 4.5851, depth_loss: 20.913 lr: 1.09375e-04, loss: 6.596\n",
      "Epoch [15][15/100], loss_cls: 1.6423, depth_loss: 17.129 lr: 1.09375e-04, loss: 6.9236\n",
      "Epoch [15][20/100], loss_cls: 1.4264, depth_loss: 11.684 lr: 1.09375e-04, loss: 5.7071\n",
      "Epoch [15][25/100], loss_cls: 3.4343, depth_loss: 28.533 lr: 1.09375e-04, loss: 5.9431\n",
      "Epoch [15][30/100], loss_cls: 2.4837, depth_loss: 17.084 lr: 1.09375e-04, loss: 8.1579\n",
      "Epoch [15][35/100], loss_cls: 1.9816, depth_loss: 16.71 lr: 1.09375e-04, loss: 5.8521\n",
      "Epoch [15][40/100], loss_cls: 1.6052, depth_loss: 39.416 lr: 1.09375e-04, loss: 6.9204\n",
      "Epoch [15][45/100], loss_cls: 3.5076, depth_loss: 17.089 lr: 1.09375e-04, loss: 6.0693\n",
      "Epoch [15][50/100], loss_cls: 1.8366, depth_loss: 23.065 lr: 1.09375e-04, loss: 7.0763\n",
      "Epoch [15][55/100], loss_cls: 0.92423, depth_loss: 14.988 lr: 1.09375e-04, loss: 5.855\n",
      "Epoch [15][60/100], loss_cls: 1.2124, depth_loss: 15.097 lr: 1.09375e-04, loss: 4.3071\n",
      "Epoch [15][65/100], loss_cls: 2.9307, depth_loss: 17.892 lr: 1.09375e-04, loss: 7.1517\n",
      "Epoch [15][70/100], loss_cls: 1.3168, depth_loss: 45.326 lr: 1.09375e-04, loss: 6.5704\n",
      "Epoch [15][75/100], loss_cls: 0.30856, depth_loss: 16.733 lr: 1.09375e-04, loss: 3.9509\n",
      "Epoch [15][80/100], loss_cls: 1.5782, depth_loss: 19.228 lr: 1.09375e-04, loss: 6.2241\n",
      "Epoch [15][85/100], loss_cls: 1.678, depth_loss: 36.34 lr: 1.09375e-04, loss: 6.4257\n",
      "Epoch [15][90/100], loss_cls: 3.0269, depth_loss: 17.445 lr: 1.09375e-04, loss: 5.8121\n",
      "Epoch [15][95/100], loss_cls: 1.9708, depth_loss: 42.803 lr: 1.09375e-04, loss: 7.399\n",
      "Epoch [15][100/100], loss_cls: 1.9271, depth_loss: 17.569 lr: 1.09375e-04, loss: 6.7008\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.4, top5_acc: 0.8857, train_loss: 6.7008, val_loss: 4.3979\n",
      "Saving checkpoint at 15 epochs...\n",
      "Epoch [16][5/100], loss_cls: 1.8054, depth_loss: 18.271 lr: 1.17187e-04, loss: 5.8721\n",
      "Epoch [16][10/100], loss_cls: 1.6494, depth_loss: 12.836 lr: 1.17187e-04, loss: 5.644\n",
      "Epoch [16][15/100], loss_cls: 2.2368, depth_loss: 17.592 lr: 1.17187e-04, loss: 4.7016\n",
      "Epoch [16][20/100], loss_cls: 2.3434, depth_loss: 16.029 lr: 1.17187e-04, loss: 6.0825\n",
      "Epoch [16][25/100], loss_cls: 2.2738, depth_loss: 13.506 lr: 1.17187e-04, loss: 5.1696\n",
      "Epoch [16][30/100], loss_cls: 0.68946, depth_loss: 27.432 lr: 1.17187e-04, loss: 6.1833\n",
      "Epoch [16][35/100], loss_cls: 0.37484, depth_loss: 11.666 lr: 1.17187e-04, loss: 5.3439\n",
      "Epoch [16][40/100], loss_cls: 1.9497, depth_loss: 11.211 lr: 1.17187e-04, loss: 8.5714\n",
      "Epoch [16][45/100], loss_cls: 0.53609, depth_loss: 13.904 lr: 1.17187e-04, loss: 6.5811\n",
      "Epoch [16][50/100], loss_cls: 2.0321, depth_loss: 19.626 lr: 1.17187e-04, loss: 5.7383\n",
      "Epoch [16][55/100], loss_cls: 1.2056, depth_loss: 18.124 lr: 1.17187e-04, loss: 4.5038\n",
      "Epoch [16][60/100], loss_cls: 1.6881, depth_loss: 18.119 lr: 1.17187e-04, loss: 4.7388\n",
      "Epoch [16][65/100], loss_cls: 2.4463, depth_loss: 11.086 lr: 1.17187e-04, loss: 5.643\n",
      "Epoch [16][70/100], loss_cls: 2.2525, depth_loss: 12.196 lr: 1.17187e-04, loss: 5.1611\n",
      "Epoch [16][75/100], loss_cls: 1.2143, depth_loss: 13.077 lr: 1.17187e-04, loss: 5.8662\n",
      "Epoch [16][80/100], loss_cls: 0.87143, depth_loss: 13.025 lr: 1.17187e-04, loss: 5.8427\n",
      "Epoch [16][85/100], loss_cls: 1.8419, depth_loss: 15.816 lr: 1.17187e-04, loss: 5.0581\n",
      "Epoch [16][90/100], loss_cls: 0.27571, depth_loss: 19.061 lr: 1.17187e-04, loss: 5.8783\n",
      "Epoch [16][95/100], loss_cls: 4.1487, depth_loss: 32.475 lr: 1.17187e-04, loss: 6.0582\n",
      "Epoch [16][100/100], loss_cls: 0.037552, depth_loss: 16.485 lr: 1.17187e-04, loss: 5.5852\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.5143, top5_acc: 0.8571, train_loss: 5.5852, val_loss: 4.2188\n",
      "Saving checkpoint at 16 epochs...\n",
      "Epoch [17][5/100], loss_cls: 1.3873, depth_loss: 36.957 lr: 1.25000e-04, loss: 6.2463\n",
      "Epoch [17][10/100], loss_cls: 0.29787, depth_loss: 24.31 lr: 1.25000e-04, loss: 6.137\n",
      "Epoch [17][15/100], loss_cls: 0.39415, depth_loss: 26.243 lr: 1.25000e-04, loss: 4.767\n",
      "Epoch [17][20/100], loss_cls: 0.55864, depth_loss: 20.245 lr: 1.25000e-04, loss: 6.5836\n",
      "Epoch [17][25/100], loss_cls: 2.2499, depth_loss: 18.872 lr: 1.25000e-04, loss: 5.5347\n",
      "Epoch [17][30/100], loss_cls: 0.52511, depth_loss: 23.792 lr: 1.25000e-04, loss: 5.2014\n",
      "Epoch [17][35/100], loss_cls: 0.71416, depth_loss: 37.226 lr: 1.25000e-04, loss: 5.3975\n",
      "Epoch [17][40/100], loss_cls: 2.3334, depth_loss: 17.967 lr: 1.25000e-04, loss: 6.4117\n",
      "Epoch [17][45/100], loss_cls: 3.503, depth_loss: 76.695 lr: 1.25000e-04, loss: 8.6451\n",
      "Epoch [17][50/100], loss_cls: 1.752, depth_loss: 25.913 lr: 1.25000e-04, loss: 6.0113\n",
      "Epoch [17][55/100], loss_cls: 1.0406, depth_loss: 12.643 lr: 1.25000e-04, loss: 6.9423\n",
      "Epoch [17][60/100], loss_cls: 1.9079, depth_loss: 39.93 lr: 1.25000e-04, loss: 9.6397\n",
      "Epoch [17][65/100], loss_cls: 2.2152, depth_loss: 23.182 lr: 1.25000e-04, loss: 5.5563\n",
      "Epoch [17][70/100], loss_cls: 1.3305, depth_loss: 22.131 lr: 1.25000e-04, loss: 5.2507\n",
      "Epoch [17][75/100], loss_cls: 2.2058, depth_loss: 41.083 lr: 1.25000e-04, loss: 6.4822\n",
      "Epoch [17][80/100], loss_cls: 1.5541, depth_loss: 29.443 lr: 1.25000e-04, loss: 4.9089\n",
      "Epoch [17][85/100], loss_cls: 0.7791, depth_loss: 33.797 lr: 1.25000e-04, loss: 6.2666\n",
      "Epoch [17][90/100], loss_cls: 2.4931, depth_loss: 20.961 lr: 1.25000e-04, loss: 5.469\n",
      "Epoch [17][95/100], loss_cls: 1.3123, depth_loss: 16.675 lr: 1.25000e-04, loss: 5.076\n",
      "Epoch [17][100/100], loss_cls: 2.6357, depth_loss: 20.626 lr: 1.25000e-04, loss: 5.9725\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.2857, top5_acc: 0.8286, train_loss: 5.9725, val_loss: 5.2305\n",
      "Epoch [18][5/100], loss_cls: 1.1323, depth_loss: 12.314 lr: 1.25000e-04, loss: 4.564\n",
      "Epoch [18][10/100], loss_cls: 0.9673, depth_loss: 8.1346 lr: 1.25000e-04, loss: 6.1784\n",
      "Epoch [18][15/100], loss_cls: 0.57234, depth_loss: 10.759 lr: 1.25000e-04, loss: 4.6748\n",
      "Epoch [18][20/100], loss_cls: 2.5948, depth_loss: 18.675 lr: 1.25000e-04, loss: 5.3037\n",
      "Epoch [18][25/100], loss_cls: 2.0098, depth_loss: 10.981 lr: 1.25000e-04, loss: 5.8612\n",
      "Epoch [18][30/100], loss_cls: 0.58735, depth_loss: 41.516 lr: 1.25000e-04, loss: 5.256\n",
      "Epoch [18][35/100], loss_cls: 3.102, depth_loss: 14.229 lr: 1.25000e-04, loss: 4.1318\n",
      "Epoch [18][40/100], loss_cls: 0.0043237, depth_loss: 27.22 lr: 1.25000e-04, loss: 6.9404\n",
      "Epoch [18][45/100], loss_cls: 0.51185, depth_loss: 29.194 lr: 1.25000e-04, loss: 6.0356\n",
      "Epoch [18][50/100], loss_cls: 3.8377, depth_loss: 13.392 lr: 1.25000e-04, loss: 4.4897\n",
      "Epoch [18][55/100], loss_cls: 1.3322, depth_loss: 30.168 lr: 1.25000e-04, loss: 5.3059\n",
      "Epoch [18][60/100], loss_cls: 2.2436, depth_loss: 21.505 lr: 1.25000e-04, loss: 4.856\n",
      "Epoch [18][65/100], loss_cls: 0.99498, depth_loss: 24.127 lr: 1.25000e-04, loss: 6.2117\n",
      "Epoch [18][70/100], loss_cls: 1.7281, depth_loss: 11.071 lr: 1.25000e-04, loss: 5.7597\n",
      "Epoch [18][75/100], loss_cls: 2.4515, depth_loss: 17.704 lr: 1.25000e-04, loss: 4.1296\n",
      "Epoch [18][80/100], loss_cls: 1.9002, depth_loss: 23.4 lr: 1.25000e-04, loss: 6.1395\n",
      "Epoch [18][85/100], loss_cls: 0.13382, depth_loss: 26.355 lr: 1.25000e-04, loss: 4.7354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18][90/100], loss_cls: 4.7135, depth_loss: 31.027 lr: 1.25000e-04, loss: 7.9469\n",
      "Epoch [18][95/100], loss_cls: 2.9992, depth_loss: 18.535 lr: 1.25000e-04, loss: 5.8633\n",
      "Epoch [18][100/100], loss_cls: 3.1691, depth_loss: 41.909 lr: 1.25000e-04, loss: 7.4427\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.3714, top5_acc: 0.9143, train_loss: 7.4427, val_loss: 4.7797\n",
      "Epoch [19][5/100], loss_cls: 3.8984, depth_loss: 19.905 lr: 1.25000e-04, loss: 6.2731\n",
      "Epoch [19][10/100], loss_cls: 2.4005, depth_loss: 17.954 lr: 1.25000e-04, loss: 4.8124\n",
      "Epoch [19][15/100], loss_cls: 0.0080468, depth_loss: 36.803 lr: 1.25000e-04, loss: 4.9173\n",
      "Epoch [19][20/100], loss_cls: 2.0369, depth_loss: 17.396 lr: 1.25000e-04, loss: 5.9393\n",
      "Epoch [19][25/100], loss_cls: 1.3523, depth_loss: 27.371 lr: 1.25000e-04, loss: 4.1416\n",
      "Epoch [19][30/100], loss_cls: 2.2661, depth_loss: 10.254 lr: 1.25000e-04, loss: 4.7529\n",
      "Epoch [19][35/100], loss_cls: 2.0465, depth_loss: 67.635 lr: 1.25000e-04, loss: 7.8822\n",
      "Epoch [19][40/100], loss_cls: 2.1941, depth_loss: 12.821 lr: 1.25000e-04, loss: 5.1631\n",
      "Epoch [19][45/100], loss_cls: 0.50998, depth_loss: 23.835 lr: 1.25000e-04, loss: 4.5933\n",
      "Epoch [19][50/100], loss_cls: 2.7518, depth_loss: 21.699 lr: 1.25000e-04, loss: 5.349\n",
      "Epoch [19][55/100], loss_cls: 3.4275, depth_loss: 13.924 lr: 1.25000e-04, loss: 4.7883\n",
      "Epoch [19][60/100], loss_cls: 2.3339, depth_loss: 29.061 lr: 1.25000e-04, loss: 6.0502\n",
      "Epoch [19][65/100], loss_cls: 3.6331, depth_loss: 41.894 lr: 1.25000e-04, loss: 6.4364\n",
      "Epoch [19][70/100], loss_cls: 0.83118, depth_loss: 8.5727 lr: 1.25000e-04, loss: 4.1698\n",
      "Epoch [19][75/100], loss_cls: 3.4655, depth_loss: 32.12 lr: 1.25000e-04, loss: 7.0813\n",
      "Epoch [19][80/100], loss_cls: 1.1262, depth_loss: 13.714 lr: 1.25000e-04, loss: 5.5814\n",
      "Epoch [19][85/100], loss_cls: 1.5633, depth_loss: 48.557 lr: 1.25000e-04, loss: 5.2743\n",
      "Epoch [19][90/100], loss_cls: 1.2606, depth_loss: 16.975 lr: 1.25000e-04, loss: 7.2673\n",
      "Epoch [19][95/100], loss_cls: 4.3192, depth_loss: 17.04 lr: 1.25000e-04, loss: 5.0489\n",
      "Epoch [19][100/100], loss_cls: 0.17316, depth_loss: 20.251 lr: 1.25000e-04, loss: 5.4712\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.4571, top5_acc: 0.8857, train_loss: 5.4712, val_loss: 4.7204\n",
      "Epoch [20][5/100], loss_cls: 0.54966, depth_loss: 14.453 lr: 1.25000e-04, loss: 5.8446\n",
      "Epoch [20][10/100], loss_cls: 2.4196, depth_loss: 48.693 lr: 1.25000e-04, loss: 8.5963\n",
      "Epoch [20][15/100], loss_cls: 1.4815, depth_loss: 20.117 lr: 1.25000e-04, loss: 3.6256\n",
      "Epoch [20][20/100], loss_cls: 0.37803, depth_loss: 9.9205 lr: 1.25000e-04, loss: 4.4216\n",
      "Epoch [20][25/100], loss_cls: 0.51758, depth_loss: 25.753 lr: 1.25000e-04, loss: 4.4795\n",
      "Epoch [20][30/100], loss_cls: 2.2991, depth_loss: 44.847 lr: 1.25000e-04, loss: 7.6501\n",
      "Epoch [20][35/100], loss_cls: 0.0017421, depth_loss: 16.362 lr: 1.25000e-04, loss: 5.7992\n",
      "Epoch [20][40/100], loss_cls: 0.69893, depth_loss: 15.814 lr: 1.25000e-04, loss: 6.3807\n",
      "Epoch [20][45/100], loss_cls: 1.0551, depth_loss: 8.9158 lr: 1.25000e-04, loss: 4.1794\n",
      "Epoch [20][50/100], loss_cls: 0.0066409, depth_loss: 14.45 lr: 1.25000e-04, loss: 4.2088\n",
      "Epoch [20][55/100], loss_cls: 1.1219, depth_loss: 27.116 lr: 1.25000e-04, loss: 6.0696\n",
      "Epoch [20][60/100], loss_cls: 2.9737, depth_loss: 19.251 lr: 1.25000e-04, loss: 6.4905\n",
      "Epoch [20][65/100], loss_cls: 0.013426, depth_loss: 23.255 lr: 1.25000e-04, loss: 4.4849\n",
      "Epoch [20][70/100], loss_cls: 0.9737, depth_loss: 19.592 lr: 1.25000e-04, loss: 6.0538\n",
      "Epoch [20][75/100], loss_cls: 1.0553, depth_loss: 13.493 lr: 1.25000e-04, loss: 4.3806\n",
      "Epoch [20][80/100], loss_cls: 2.3754, depth_loss: 20.052 lr: 1.25000e-04, loss: 7.2717\n",
      "Epoch [20][85/100], loss_cls: 2.0799, depth_loss: 10.537 lr: 1.25000e-04, loss: 4.8515\n",
      "Epoch [20][90/100], loss_cls: 0.40874, depth_loss: 14.912 lr: 1.25000e-04, loss: 6.2767\n",
      "Epoch [20][95/100], loss_cls: 0.8572, depth_loss: 37.215 lr: 1.25000e-04, loss: 6.1346\n",
      "Epoch [20][100/100], loss_cls: 0.11947, depth_loss: 29.874 lr: 1.25000e-04, loss: 5.7236\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.5429, top5_acc: 0.9429, train_loss: 5.7236, val_loss: 4.3697\n",
      "Epoch [21][5/100], loss_cls: 3.1573, depth_loss: 20.697 lr: 1.25000e-04, loss: 5.6688\n",
      "Epoch [21][10/100], loss_cls: 1.5537, depth_loss: 9.2746 lr: 1.25000e-04, loss: 4.9471\n",
      "Epoch [21][15/100], loss_cls: 0.912, depth_loss: 11.89 lr: 1.25000e-04, loss: 3.5186\n",
      "Epoch [21][20/100], loss_cls: 2.0097, depth_loss: 21.091 lr: 1.25000e-04, loss: 4.4927\n",
      "Epoch [21][25/100], loss_cls: 0.125, depth_loss: 23.115 lr: 1.25000e-04, loss: 5.4274\n",
      "Epoch [21][30/100], loss_cls: 1.2474, depth_loss: 16.285 lr: 1.25000e-04, loss: 4.2273\n",
      "Epoch [21][35/100], loss_cls: 1.8147, depth_loss: 19.6 lr: 1.25000e-04, loss: 5.1363\n",
      "Epoch [21][40/100], loss_cls: 2.0082, depth_loss: 89.811 lr: 1.25000e-04, loss: 7.1001\n",
      "Epoch [21][45/100], loss_cls: 3.9129, depth_loss: 16.304 lr: 1.25000e-04, loss: 6.5306\n",
      "Epoch [21][50/100], loss_cls: 2.1807, depth_loss: 15.966 lr: 1.25000e-04, loss: 4.6085\n",
      "Epoch [21][55/100], loss_cls: 1.7652, depth_loss: 17.548 lr: 1.25000e-04, loss: 5.0629\n",
      "Epoch [21][60/100], loss_cls: 1.7127, depth_loss: 14.626 lr: 1.25000e-04, loss: 5.4229\n",
      "Epoch [21][65/100], loss_cls: 2.3003, depth_loss: 12.466 lr: 1.25000e-04, loss: 5.6555\n",
      "Epoch [21][70/100], loss_cls: 0.10311, depth_loss: 13.3 lr: 1.25000e-04, loss: 5.927\n",
      "Epoch [21][75/100], loss_cls: 0.48338, depth_loss: 20.943 lr: 1.25000e-04, loss: 4.8998\n",
      "Epoch [21][80/100], loss_cls: 0.044044, depth_loss: 18.144 lr: 1.25000e-04, loss: 4.2377\n",
      "Epoch [21][85/100], loss_cls: 1.7816, depth_loss: 20.134 lr: 1.25000e-04, loss: 4.7653\n",
      "Epoch [21][90/100], loss_cls: 1.3808, depth_loss: 18.233 lr: 1.25000e-04, loss: 6.2599\n",
      "Epoch [21][95/100], loss_cls: 0.38169, depth_loss: 30.177 lr: 1.25000e-04, loss: 5.5848\n",
      "Epoch [21][100/100], loss_cls: 0.72858, depth_loss: 10.406 lr: 1.25000e-04, loss: 5.5219\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.4571, top5_acc: 0.9714, train_loss: 5.5219, val_loss: 4.2815\n",
      "Epoch [22][5/100], loss_cls: 0.96803, depth_loss: 22.782 lr: 1.25000e-04, loss: 3.9191\n",
      "Epoch [22][10/100], loss_cls: 1.1609, depth_loss: 8.8472 lr: 1.25000e-04, loss: 4.842\n",
      "Epoch [22][15/100], loss_cls: 0.00034733, depth_loss: 13.16 lr: 1.25000e-04, loss: 4.7704\n",
      "Epoch [22][20/100], loss_cls: 0.33806, depth_loss: 26.307 lr: 1.25000e-04, loss: 4.2192\n",
      "Epoch [22][25/100], loss_cls: 2.7564, depth_loss: 15.861 lr: 1.25000e-04, loss: 5.2742\n",
      "Epoch [22][30/100], loss_cls: 3.0677, depth_loss: 19.431 lr: 1.25000e-04, loss: 5.6724\n",
      "Epoch [22][35/100], loss_cls: 1.3127, depth_loss: 36.167 lr: 1.25000e-04, loss: 5.1575\n",
      "Epoch [22][40/100], loss_cls: 0.11893, depth_loss: 20.942 lr: 1.25000e-04, loss: 6.0521\n",
      "Epoch [22][45/100], loss_cls: 1.0843, depth_loss: 20.152 lr: 1.25000e-04, loss: 3.9267\n",
      "Epoch [22][50/100], loss_cls: 1.9639, depth_loss: 48.355 lr: 1.25000e-04, loss: 5.6544\n",
      "Epoch [22][55/100], loss_cls: 5.3239, depth_loss: 11.708 lr: 1.25000e-04, loss: 6.0323\n",
      "Epoch [22][60/100], loss_cls: 1.8073, depth_loss: 21.944 lr: 1.25000e-04, loss: 4.5308\n",
      "Epoch [22][65/100], loss_cls: 1.5365, depth_loss: 8.2015 lr: 1.25000e-04, loss: 4.7964\n",
      "Epoch [22][70/100], loss_cls: 3.2431, depth_loss: 80.485 lr: 1.25000e-04, loss: 7.7978\n",
      "Epoch [22][75/100], loss_cls: 0.92667, depth_loss: 14.151 lr: 1.25000e-04, loss: 5.594\n",
      "Epoch [22][80/100], loss_cls: 0.55481, depth_loss: 11.065 lr: 1.25000e-04, loss: 4.7879\n",
      "Epoch [22][85/100], loss_cls: 1.9017, depth_loss: 14.744 lr: 1.25000e-04, loss: 4.4295\n",
      "Epoch [22][90/100], loss_cls: 0.43075, depth_loss: 18.387 lr: 1.25000e-04, loss: 4.4007\n",
      "Epoch [22][95/100], loss_cls: 0.067919, depth_loss: 26.176 lr: 1.25000e-04, loss: 4.7702\n",
      "Epoch [22][100/100], loss_cls: 0.9355, depth_loss: 20.434 lr: 1.25000e-04, loss: 5.8555\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.5429, top5_acc: 1.0, train_loss: 5.8555, val_loss: 3.8433\n",
      "Saving checkpoint at 22 epochs...\n",
      "Epoch [23][5/100], loss_cls: 1.5162, depth_loss: 49.458 lr: 1.25000e-04, loss: 6.0593\n",
      "Epoch [23][10/100], loss_cls: 0.00023295, depth_loss: 9.4559 lr: 1.25000e-04, loss: 4.5349\n",
      "Epoch [23][15/100], loss_cls: 0.00018553, depth_loss: 17.586 lr: 1.25000e-04, loss: 3.9262\n",
      "Epoch [23][20/100], loss_cls: 0.090983, depth_loss: 17.695 lr: 1.25000e-04, loss: 4.0925\n",
      "Epoch [23][25/100], loss_cls: 1.6987, depth_loss: 26.78 lr: 1.25000e-04, loss: 6.2194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23][30/100], loss_cls: 0.0031927, depth_loss: 17.74 lr: 1.25000e-04, loss: 4.0174\n",
      "Epoch [23][35/100], loss_cls: 2.2993, depth_loss: 35.114 lr: 1.25000e-04, loss: 7.6215\n",
      "Epoch [23][40/100], loss_cls: 1.2019, depth_loss: 20.958 lr: 1.25000e-04, loss: 5.8886\n",
      "Epoch [23][45/100], loss_cls: 0.0087104, depth_loss: 12.222 lr: 1.25000e-04, loss: 4.0089\n",
      "Epoch [23][50/100], loss_cls: 2.1741, depth_loss: 37.749 lr: 1.25000e-04, loss: 6.1134\n",
      "Epoch [23][55/100], loss_cls: 2.0446, depth_loss: 26.205 lr: 1.25000e-04, loss: 5.9352\n",
      "Epoch [23][60/100], loss_cls: 1.1954, depth_loss: 9.8482 lr: 1.25000e-04, loss: 5.8075\n",
      "Epoch [23][65/100], loss_cls: 0.11137, depth_loss: 15.175 lr: 1.25000e-04, loss: 5.2311\n",
      "Epoch [23][70/100], loss_cls: 1.6779, depth_loss: 17.928 lr: 1.25000e-04, loss: 4.3752\n",
      "Epoch [23][75/100], loss_cls: 1.673, depth_loss: 28.967 lr: 1.25000e-04, loss: 6.6553\n",
      "Epoch [23][80/100], loss_cls: 0.040073, depth_loss: 29.786 lr: 1.25000e-04, loss: 5.0371\n",
      "Epoch [23][85/100], loss_cls: 0.67811, depth_loss: 32.691 lr: 1.25000e-04, loss: 5.0718\n",
      "Epoch [23][90/100], loss_cls: 2.5007, depth_loss: 16.828 lr: 1.25000e-04, loss: 5.7236\n",
      "Epoch [23][95/100], loss_cls: 2.2501, depth_loss: 42.119 lr: 1.25000e-04, loss: 5.0639\n",
      "Epoch [23][100/100], loss_cls: 0.52503, depth_loss: 9.6013 lr: 1.25000e-04, loss: 3.3523\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.5714, top5_acc: 0.9714, train_loss: 3.3523, val_loss: 4.1253\n",
      "Epoch [24][5/100], loss_cls: 1.4583, depth_loss: 13.331 lr: 1.25000e-04, loss: 4.9666\n",
      "Epoch [24][10/100], loss_cls: 0.80546, depth_loss: 30.617 lr: 1.25000e-04, loss: 6.0661\n",
      "Epoch [24][15/100], loss_cls: 0.056356, depth_loss: 30.867 lr: 1.25000e-04, loss: 4.1315\n",
      "Epoch [24][20/100], loss_cls: 1.1651, depth_loss: 22.106 lr: 1.25000e-04, loss: 5.6417\n",
      "Epoch [24][25/100], loss_cls: 1.025, depth_loss: 18.75 lr: 1.25000e-04, loss: 4.8919\n",
      "Epoch [24][30/100], loss_cls: 1.0852, depth_loss: 36.291 lr: 1.25000e-04, loss: 4.7157\n",
      "Epoch [24][35/100], loss_cls: 1.7325, depth_loss: 16.495 lr: 1.25000e-04, loss: 5.7095\n",
      "Epoch [24][40/100], loss_cls: 0.62506, depth_loss: 12.469 lr: 1.25000e-04, loss: 4.1243\n",
      "Epoch [24][45/100], loss_cls: 1.2131, depth_loss: 16.79 lr: 1.25000e-04, loss: 5.0295\n",
      "Epoch [24][50/100], loss_cls: 0.71444, depth_loss: 16.088 lr: 1.25000e-04, loss: 5.0525\n",
      "Epoch [24][55/100], loss_cls: 0.00010209, depth_loss: 19.74 lr: 1.25000e-04, loss: 4.6178\n",
      "Epoch [24][60/100], loss_cls: 4.1461, depth_loss: 23.334 lr: 1.25000e-04, loss: 6.5538\n",
      "Epoch [24][65/100], loss_cls: 0.69565, depth_loss: 5.6581 lr: 1.25000e-04, loss: 5.2253\n",
      "Epoch [24][70/100], loss_cls: 0.0038353, depth_loss: 17.155 lr: 1.25000e-04, loss: 4.2559\n",
      "Epoch [24][75/100], loss_cls: 1.792, depth_loss: 22.925 lr: 1.25000e-04, loss: 4.8206\n",
      "Epoch [24][80/100], loss_cls: 2.3257, depth_loss: 17.198 lr: 1.25000e-04, loss: 5.0605\n",
      "Epoch [24][85/100], loss_cls: 0.30579, depth_loss: 15.982 lr: 1.25000e-04, loss: 4.2871\n",
      "Epoch [24][90/100], loss_cls: 1.0417, depth_loss: 12.502 lr: 1.25000e-04, loss: 5.167\n",
      "Epoch [24][95/100], loss_cls: 0.0033852, depth_loss: 15.377 lr: 1.25000e-04, loss: 3.1166\n",
      "Epoch [24][100/100], loss_cls: 1.5411, depth_loss: 14.66 lr: 1.25000e-04, loss: 4.7546\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.6, top5_acc: 0.9714, train_loss: 4.7546, val_loss: 3.469\n",
      "Saving checkpoint at 24 epochs...\n",
      "Epoch [25][5/100], loss_cls: 0.96657, depth_loss: 81.499 lr: 1.25000e-04, loss: 7.0593\n",
      "Epoch [25][10/100], loss_cls: 0.76271, depth_loss: 17.25 lr: 1.25000e-04, loss: 6.3177\n",
      "Epoch [25][15/100], loss_cls: 0.016719, depth_loss: 9.5728 lr: 1.25000e-04, loss: 4.9062\n",
      "Epoch [25][20/100], loss_cls: 0.84163, depth_loss: 20.457 lr: 1.25000e-04, loss: 5.0948\n",
      "Epoch [25][25/100], loss_cls: 2.444, depth_loss: 32.674 lr: 1.25000e-04, loss: 5.203\n",
      "Epoch [25][30/100], loss_cls: 0.3896, depth_loss: 21.062 lr: 1.25000e-04, loss: 4.8254\n",
      "Epoch [25][35/100], loss_cls: 1.5612, depth_loss: 40.333 lr: 1.25000e-04, loss: 5.9141\n",
      "Epoch [25][40/100], loss_cls: 1.826, depth_loss: 9.2357 lr: 1.25000e-04, loss: 4.4002\n",
      "Epoch [25][45/100], loss_cls: 0.077295, depth_loss: 20.453 lr: 1.25000e-04, loss: 2.8681\n",
      "Epoch [25][50/100], loss_cls: 0.36162, depth_loss: 18.666 lr: 1.25000e-04, loss: 3.7052\n",
      "Epoch [25][55/100], loss_cls: 8.2785e-05, depth_loss: 22.815 lr: 1.25000e-04, loss: 5.1781\n",
      "Epoch [25][60/100], loss_cls: 1.0418, depth_loss: 33.9 lr: 1.25000e-04, loss: 6.3315\n",
      "Epoch [25][65/100], loss_cls: 0.27351, depth_loss: 17.734 lr: 1.25000e-04, loss: 4.3634\n",
      "Epoch [25][70/100], loss_cls: 0.36112, depth_loss: 9.9265 lr: 1.25000e-04, loss: 3.7803\n",
      "Epoch [25][75/100], loss_cls: 0.75801, depth_loss: 22.769 lr: 1.25000e-04, loss: 4.4593\n",
      "Epoch [25][80/100], loss_cls: 0.76723, depth_loss: 20.458 lr: 1.25000e-04, loss: 4.0901\n",
      "Epoch [25][85/100], loss_cls: 0.28908, depth_loss: 23.143 lr: 1.25000e-04, loss: 4.0182\n",
      "Epoch [25][90/100], loss_cls: 2.4119, depth_loss: 33.391 lr: 1.25000e-04, loss: 4.5599\n",
      "Epoch [25][95/100], loss_cls: 0.74197, depth_loss: 23.201 lr: 1.25000e-04, loss: 4.9986\n",
      "Epoch [25][100/100], loss_cls: 0.21387, depth_loss: 16.274 lr: 1.25000e-04, loss: 6.0059\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.4571, top5_acc: 0.9429, train_loss: 6.0059, val_loss: 3.9214\n",
      "Epoch [26][5/100], loss_cls: 0.047618, depth_loss: 10.6 lr: 1.25000e-04, loss: 4.8799\n",
      "Epoch [26][10/100], loss_cls: 4.6699, depth_loss: 31.572 lr: 1.25000e-04, loss: 6.5565\n",
      "Epoch [26][15/100], loss_cls: 1.1518, depth_loss: 14.608 lr: 1.25000e-04, loss: 4.6829\n",
      "Epoch [26][20/100], loss_cls: 0.0019197, depth_loss: 11.909 lr: 1.25000e-04, loss: 3.3457\n",
      "Epoch [26][25/100], loss_cls: 1.1207, depth_loss: 7.285 lr: 1.25000e-04, loss: 3.9915\n",
      "Epoch [26][30/100], loss_cls: 1.6341, depth_loss: 12.117 lr: 1.25000e-04, loss: 4.0431\n",
      "Epoch [26][35/100], loss_cls: 0.0029998, depth_loss: 33.635 lr: 1.25000e-04, loss: 6.128\n",
      "Epoch [26][40/100], loss_cls: 0.06337, depth_loss: 11.6 lr: 1.25000e-04, loss: 4.8649\n",
      "Epoch [26][45/100], loss_cls: 0.019024, depth_loss: 20.346 lr: 1.25000e-04, loss: 4.4685\n",
      "Epoch [26][50/100], loss_cls: 0.039053, depth_loss: 10.139 lr: 1.25000e-04, loss: 4.5916\n",
      "Epoch [26][55/100], loss_cls: 2.2195, depth_loss: 20.023 lr: 1.25000e-04, loss: 4.5671\n",
      "Epoch [26][60/100], loss_cls: 1.954, depth_loss: 13.04 lr: 1.25000e-04, loss: 4.4681\n",
      "Epoch [26][65/100], loss_cls: 3.0956, depth_loss: 8.0806 lr: 1.25000e-04, loss: 4.0172\n",
      "Epoch [26][70/100], loss_cls: 1.3245, depth_loss: 21.546 lr: 1.25000e-04, loss: 6.4224\n",
      "Epoch [26][75/100], loss_cls: 1.7321, depth_loss: 24.261 lr: 1.25000e-04, loss: 3.9455\n",
      "Epoch [26][80/100], loss_cls: 2.8454, depth_loss: 10.217 lr: 1.25000e-04, loss: 4.0345\n",
      "Epoch [26][85/100], loss_cls: 2.3841, depth_loss: 10.803 lr: 1.25000e-04, loss: 4.2753\n",
      "Epoch [26][90/100], loss_cls: 3.4178, depth_loss: 14.591 lr: 1.25000e-04, loss: 5.4\n",
      "Epoch [26][95/100], loss_cls: 0.25365, depth_loss: 11.028 lr: 1.25000e-04, loss: 3.6169\n",
      "Epoch [26][100/100], loss_cls: 1.5528, depth_loss: 30.276 lr: 1.25000e-04, loss: 4.4442\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.6857, top5_acc: 1.0, train_loss: 4.4442, val_loss: 3.5192\n",
      "Epoch [27][5/100], loss_cls: 0.95289, depth_loss: 23.064 lr: 1.25000e-04, loss: 4.1268\n",
      "Epoch [27][10/100], loss_cls: 0.048415, depth_loss: 9.7721 lr: 1.25000e-04, loss: 4.0299\n",
      "Epoch [27][15/100], loss_cls: 0.014436, depth_loss: 10.644 lr: 1.25000e-04, loss: 6.3887\n",
      "Epoch [27][20/100], loss_cls: 0.60196, depth_loss: 34.466 lr: 1.25000e-04, loss: 6.0019\n",
      "Epoch [27][25/100], loss_cls: 0.0014194, depth_loss: 11.899 lr: 1.25000e-04, loss: 3.8263\n",
      "Epoch [27][30/100], loss_cls: 1.6694, depth_loss: 15.319 lr: 1.25000e-04, loss: 2.8608\n",
      "Epoch [27][35/100], loss_cls: 0.070669, depth_loss: 33.537 lr: 1.25000e-04, loss: 4.0918\n",
      "Epoch [27][40/100], loss_cls: 1.5994, depth_loss: 14.893 lr: 1.25000e-04, loss: 4.8856\n",
      "Epoch [27][45/100], loss_cls: 1.5072, depth_loss: 10.909 lr: 1.25000e-04, loss: 6.7912\n",
      "Epoch [27][50/100], loss_cls: 2.6214, depth_loss: 18.469 lr: 1.25000e-04, loss: 4.5037\n",
      "Epoch [27][55/100], loss_cls: 1.2302, depth_loss: 16.691 lr: 1.25000e-04, loss: 4.1138\n",
      "Epoch [27][60/100], loss_cls: 4.6702, depth_loss: 9.4567 lr: 1.25000e-04, loss: 7.7148\n",
      "Epoch [27][65/100], loss_cls: 0.53611, depth_loss: 12.72 lr: 1.25000e-04, loss: 3.6855\n",
      "Epoch [27][70/100], loss_cls: 0.1533, depth_loss: 16.444 lr: 1.25000e-04, loss: 4.7237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27][75/100], loss_cls: 0.30047, depth_loss: 16.621 lr: 1.25000e-04, loss: 3.6252\n",
      "Epoch [27][80/100], loss_cls: 3.0388, depth_loss: 12.62 lr: 1.25000e-04, loss: 4.9626\n",
      "Epoch [27][85/100], loss_cls: 0.53315, depth_loss: 30.639 lr: 1.25000e-04, loss: 3.9128\n",
      "Epoch [27][90/100], loss_cls: 0.0, depth_loss: 17.083 lr: 1.25000e-04, loss: 4.5771\n",
      "Epoch [27][95/100], loss_cls: 0.1318, depth_loss: 7.9498 lr: 1.25000e-04, loss: 4.0028\n",
      "Epoch [27][100/100], loss_cls: 0.26272, depth_loss: 15.392 lr: 1.25000e-04, loss: 3.308\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.6857, top5_acc: 0.9429, train_loss: 3.308, val_loss: 3.4711\n",
      "Epoch [28][5/100], loss_cls: 0.38823, depth_loss: 26.878 lr: 1.25000e-04, loss: 4.2351\n",
      "Epoch [28][10/100], loss_cls: 1.6172, depth_loss: 12.714 lr: 1.25000e-04, loss: 3.6093\n",
      "Epoch [28][15/100], loss_cls: 0.39687, depth_loss: 15.944 lr: 1.25000e-04, loss: 4.1846\n",
      "Epoch [28][20/100], loss_cls: 0.73271, depth_loss: 16.063 lr: 1.25000e-04, loss: 4.3666\n",
      "Epoch [28][25/100], loss_cls: 0.40421, depth_loss: 6.7528 lr: 1.25000e-04, loss: 4.5313\n",
      "Epoch [28][30/100], loss_cls: 1.212, depth_loss: 35.828 lr: 1.25000e-04, loss: 4.5693\n",
      "Epoch [28][35/100], loss_cls: 1.0181, depth_loss: 24.548 lr: 1.25000e-04, loss: 2.9025\n",
      "Epoch [28][40/100], loss_cls: 1.9455, depth_loss: 21.429 lr: 1.25000e-04, loss: 3.7431\n",
      "Epoch [28][45/100], loss_cls: 0.087639, depth_loss: 10.525 lr: 1.25000e-04, loss: 3.4756\n",
      "Epoch [28][50/100], loss_cls: 0.368, depth_loss: 15.75 lr: 1.25000e-04, loss: 3.1481\n",
      "Epoch [28][55/100], loss_cls: 0.85672, depth_loss: 19.852 lr: 1.25000e-04, loss: 4.4976\n",
      "Epoch [28][60/100], loss_cls: 0.54266, depth_loss: 51.688 lr: 1.25000e-04, loss: 5.9396\n",
      "Epoch [28][65/100], loss_cls: 1.8554, depth_loss: 13.749 lr: 1.25000e-04, loss: 4.6007\n",
      "Epoch [28][70/100], loss_cls: 0.0059143, depth_loss: 24.388 lr: 1.25000e-04, loss: 6.9216\n",
      "Epoch [28][75/100], loss_cls: 0.033174, depth_loss: 26.208 lr: 1.25000e-04, loss: 5.3573\n",
      "Epoch [28][80/100], loss_cls: 1.9941, depth_loss: 13.662 lr: 1.25000e-04, loss: 5.8092\n",
      "Epoch [28][85/100], loss_cls: 3.0047, depth_loss: 18.78 lr: 1.25000e-04, loss: 3.8362\n",
      "Epoch [28][90/100], loss_cls: 0.60303, depth_loss: 17.899 lr: 1.25000e-04, loss: 4.5211\n",
      "Epoch [28][95/100], loss_cls: 0.69147, depth_loss: 19.449 lr: 1.25000e-04, loss: 3.3779\n",
      "Epoch [28][100/100], loss_cls: 0.42559, depth_loss: 12.688 lr: 1.25000e-04, loss: 5.6732\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7714, top5_acc: 0.9714, train_loss: 5.6732, val_loss: 4.6009\n",
      "Epoch [29][5/100], loss_cls: 1.2947, depth_loss: 17.485 lr: 1.25000e-04, loss: 4.7542\n",
      "Epoch [29][10/100], loss_cls: 8.6426e-06, depth_loss: 13.402 lr: 1.25000e-04, loss: 2.7039\n",
      "Epoch [29][15/100], loss_cls: 1.1498, depth_loss: 31.666 lr: 1.25000e-04, loss: 7.8868\n",
      "Epoch [29][20/100], loss_cls: 0.5352, depth_loss: 18.743 lr: 1.25000e-04, loss: 4.9976\n",
      "Epoch [29][25/100], loss_cls: 0.040209, depth_loss: 13.009 lr: 1.25000e-04, loss: 3.6119\n",
      "Epoch [29][30/100], loss_cls: 0.93312, depth_loss: 13.334 lr: 1.25000e-04, loss: 3.6842\n",
      "Epoch [29][35/100], loss_cls: 2.1934, depth_loss: 83.947 lr: 1.25000e-04, loss: 7.5242\n",
      "Epoch [29][40/100], loss_cls: 1.7504, depth_loss: 19.344 lr: 1.25000e-04, loss: 6.0276\n",
      "Epoch [29][45/100], loss_cls: 0.1564, depth_loss: 33.611 lr: 1.25000e-04, loss: 6.0647\n",
      "Epoch [29][50/100], loss_cls: 4.7684e-07, depth_loss: 14.556 lr: 1.25000e-04, loss: 4.6044\n",
      "Epoch [29][55/100], loss_cls: 4.345e-05, depth_loss: 11.117 lr: 1.25000e-04, loss: 2.9841\n",
      "Epoch [29][60/100], loss_cls: 1.4007e-05, depth_loss: 14.283 lr: 1.25000e-04, loss: 5.5772\n",
      "Epoch [29][65/100], loss_cls: 1.9433, depth_loss: 16.242 lr: 1.25000e-04, loss: 3.9784\n",
      "Epoch [29][70/100], loss_cls: 0.87919, depth_loss: 17.045 lr: 1.25000e-04, loss: 6.2655\n",
      "Epoch [29][75/100], loss_cls: 0.45415, depth_loss: 6.9615 lr: 1.25000e-04, loss: 3.8354\n",
      "Epoch [29][80/100], loss_cls: 0.1739, depth_loss: 17.044 lr: 1.25000e-04, loss: 3.902\n",
      "Epoch [29][85/100], loss_cls: 0.01783, depth_loss: 8.7813 lr: 1.25000e-04, loss: 3.873\n",
      "Epoch [29][90/100], loss_cls: 1.0337, depth_loss: 13.968 lr: 1.25000e-04, loss: 4.9122\n",
      "Epoch [29][95/100], loss_cls: 1.0015, depth_loss: 16.555 lr: 1.25000e-04, loss: 4.361\n",
      "Epoch [29][100/100], loss_cls: 0.22897, depth_loss: 14.276 lr: 1.25000e-04, loss: 4.4984\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7429, top5_acc: 1.0, train_loss: 4.4984, val_loss: 4.2056\n",
      "Epoch [30][5/100], loss_cls: 0.60141, depth_loss: 36.664 lr: 1.25000e-04, loss: 3.9402\n",
      "Epoch [30][10/100], loss_cls: 1.6641, depth_loss: 38.524 lr: 1.25000e-04, loss: 5.7655\n",
      "Epoch [30][15/100], loss_cls: 0.042882, depth_loss: 13.345 lr: 1.25000e-04, loss: 4.805\n",
      "Epoch [30][20/100], loss_cls: 0.0053744, depth_loss: 15.905 lr: 1.25000e-04, loss: 4.3632\n",
      "Epoch [30][25/100], loss_cls: 0.00088251, depth_loss: 12.041 lr: 1.25000e-04, loss: 3.6088\n",
      "Epoch [30][30/100], loss_cls: 0.93909, depth_loss: 13.456 lr: 1.25000e-04, loss: 3.6896\n",
      "Epoch [30][35/100], loss_cls: 1.2361, depth_loss: 30.101 lr: 1.25000e-04, loss: 4.9736\n",
      "Epoch [30][40/100], loss_cls: 2.106, depth_loss: 38.211 lr: 1.25000e-04, loss: 5.7931\n",
      "Epoch [30][45/100], loss_cls: 0.0028513, depth_loss: 21.969 lr: 1.25000e-04, loss: 4.6403\n",
      "Epoch [30][50/100], loss_cls: 1.3345, depth_loss: 26.977 lr: 1.25000e-04, loss: 3.2997\n",
      "Epoch [30][55/100], loss_cls: 0.86198, depth_loss: 8.3577 lr: 1.25000e-04, loss: 4.4854\n",
      "Epoch [30][60/100], loss_cls: 0.061814, depth_loss: 13.516 lr: 1.25000e-04, loss: 5.0687\n",
      "Epoch [30][65/100], loss_cls: 0.3612, depth_loss: 14.098 lr: 1.25000e-04, loss: 4.0433\n",
      "Epoch [30][70/100], loss_cls: 0.00035676, depth_loss: 19.93 lr: 1.25000e-04, loss: 3.7035\n",
      "Epoch [30][75/100], loss_cls: 2.4081, depth_loss: 10.68 lr: 1.25000e-04, loss: 4.3848\n",
      "Epoch [30][80/100], loss_cls: 0.041463, depth_loss: 12.547 lr: 1.25000e-04, loss: 3.5455\n",
      "Epoch [30][85/100], loss_cls: 0.018095, depth_loss: 12.42 lr: 1.25000e-04, loss: 4.6785\n",
      "Epoch [30][90/100], loss_cls: 0.84514, depth_loss: 36.163 lr: 1.25000e-04, loss: 4.383\n",
      "Epoch [30][95/100], loss_cls: 4.0351e-05, depth_loss: 17.459 lr: 1.25000e-04, loss: 4.3357\n",
      "Epoch [30][100/100], loss_cls: 0.00086098, depth_loss: 18.354 lr: 1.25000e-04, loss: 6.5333\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.6286, top5_acc: 0.9714, train_loss: 6.5333, val_loss: 4.4363\n",
      "Epoch [31][5/100], loss_cls: 1.3112, depth_loss: 19.812 lr: 1.25000e-04, loss: 4.3053\n",
      "Epoch [31][10/100], loss_cls: 0.13235, depth_loss: 22.031 lr: 1.25000e-04, loss: 3.7217\n",
      "Epoch [31][15/100], loss_cls: 0.95198, depth_loss: 12.082 lr: 1.25000e-04, loss: 3.3295\n",
      "Epoch [31][20/100], loss_cls: 0.74267, depth_loss: 12.404 lr: 1.25000e-04, loss: 3.4495\n",
      "Epoch [31][25/100], loss_cls: 0.0016528, depth_loss: 14.967 lr: 1.25000e-04, loss: 4.7176\n",
      "Epoch [31][30/100], loss_cls: 0.0058535, depth_loss: 13.829 lr: 1.25000e-04, loss: 3.5392\n",
      "Epoch [31][35/100], loss_cls: 0.052164, depth_loss: 14.591 lr: 1.25000e-04, loss: 2.5695\n",
      "Epoch [31][40/100], loss_cls: 0.0096448, depth_loss: 21.429 lr: 1.25000e-04, loss: 5.6166\n",
      "Epoch [31][45/100], loss_cls: 0.87245, depth_loss: 12.64 lr: 1.25000e-04, loss: 3.223\n",
      "Epoch [31][50/100], loss_cls: 0.46792, depth_loss: 18.752 lr: 1.25000e-04, loss: 3.845\n",
      "Epoch [31][55/100], loss_cls: 0.64808, depth_loss: 18.866 lr: 1.25000e-04, loss: 4.8962\n",
      "Epoch [31][60/100], loss_cls: 0.044621, depth_loss: 24.728 lr: 1.25000e-04, loss: 4.4746\n",
      "Epoch [31][65/100], loss_cls: 0.032621, depth_loss: 19.525 lr: 1.25000e-04, loss: 5.2942\n",
      "Epoch [31][70/100], loss_cls: 0.0045308, depth_loss: 14.345 lr: 1.25000e-04, loss: 4.2198\n",
      "Epoch [31][75/100], loss_cls: 0.14011, depth_loss: 20.706 lr: 1.25000e-04, loss: 5.3867\n",
      "Epoch [31][80/100], loss_cls: 0.33235, depth_loss: 14.528 lr: 1.25000e-04, loss: 4.817\n",
      "Epoch [31][85/100], loss_cls: 0.10921, depth_loss: 15.555 lr: 1.25000e-04, loss: 3.908\n",
      "Epoch [31][90/100], loss_cls: 1.4034, depth_loss: 21.748 lr: 1.25000e-04, loss: 4.6019\n",
      "Epoch [31][95/100], loss_cls: 0.61599, depth_loss: 37.84 lr: 1.25000e-04, loss: 5.742\n",
      "Epoch [31][100/100], loss_cls: 0.76452, depth_loss: 17.896 lr: 1.25000e-04, loss: 3.5702\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7429, top5_acc: 1.0, train_loss: 3.5702, val_loss: 3.5502\n",
      "Epoch [32][5/100], loss_cls: 0.0051671, depth_loss: 23.958 lr: 1.25000e-04, loss: 4.5087\n",
      "Epoch [32][10/100], loss_cls: 0.019944, depth_loss: 17.631 lr: 1.25000e-04, loss: 3.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32][15/100], loss_cls: 0.4448, depth_loss: 22.128 lr: 1.25000e-04, loss: 3.6094\n",
      "Epoch [32][20/100], loss_cls: 0.57122, depth_loss: 22.011 lr: 1.25000e-04, loss: 3.9097\n",
      "Epoch [32][25/100], loss_cls: 1.0237, depth_loss: 22.431 lr: 1.25000e-04, loss: 4.9831\n",
      "Epoch [32][30/100], loss_cls: 1.5649, depth_loss: 18.895 lr: 1.25000e-04, loss: 3.1251\n",
      "Epoch [32][35/100], loss_cls: 5.5399, depth_loss: 10.096 lr: 1.25000e-04, loss: 5.3715\n",
      "Epoch [32][40/100], loss_cls: 0.94701, depth_loss: 12.815 lr: 1.25000e-04, loss: 5.1202\n",
      "Epoch [32][45/100], loss_cls: 0.53716, depth_loss: 22.434 lr: 1.25000e-04, loss: 4.0505\n",
      "Epoch [32][50/100], loss_cls: 3.889, depth_loss: 18.2 lr: 1.25000e-04, loss: 4.9014\n",
      "Epoch [32][55/100], loss_cls: 0.77809, depth_loss: 21.455 lr: 1.25000e-04, loss: 4.7031\n",
      "Epoch [32][60/100], loss_cls: 1.042, depth_loss: 51.84 lr: 1.25000e-04, loss: 4.696\n",
      "Epoch [32][65/100], loss_cls: 1.3104, depth_loss: 9.5162 lr: 1.25000e-04, loss: 3.9251\n",
      "Epoch [32][70/100], loss_cls: 0.724, depth_loss: 15.995 lr: 1.25000e-04, loss: 3.0103\n",
      "Epoch [32][75/100], loss_cls: 0.0020895, depth_loss: 8.5099 lr: 1.25000e-04, loss: 3.4469\n",
      "Epoch [32][80/100], loss_cls: 0.02804, depth_loss: 22.671 lr: 1.25000e-04, loss: 3.4539\n",
      "Epoch [32][85/100], loss_cls: 0.00047214, depth_loss: 11.291 lr: 1.25000e-04, loss: 4.161\n",
      "Epoch [32][90/100], loss_cls: 4.6161, depth_loss: 36.612 lr: 1.25000e-04, loss: 6.0804\n",
      "Epoch [32][95/100], loss_cls: 0.0054143, depth_loss: 15.425 lr: 1.25000e-04, loss: 3.6576\n",
      "Epoch [32][100/100], loss_cls: 0.026944, depth_loss: 9.1642 lr: 1.25000e-04, loss: 3.513\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7143, top5_acc: 0.9429, train_loss: 3.513, val_loss: 3.4572\n",
      "Saving checkpoint at 32 epochs...\n",
      "Epoch [33][5/100], loss_cls: 2.9805, depth_loss: 13.389 lr: 1.25000e-04, loss: 4.8697\n",
      "Epoch [33][10/100], loss_cls: 1.8222, depth_loss: 40.058 lr: 1.25000e-04, loss: 4.925\n",
      "Epoch [33][15/100], loss_cls: 1.6306, depth_loss: 11.383 lr: 1.25000e-04, loss: 4.678\n",
      "Epoch [33][20/100], loss_cls: 0.46824, depth_loss: 10.022 lr: 1.25000e-04, loss: 3.4775\n",
      "Epoch [33][25/100], loss_cls: 0.56546, depth_loss: 19.067 lr: 1.25000e-04, loss: 3.3555\n",
      "Epoch [33][30/100], loss_cls: 1.3616, depth_loss: 54.551 lr: 1.25000e-04, loss: 5.2794\n",
      "Epoch [33][35/100], loss_cls: 1.1323, depth_loss: 17.816 lr: 1.25000e-04, loss: 4.2166\n",
      "Epoch [33][40/100], loss_cls: 1.5942, depth_loss: 13.482 lr: 1.25000e-04, loss: 3.6728\n",
      "Epoch [33][45/100], loss_cls: 0.20805, depth_loss: 15.719 lr: 1.25000e-04, loss: 4.9857\n",
      "Epoch [33][50/100], loss_cls: 9.5367e-06, depth_loss: 17.363 lr: 1.25000e-04, loss: 2.639\n",
      "Epoch [33][55/100], loss_cls: 0.031783, depth_loss: 5.9706 lr: 1.25000e-04, loss: 6.5123\n",
      "Epoch [33][60/100], loss_cls: 0.0071026, depth_loss: 8.8401 lr: 1.25000e-04, loss: 2.9549\n",
      "Epoch [33][65/100], loss_cls: 0.00025111, depth_loss: 17.202 lr: 1.25000e-04, loss: 3.5037\n",
      "Epoch [33][70/100], loss_cls: 0.13936, depth_loss: 21.572 lr: 1.25000e-04, loss: 4.3185\n",
      "Epoch [33][75/100], loss_cls: 0.00038402, depth_loss: 11.625 lr: 1.25000e-04, loss: 4.8155\n",
      "Epoch [33][80/100], loss_cls: 0.47823, depth_loss: 11.48 lr: 1.25000e-04, loss: 3.6036\n",
      "Epoch [33][85/100], loss_cls: 1.5347, depth_loss: 10.88 lr: 1.25000e-04, loss: 5.2137\n",
      "Epoch [33][90/100], loss_cls: 0.039257, depth_loss: 29.698 lr: 1.25000e-04, loss: 3.6457\n",
      "Epoch [33][95/100], loss_cls: 0.0041215, depth_loss: 14.473 lr: 1.25000e-04, loss: 4.1439\n",
      "Epoch [33][100/100], loss_cls: 0.0087386, depth_loss: 36.008 lr: 1.25000e-04, loss: 4.7354\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7429, top5_acc: 0.9714, train_loss: 4.7354, val_loss: 3.7768\n",
      "Epoch [34][5/100], loss_cls: 2.1216, depth_loss: 7.4011 lr: 1.25000e-04, loss: 4.4109\n",
      "Epoch [34][10/100], loss_cls: 0.27674, depth_loss: 14.392 lr: 1.25000e-04, loss: 3.6811\n",
      "Epoch [34][15/100], loss_cls: 0.042654, depth_loss: 21.035 lr: 1.25000e-04, loss: 4.5072\n",
      "Epoch [34][20/100], loss_cls: 1.6343, depth_loss: 18.253 lr: 1.25000e-04, loss: 3.7228\n",
      "Epoch [34][25/100], loss_cls: 0.66573, depth_loss: 14.487 lr: 1.25000e-04, loss: 4.5546\n",
      "Epoch [34][30/100], loss_cls: 0.47454, depth_loss: 16.558 lr: 1.25000e-04, loss: 3.6295\n",
      "Epoch [34][35/100], loss_cls: 0.086164, depth_loss: 24.613 lr: 1.25000e-04, loss: 4.376\n",
      "Epoch [34][40/100], loss_cls: 0.0050563, depth_loss: 16.616 lr: 1.25000e-04, loss: 4.7835\n",
      "Epoch [34][45/100], loss_cls: 0.92533, depth_loss: 20.823 lr: 1.25000e-04, loss: 4.8579\n",
      "Epoch [34][50/100], loss_cls: 0.23787, depth_loss: 20.412 lr: 1.25000e-04, loss: 4.3391\n",
      "Epoch [34][55/100], loss_cls: 1.0888, depth_loss: 12.185 lr: 1.25000e-04, loss: 3.9818\n",
      "Epoch [34][60/100], loss_cls: 0.0014837, depth_loss: 6.9743 lr: 1.25000e-04, loss: 2.6721\n",
      "Epoch [34][65/100], loss_cls: 1.2504, depth_loss: 16.716 lr: 1.25000e-04, loss: 4.0176\n",
      "Epoch [34][70/100], loss_cls: 1.4573, depth_loss: 25.495 lr: 1.25000e-04, loss: 3.4765\n",
      "Epoch [34][75/100], loss_cls: 0.070651, depth_loss: 12.688 lr: 1.25000e-04, loss: 2.8909\n",
      "Epoch [34][80/100], loss_cls: 0.11097, depth_loss: 17.921 lr: 1.25000e-04, loss: 3.5739\n",
      "Epoch [34][85/100], loss_cls: 0.00017652, depth_loss: 14.933 lr: 1.25000e-04, loss: 3.9298\n",
      "Epoch [34][90/100], loss_cls: 1.8275, depth_loss: 30.736 lr: 1.25000e-04, loss: 5.1375\n",
      "Epoch [34][95/100], loss_cls: 0.069423, depth_loss: 18.304 lr: 1.25000e-04, loss: 3.5989\n",
      "Epoch [34][100/100], loss_cls: 0.0010542, depth_loss: 12.875 lr: 1.25000e-04, loss: 3.5308\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9429, train_loss: 3.5308, val_loss: 3.5749\n",
      "Epoch [35][5/100], loss_cls: 0.002996, depth_loss: 10.985 lr: 1.25000e-04, loss: 6.7613\n",
      "Epoch [35][10/100], loss_cls: 1.8832, depth_loss: 17.034 lr: 1.25000e-04, loss: 3.4437\n",
      "Epoch [35][15/100], loss_cls: 0.0057356, depth_loss: 13.623 lr: 1.25000e-04, loss: 2.3568\n",
      "Epoch [35][20/100], loss_cls: 0.039773, depth_loss: 21.557 lr: 1.25000e-04, loss: 3.7249\n",
      "Epoch [35][25/100], loss_cls: 0.17992, depth_loss: 15.293 lr: 1.25000e-04, loss: 4.0515\n",
      "Epoch [35][30/100], loss_cls: 0.73863, depth_loss: 10.129 lr: 1.25000e-04, loss: 3.0418\n",
      "Epoch [35][35/100], loss_cls: 0.069412, depth_loss: 16.143 lr: 1.25000e-04, loss: 5.0679\n",
      "Epoch [35][40/100], loss_cls: 0.011744, depth_loss: 6.9599 lr: 1.25000e-04, loss: 4.4454\n",
      "Epoch [35][45/100], loss_cls: 1.9272, depth_loss: 19.908 lr: 1.25000e-04, loss: 3.2287\n",
      "Epoch [35][50/100], loss_cls: 0.00059951, depth_loss: 16.413 lr: 1.25000e-04, loss: 3.2641\n",
      "Epoch [35][55/100], loss_cls: 0.41521, depth_loss: 11.594 lr: 1.25000e-04, loss: 2.1532\n",
      "Epoch [35][60/100], loss_cls: 5.1164, depth_loss: 40.713 lr: 1.25000e-04, loss: 5.2494\n",
      "Epoch [35][65/100], loss_cls: 0.45765, depth_loss: 18.812 lr: 1.25000e-04, loss: 3.3421\n",
      "Epoch [35][70/100], loss_cls: 0.088124, depth_loss: 23.328 lr: 1.25000e-04, loss: 3.8623\n",
      "Epoch [35][75/100], loss_cls: 1.8215, depth_loss: 17.738 lr: 1.25000e-04, loss: 5.284\n",
      "Epoch [35][80/100], loss_cls: 0.7233, depth_loss: 10.359 lr: 1.25000e-04, loss: 4.4824\n",
      "Epoch [35][85/100], loss_cls: 0.00032134, depth_loss: 15.054 lr: 1.25000e-04, loss: 4.1311\n",
      "Epoch [35][90/100], loss_cls: 0.35523, depth_loss: 13.39 lr: 1.25000e-04, loss: 3.071\n",
      "Epoch [35][95/100], loss_cls: 1.7416, depth_loss: 15.875 lr: 1.25000e-04, loss: 3.8428\n",
      "Epoch [35][100/100], loss_cls: 0.87279, depth_loss: 25.098 lr: 1.25000e-04, loss: 5.1503\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7429, top5_acc: 0.9714, train_loss: 5.1503, val_loss: 3.135\n",
      "Saving checkpoint at 35 epochs...\n",
      "Epoch [36][5/100], loss_cls: 0.00016138, depth_loss: 15.135 lr: 1.25000e-04, loss: 3.2022\n",
      "Epoch [36][10/100], loss_cls: 0.039436, depth_loss: 11.242 lr: 1.25000e-04, loss: 5.6487\n",
      "Epoch [36][15/100], loss_cls: 0.49927, depth_loss: 19.962 lr: 1.25000e-04, loss: 3.2825\n",
      "Epoch [36][20/100], loss_cls: 1.0034, depth_loss: 14.604 lr: 1.25000e-04, loss: 3.0062\n",
      "Epoch [36][25/100], loss_cls: 1.045, depth_loss: 40.748 lr: 1.25000e-04, loss: 4.7597\n",
      "Epoch [36][30/100], loss_cls: 0.0012519, depth_loss: 20.652 lr: 1.25000e-04, loss: 3.491\n",
      "Epoch [36][35/100], loss_cls: 1.9935, depth_loss: 20.762 lr: 1.25000e-04, loss: 5.5321\n",
      "Epoch [36][40/100], loss_cls: 1.5383, depth_loss: 16.586 lr: 1.25000e-04, loss: 4.583\n",
      "Epoch [36][45/100], loss_cls: 0.058301, depth_loss: 28.841 lr: 1.25000e-04, loss: 4.4626\n",
      "Epoch [36][50/100], loss_cls: 0.041431, depth_loss: 14.151 lr: 1.25000e-04, loss: 4.4203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36][55/100], loss_cls: 0.010228, depth_loss: 20.679 lr: 1.25000e-04, loss: 4.3693\n",
      "Epoch [36][60/100], loss_cls: 2.9626, depth_loss: 18.024 lr: 1.25000e-04, loss: 4.9009\n",
      "Epoch [36][65/100], loss_cls: 0.40098, depth_loss: 18.87 lr: 1.25000e-04, loss: 4.7365\n",
      "Epoch [36][70/100], loss_cls: 0.84873, depth_loss: 28.42 lr: 1.25000e-04, loss: 4.7354\n",
      "Epoch [36][75/100], loss_cls: 0.018322, depth_loss: 14.841 lr: 1.25000e-04, loss: 2.84\n",
      "Epoch [36][80/100], loss_cls: 0.73949, depth_loss: 8.9467 lr: 1.25000e-04, loss: 3.6211\n",
      "Epoch [36][85/100], loss_cls: 0.41313, depth_loss: 35.455 lr: 1.25000e-04, loss: 3.6223\n",
      "Epoch [36][90/100], loss_cls: 0.26518, depth_loss: 6.3294 lr: 1.25000e-04, loss: 3.1239\n",
      "Epoch [36][95/100], loss_cls: 0.001281, depth_loss: 13.33 lr: 1.25000e-04, loss: 3.4804\n",
      "Epoch [36][100/100], loss_cls: 0.56828, depth_loss: 6.5558 lr: 1.25000e-04, loss: 5.6815\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7714, top5_acc: 1.0, train_loss: 5.6815, val_loss: 3.8299\n",
      "Epoch [37][5/100], loss_cls: 0.00016448, depth_loss: 25.818 lr: 1.25000e-04, loss: 4.6953\n",
      "Epoch [37][10/100], loss_cls: 0.024046, depth_loss: 24.195 lr: 1.25000e-04, loss: 4.5731\n",
      "Epoch [37][15/100], loss_cls: 2.5424, depth_loss: 29.493 lr: 1.25000e-04, loss: 3.8786\n",
      "Epoch [37][20/100], loss_cls: 0.15016, depth_loss: 21.587 lr: 1.25000e-04, loss: 3.8642\n",
      "Epoch [37][25/100], loss_cls: 0.022244, depth_loss: 27.643 lr: 1.25000e-04, loss: 4.4798\n",
      "Epoch [37][30/100], loss_cls: 0.07445, depth_loss: 12.919 lr: 1.25000e-04, loss: 3.552\n",
      "Epoch [37][35/100], loss_cls: 1.9064, depth_loss: 14.736 lr: 1.25000e-04, loss: 3.8376\n",
      "Epoch [37][40/100], loss_cls: 0.00014155, depth_loss: 14.818 lr: 1.25000e-04, loss: 2.7696\n",
      "Epoch [37][45/100], loss_cls: 0.039349, depth_loss: 14.009 lr: 1.25000e-04, loss: 5.9596\n",
      "Epoch [37][50/100], loss_cls: 0.14301, depth_loss: 14.514 lr: 1.25000e-04, loss: 2.804\n",
      "Epoch [37][55/100], loss_cls: 2.7056, depth_loss: 10.251 lr: 1.25000e-04, loss: 4.1459\n",
      "Epoch [37][60/100], loss_cls: 0.001236, depth_loss: 19.177 lr: 1.25000e-04, loss: 2.9727\n",
      "Epoch [37][65/100], loss_cls: 0.38474, depth_loss: 9.0161 lr: 1.25000e-04, loss: 2.6639\n",
      "Epoch [37][70/100], loss_cls: 1.1874, depth_loss: 15.264 lr: 1.25000e-04, loss: 3.8829\n",
      "Epoch [37][75/100], loss_cls: 2.3215, depth_loss: 11.43 lr: 1.25000e-04, loss: 2.732\n",
      "Epoch [37][80/100], loss_cls: 0.057536, depth_loss: 14.472 lr: 1.25000e-04, loss: 3.6184\n",
      "Epoch [37][85/100], loss_cls: 1.2842, depth_loss: 10.375 lr: 1.25000e-04, loss: 3.4924\n",
      "Epoch [37][90/100], loss_cls: 1.2837, depth_loss: 23.674 lr: 1.25000e-04, loss: 3.568\n",
      "Epoch [37][95/100], loss_cls: 1.2957, depth_loss: 13.313 lr: 1.25000e-04, loss: 3.8919\n",
      "Epoch [37][100/100], loss_cls: 1.5512, depth_loss: 9.1458 lr: 1.25000e-04, loss: 3.3668\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 3.3668, val_loss: 3.5773\n",
      "Epoch [38][5/100], loss_cls: 0.016736, depth_loss: 11.761 lr: 1.25000e-04, loss: 4.826\n",
      "Epoch [38][10/100], loss_cls: 1.3292, depth_loss: 5.672 lr: 1.25000e-04, loss: 3.5028\n",
      "Epoch [38][15/100], loss_cls: 0.18981, depth_loss: 20.491 lr: 1.25000e-04, loss: 6.8417\n",
      "Epoch [38][20/100], loss_cls: 0.17005, depth_loss: 21.165 lr: 1.25000e-04, loss: 3.6869\n",
      "Epoch [38][25/100], loss_cls: 0.054697, depth_loss: 9.4323 lr: 1.25000e-04, loss: 2.6081\n",
      "Epoch [38][30/100], loss_cls: 5.9605e-08, depth_loss: 17.025 lr: 1.25000e-04, loss: 3.3578\n",
      "Epoch [38][35/100], loss_cls: 0.066566, depth_loss: 10.221 lr: 1.25000e-04, loss: 3.0937\n",
      "Epoch [38][40/100], loss_cls: 0.022449, depth_loss: 8.8917 lr: 1.25000e-04, loss: 5.2156\n",
      "Epoch [38][45/100], loss_cls: 0.0020366, depth_loss: 18.643 lr: 1.25000e-04, loss: 3.963\n",
      "Epoch [38][50/100], loss_cls: 0.24069, depth_loss: 11.798 lr: 1.25000e-04, loss: 5.4984\n",
      "Epoch [38][55/100], loss_cls: 0.0019087, depth_loss: 7.3977 lr: 1.25000e-04, loss: 4.4904\n",
      "Epoch [38][60/100], loss_cls: 1.0114, depth_loss: 10.2 lr: 1.25000e-04, loss: 4.5367\n",
      "Epoch [38][65/100], loss_cls: 0.028087, depth_loss: 16.296 lr: 1.25000e-04, loss: 4.3855\n",
      "Epoch [38][70/100], loss_cls: 0.95604, depth_loss: 8.5 lr: 1.25000e-04, loss: 3.32\n",
      "Epoch [38][75/100], loss_cls: 0.020485, depth_loss: 16.235 lr: 1.25000e-04, loss: 3.5762\n",
      "Epoch [38][80/100], loss_cls: 0.66305, depth_loss: 10.82 lr: 1.25000e-04, loss: 3.4777\n",
      "Epoch [38][85/100], loss_cls: 0.0017004, depth_loss: 10.636 lr: 1.25000e-04, loss: 2.5101\n",
      "Epoch [38][90/100], loss_cls: 0.66833, depth_loss: 19.0 lr: 1.25000e-04, loss: 4.6034\n",
      "Epoch [38][95/100], loss_cls: 0.38276, depth_loss: 14.362 lr: 1.25000e-04, loss: 5.2437\n",
      "Epoch [38][100/100], loss_cls: 1.8712, depth_loss: 23.982 lr: 1.25000e-04, loss: 3.5917\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 3.5917, val_loss: 3.0946\n",
      "Saving checkpoint at 38 epochs...\n",
      "Epoch [39][5/100], loss_cls: 0.097724, depth_loss: 26.5 lr: 1.25000e-04, loss: 2.9833\n",
      "Epoch [39][10/100], loss_cls: 1.7773, depth_loss: 31.513 lr: 1.25000e-04, loss: 5.0924\n",
      "Epoch [39][15/100], loss_cls: 0.015113, depth_loss: 25.026 lr: 1.25000e-04, loss: 3.5281\n",
      "Epoch [39][20/100], loss_cls: 0.052822, depth_loss: 10.345 lr: 1.25000e-04, loss: 3.563\n",
      "Epoch [39][25/100], loss_cls: 2.546, depth_loss: 12.175 lr: 1.25000e-04, loss: 6.646\n",
      "Epoch [39][30/100], loss_cls: 1.4417, depth_loss: 51.95 lr: 1.25000e-04, loss: 7.1719\n",
      "Epoch [39][35/100], loss_cls: 0.0037, depth_loss: 10.445 lr: 1.25000e-04, loss: 3.9143\n",
      "Epoch [39][40/100], loss_cls: 0.25377, depth_loss: 16.219 lr: 1.25000e-04, loss: 4.1424\n",
      "Epoch [39][45/100], loss_cls: 1.4968, depth_loss: 13.523 lr: 1.25000e-04, loss: 4.6659\n",
      "Epoch [39][50/100], loss_cls: 1.0952, depth_loss: 18.512 lr: 1.25000e-04, loss: 4.4094\n",
      "Epoch [39][55/100], loss_cls: 3.1767, depth_loss: 8.3872 lr: 1.25000e-04, loss: 4.0933\n",
      "Epoch [39][60/100], loss_cls: 1.1458, depth_loss: 24.738 lr: 1.25000e-04, loss: 5.7467\n",
      "Epoch [39][65/100], loss_cls: 6.7051e-05, depth_loss: 24.777 lr: 1.25000e-04, loss: 3.6348\n",
      "Epoch [39][70/100], loss_cls: 5.1377e-05, depth_loss: 16.565 lr: 1.25000e-04, loss: 3.1694\n",
      "Epoch [39][75/100], loss_cls: 1.592, depth_loss: 20.367 lr: 1.25000e-04, loss: 5.2864\n",
      "Epoch [39][80/100], loss_cls: 0.87669, depth_loss: 17.7 lr: 1.25000e-04, loss: 3.5224\n",
      "Epoch [39][85/100], loss_cls: 0.29389, depth_loss: 7.4626 lr: 1.25000e-04, loss: 3.1954\n",
      "Epoch [39][90/100], loss_cls: 0.011816, depth_loss: 9.4686 lr: 1.25000e-04, loss: 3.1833\n",
      "Epoch [39][95/100], loss_cls: 0.067559, depth_loss: 11.826 lr: 1.25000e-04, loss: 4.1001\n",
      "Epoch [39][100/100], loss_cls: 0.18166, depth_loss: 13.23 lr: 1.25000e-04, loss: 5.0659\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7143, top5_acc: 0.9714, train_loss: 5.0659, val_loss: 5.9193\n",
      "Epoch [40][5/100], loss_cls: 0.99157, depth_loss: 12.117 lr: 1.25000e-04, loss: 3.7208\n",
      "Epoch [40][10/100], loss_cls: 0.71987, depth_loss: 18.258 lr: 1.25000e-04, loss: 4.0902\n",
      "Epoch [40][15/100], loss_cls: 0.014335, depth_loss: 26.588 lr: 1.25000e-04, loss: 2.9354\n",
      "Epoch [40][20/100], loss_cls: 2.3498, depth_loss: 35.613 lr: 1.25000e-04, loss: 6.4797\n",
      "Epoch [40][25/100], loss_cls: 2.6345e-05, depth_loss: 15.152 lr: 1.25000e-04, loss: 4.9614\n",
      "Epoch [40][30/100], loss_cls: 0.00042444, depth_loss: 16.503 lr: 1.25000e-04, loss: 4.057\n",
      "Epoch [40][35/100], loss_cls: 0.012064, depth_loss: 16.765 lr: 1.25000e-04, loss: 2.9663\n",
      "Epoch [40][40/100], loss_cls: 0.0019262, depth_loss: 16.517 lr: 1.25000e-04, loss: 3.9514\n",
      "Epoch [40][45/100], loss_cls: 1.9878, depth_loss: 14.599 lr: 1.25000e-04, loss: 3.3169\n",
      "Epoch [40][50/100], loss_cls: 2.3362, depth_loss: 16.717 lr: 1.25000e-04, loss: 4.7833\n",
      "Epoch [40][55/100], loss_cls: 0.24468, depth_loss: 34.17 lr: 1.25000e-04, loss: 3.6405\n",
      "Epoch [40][60/100], loss_cls: 2.4709, depth_loss: 10.953 lr: 1.25000e-04, loss: 5.1842\n",
      "Epoch [40][65/100], loss_cls: 0.00058882, depth_loss: 10.794 lr: 1.25000e-04, loss: 3.0188\n",
      "Epoch [40][70/100], loss_cls: 0.0024582, depth_loss: 9.5525 lr: 1.25000e-04, loss: 3.9019\n",
      "Epoch [40][75/100], loss_cls: 1.6792, depth_loss: 8.2668 lr: 1.25000e-04, loss: 3.2952\n",
      "Epoch [40][80/100], loss_cls: 0.00024605, depth_loss: 9.9138 lr: 1.25000e-04, loss: 3.3214\n",
      "Epoch [40][85/100], loss_cls: 0.0040807, depth_loss: 6.7905 lr: 1.25000e-04, loss: 4.1138\n",
      "Epoch [40][90/100], loss_cls: 0.082824, depth_loss: 13.058 lr: 1.25000e-04, loss: 5.562\n",
      "Epoch [40][95/100], loss_cls: 1.7085, depth_loss: 29.47 lr: 1.25000e-04, loss: 3.7268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40][100/100], loss_cls: 1.6832, depth_loss: 15.941 lr: 1.25000e-04, loss: 4.4773\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 4.4773, val_loss: 3.3352\n",
      "Epoch [41][5/100], loss_cls: 0.038611, depth_loss: 19.606 lr: 1.25000e-04, loss: 3.3086\n",
      "Epoch [41][10/100], loss_cls: 0.98954, depth_loss: 24.888 lr: 1.25000e-04, loss: 3.7292\n",
      "Epoch [41][15/100], loss_cls: 0.031393, depth_loss: 12.466 lr: 1.25000e-04, loss: 3.2346\n",
      "Epoch [41][20/100], loss_cls: 1.844, depth_loss: 23.536 lr: 1.25000e-04, loss: 3.2911\n",
      "Epoch [41][25/100], loss_cls: 0.20531, depth_loss: 22.776 lr: 1.25000e-04, loss: 6.6536\n",
      "Epoch [41][30/100], loss_cls: 0.42943, depth_loss: 8.8557 lr: 1.25000e-04, loss: 2.7872\n",
      "Epoch [41][35/100], loss_cls: 0.07552, depth_loss: 19.889 lr: 1.25000e-04, loss: 2.1942\n",
      "Epoch [41][40/100], loss_cls: 0.0058587, depth_loss: 14.703 lr: 1.25000e-04, loss: 3.8145\n",
      "Epoch [41][45/100], loss_cls: 0.0098062, depth_loss: 13.838 lr: 1.25000e-04, loss: 3.1295\n",
      "Epoch [41][50/100], loss_cls: 0.048889, depth_loss: 38.472 lr: 1.25000e-04, loss: 5.5811\n",
      "Epoch [41][55/100], loss_cls: 0.02824, depth_loss: 12.863 lr: 1.25000e-04, loss: 4.0826\n",
      "Epoch [41][60/100], loss_cls: 4.512e-05, depth_loss: 14.765 lr: 1.25000e-04, loss: 2.6649\n",
      "Epoch [41][65/100], loss_cls: 0.012678, depth_loss: 12.816 lr: 1.25000e-04, loss: 3.0908\n",
      "Epoch [41][70/100], loss_cls: 0.0030563, depth_loss: 14.936 lr: 1.25000e-04, loss: 4.2395\n",
      "Epoch [41][75/100], loss_cls: 0.0070969, depth_loss: 7.4901 lr: 1.25000e-04, loss: 2.7161\n",
      "Epoch [41][80/100], loss_cls: 4.1723e-07, depth_loss: 27.107 lr: 1.25000e-04, loss: 3.3408\n",
      "Epoch [41][85/100], loss_cls: 0.10166, depth_loss: 12.256 lr: 1.25000e-04, loss: 3.7056\n",
      "Epoch [41][90/100], loss_cls: 1.6735, depth_loss: 11.912 lr: 1.25000e-04, loss: 4.186\n",
      "Epoch [41][95/100], loss_cls: 2.4209, depth_loss: 13.094 lr: 1.25000e-04, loss: 4.5077\n",
      "Epoch [41][100/100], loss_cls: 0.0033481, depth_loss: 12.828 lr: 1.25000e-04, loss: 3.5427\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 1.0, train_loss: 3.5427, val_loss: 2.9871\n",
      "Saving checkpoint at 41 epochs...\n",
      "Epoch [42][5/100], loss_cls: 1.6897, depth_loss: 24.602 lr: 1.25000e-04, loss: 3.5519\n",
      "Epoch [42][10/100], loss_cls: 1.5493, depth_loss: 12.519 lr: 1.25000e-04, loss: 3.7361\n",
      "Epoch [42][15/100], loss_cls: 0.0029158, depth_loss: 15.63 lr: 1.25000e-04, loss: 4.7228\n",
      "Epoch [42][20/100], loss_cls: 3.0695e-05, depth_loss: 10.013 lr: 1.25000e-04, loss: 4.0706\n",
      "Epoch [42][25/100], loss_cls: 0.0017302, depth_loss: 15.587 lr: 1.25000e-04, loss: 3.5046\n",
      "Epoch [42][30/100], loss_cls: 0.90903, depth_loss: 11.326 lr: 1.25000e-04, loss: 3.229\n",
      "Epoch [42][35/100], loss_cls: 4.2316, depth_loss: 33.585 lr: 1.25000e-04, loss: 4.5821\n",
      "Epoch [42][40/100], loss_cls: 0.0041285, depth_loss: 8.6634 lr: 1.25000e-04, loss: 2.4737\n",
      "Epoch [42][45/100], loss_cls: 1.6971, depth_loss: 11.36 lr: 1.25000e-04, loss: 4.2559\n",
      "Epoch [42][50/100], loss_cls: 2.122, depth_loss: 28.396 lr: 1.25000e-04, loss: 3.6929\n",
      "Epoch [42][55/100], loss_cls: 0.0084086, depth_loss: 19.155 lr: 1.25000e-04, loss: 3.4417\n",
      "Epoch [42][60/100], loss_cls: 5.2452e-06, depth_loss: 25.938 lr: 1.25000e-04, loss: 3.5321\n",
      "Epoch [42][65/100], loss_cls: 0.00039235, depth_loss: 21.164 lr: 1.25000e-04, loss: 4.5217\n",
      "Epoch [42][70/100], loss_cls: 0.07722, depth_loss: 9.4931 lr: 1.25000e-04, loss: 3.4774\n",
      "Epoch [42][75/100], loss_cls: 0.059966, depth_loss: 41.901 lr: 1.25000e-04, loss: 3.9413\n",
      "Epoch [42][80/100], loss_cls: 0.0052151, depth_loss: 13.996 lr: 1.25000e-04, loss: 2.552\n",
      "Epoch [42][85/100], loss_cls: 0.097497, depth_loss: 13.157 lr: 1.25000e-04, loss: 4.1862\n",
      "Epoch [42][90/100], loss_cls: 1.2621, depth_loss: 14.564 lr: 1.25000e-04, loss: 2.684\n",
      "Epoch [42][95/100], loss_cls: 3.7371e-05, depth_loss: 15.696 lr: 1.25000e-04, loss: 2.6885\n",
      "Epoch [42][100/100], loss_cls: 2.2404, depth_loss: 16.108 lr: 1.25000e-04, loss: 3.4423\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7429, top5_acc: 1.0, train_loss: 3.4423, val_loss: 3.2636\n",
      "Epoch [43][5/100], loss_cls: 0.033379, depth_loss: 13.599 lr: 1.25000e-04, loss: 3.0366\n",
      "Epoch [43][10/100], loss_cls: 0.60163, depth_loss: 15.741 lr: 1.25000e-04, loss: 3.1908\n",
      "Epoch [43][15/100], loss_cls: 0.75823, depth_loss: 9.7053 lr: 1.25000e-04, loss: 3.2871\n",
      "Epoch [43][20/100], loss_cls: 0.00071974, depth_loss: 19.047 lr: 1.25000e-04, loss: 4.7138\n",
      "Epoch [43][25/100], loss_cls: 2.7448, depth_loss: 35.275 lr: 1.25000e-04, loss: 4.8482\n",
      "Epoch [43][30/100], loss_cls: 0.013547, depth_loss: 15.979 lr: 1.25000e-04, loss: 3.4189\n",
      "Epoch [43][35/100], loss_cls: 0.0031249, depth_loss: 22.902 lr: 1.25000e-04, loss: 3.0971\n",
      "Epoch [43][40/100], loss_cls: 4.9231e-05, depth_loss: 10.26 lr: 1.25000e-04, loss: 3.2287\n",
      "Epoch [43][45/100], loss_cls: 0.024577, depth_loss: 17.531 lr: 1.25000e-04, loss: 4.5274\n",
      "Epoch [43][50/100], loss_cls: 2.2527, depth_loss: 11.408 lr: 1.25000e-04, loss: 4.1816\n",
      "Epoch [43][55/100], loss_cls: 0.039403, depth_loss: 16.349 lr: 1.25000e-04, loss: 3.1553\n",
      "Epoch [43][60/100], loss_cls: 0.0080351, depth_loss: 10.063 lr: 1.25000e-04, loss: 2.9422\n",
      "Epoch [43][65/100], loss_cls: 0.0082842, depth_loss: 13.647 lr: 1.25000e-04, loss: 3.7779\n",
      "Epoch [43][70/100], loss_cls: 0.32634, depth_loss: 14.579 lr: 1.25000e-04, loss: 3.1178\n",
      "Epoch [43][75/100], loss_cls: 2.022, depth_loss: 14.924 lr: 1.25000e-04, loss: 3.7338\n",
      "Epoch [43][80/100], loss_cls: 2.8192e-05, depth_loss: 11.672 lr: 1.25000e-04, loss: 3.7161\n",
      "Epoch [43][85/100], loss_cls: 0.88261, depth_loss: 18.141 lr: 1.25000e-04, loss: 2.836\n",
      "Epoch [43][90/100], loss_cls: 0.088376, depth_loss: 7.9132 lr: 1.25000e-04, loss: 2.5918\n",
      "Epoch [43][95/100], loss_cls: 0.11953, depth_loss: 16.643 lr: 1.25000e-04, loss: 3.1377\n",
      "Epoch [43][100/100], loss_cls: 1.9684, depth_loss: 9.7784 lr: 1.25000e-04, loss: 3.3792\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 3.3792, val_loss: 2.7602\n",
      "Saving checkpoint at 43 epochs...\n",
      "Epoch [44][5/100], loss_cls: 0.077222, depth_loss: 10.793 lr: 1.25000e-04, loss: 5.3949\n",
      "Epoch [44][10/100], loss_cls: 0.45421, depth_loss: 9.5981 lr: 1.25000e-04, loss: 4.0171\n",
      "Epoch [44][15/100], loss_cls: 0.0065335, depth_loss: 10.955 lr: 1.25000e-04, loss: 3.6382\n",
      "Epoch [44][20/100], loss_cls: 4.4587, depth_loss: 10.116 lr: 1.25000e-04, loss: 4.7183\n",
      "Epoch [44][25/100], loss_cls: 0.053891, depth_loss: 11.933 lr: 1.25000e-04, loss: 2.6709\n",
      "Epoch [44][30/100], loss_cls: 1.7057, depth_loss: 18.941 lr: 1.25000e-04, loss: 3.4786\n",
      "Epoch [44][35/100], loss_cls: 0.65913, depth_loss: 19.535 lr: 1.25000e-04, loss: 2.6606\n",
      "Epoch [44][40/100], loss_cls: 0.00040634, depth_loss: 22.615 lr: 1.25000e-04, loss: 5.2938\n",
      "Epoch [44][45/100], loss_cls: 0.007885, depth_loss: 15.412 lr: 1.25000e-04, loss: 3.978\n",
      "Epoch [44][50/100], loss_cls: 1.7226e-05, depth_loss: 20.652 lr: 1.25000e-04, loss: 3.5317\n",
      "Epoch [44][55/100], loss_cls: 1.4954, depth_loss: 25.868 lr: 1.25000e-04, loss: 4.4072\n",
      "Epoch [44][60/100], loss_cls: 0.074355, depth_loss: 16.51 lr: 1.25000e-04, loss: 3.6968\n",
      "Epoch [44][65/100], loss_cls: 0.0013892, depth_loss: 9.2621 lr: 1.25000e-04, loss: 2.9177\n",
      "Epoch [44][70/100], loss_cls: 0.00025933, depth_loss: 10.233 lr: 1.25000e-04, loss: 2.6565\n",
      "Epoch [44][75/100], loss_cls: 0.28647, depth_loss: 31.88 lr: 1.25000e-04, loss: 4.9574\n",
      "Epoch [44][80/100], loss_cls: 0.0019297, depth_loss: 18.442 lr: 1.25000e-04, loss: 3.6413\n",
      "Epoch [44][85/100], loss_cls: 3.0439, depth_loss: 40.661 lr: 1.25000e-04, loss: 4.9384\n",
      "Epoch [44][90/100], loss_cls: 0.00038849, depth_loss: 10.959 lr: 1.25000e-04, loss: 2.7936\n",
      "Epoch [44][95/100], loss_cls: 0.0017517, depth_loss: 10.242 lr: 1.25000e-04, loss: 6.7049\n",
      "Epoch [44][100/100], loss_cls: 1.924, depth_loss: 18.779 lr: 1.25000e-04, loss: 3.703\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.703, val_loss: 3.0674\n",
      "Epoch [45][5/100], loss_cls: 0.89408, depth_loss: 19.398 lr: 1.25000e-04, loss: 4.0746\n",
      "Epoch [45][10/100], loss_cls: 0.00023503, depth_loss: 12.151 lr: 1.25000e-04, loss: 3.5159\n",
      "Epoch [45][15/100], loss_cls: 0.24727, depth_loss: 4.769 lr: 1.25000e-04, loss: 2.9347\n",
      "Epoch [45][20/100], loss_cls: 8.8982e-05, depth_loss: 10.93 lr: 1.25000e-04, loss: 4.801\n",
      "Epoch [45][25/100], loss_cls: 9.4941e-05, depth_loss: 6.6054 lr: 1.25000e-04, loss: 3.2635\n",
      "Epoch [45][30/100], loss_cls: 2.7091, depth_loss: 13.382 lr: 1.25000e-04, loss: 3.4827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45][35/100], loss_cls: 7.2951e-05, depth_loss: 18.585 lr: 1.25000e-04, loss: 2.5783\n",
      "Epoch [45][40/100], loss_cls: 0.067118, depth_loss: 13.537 lr: 1.25000e-04, loss: 3.084\n",
      "Epoch [45][45/100], loss_cls: 0.035441, depth_loss: 18.687 lr: 1.25000e-04, loss: 4.6583\n",
      "Epoch [45][50/100], loss_cls: 0.0026531, depth_loss: 21.814 lr: 1.25000e-04, loss: 4.1173\n",
      "Epoch [45][55/100], loss_cls: 0.32674, depth_loss: 29.362 lr: 1.25000e-04, loss: 4.4839\n",
      "Epoch [45][60/100], loss_cls: 2.8914, depth_loss: 15.835 lr: 1.25000e-04, loss: 4.4765\n",
      "Epoch [45][65/100], loss_cls: 1.4484e-05, depth_loss: 7.8362 lr: 1.25000e-04, loss: 2.6254\n",
      "Epoch [45][70/100], loss_cls: 3.2186e-06, depth_loss: 19.001 lr: 1.25000e-04, loss: 3.7945\n",
      "Epoch [45][75/100], loss_cls: 1.5843, depth_loss: 22.447 lr: 1.25000e-04, loss: 5.4972\n",
      "Epoch [45][80/100], loss_cls: 0.8683, depth_loss: 17.801 lr: 1.25000e-04, loss: 2.6153\n",
      "Epoch [45][85/100], loss_cls: 0.00032874, depth_loss: 32.737 lr: 1.25000e-04, loss: 5.2296\n",
      "Epoch [45][90/100], loss_cls: 0.00028983, depth_loss: 15.748 lr: 1.25000e-04, loss: 3.606\n",
      "Epoch [45][95/100], loss_cls: 0.43737, depth_loss: 16.594 lr: 1.25000e-04, loss: 4.5495\n",
      "Epoch [45][100/100], loss_cls: 5.9899e-05, depth_loss: 21.021 lr: 1.25000e-04, loss: 4.4828\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 4.4828, val_loss: 2.7716\n",
      "Epoch [46][5/100], loss_cls: 2.6566, depth_loss: 12.718 lr: 1.25000e-04, loss: 3.3875\n",
      "Epoch [46][10/100], loss_cls: 0.00021828, depth_loss: 11.27 lr: 1.25000e-04, loss: 2.7121\n",
      "Epoch [46][15/100], loss_cls: 0.066904, depth_loss: 13.216 lr: 1.25000e-04, loss: 3.4858\n",
      "Epoch [46][20/100], loss_cls: 0.010423, depth_loss: 15.9 lr: 1.25000e-04, loss: 2.8487\n",
      "Epoch [46][25/100], loss_cls: 2.0504e-05, depth_loss: 9.7774 lr: 1.25000e-04, loss: 4.9955\n",
      "Epoch [46][30/100], loss_cls: 0.99722, depth_loss: 14.632 lr: 1.25000e-04, loss: 3.3155\n",
      "Epoch [46][35/100], loss_cls: 1.9494, depth_loss: 5.7793 lr: 1.25000e-04, loss: 2.819\n",
      "Epoch [46][40/100], loss_cls: 0.86566, depth_loss: 21.761 lr: 1.25000e-04, loss: 3.6528\n",
      "Epoch [46][45/100], loss_cls: 1.5437, depth_loss: 30.181 lr: 1.25000e-04, loss: 4.2994\n",
      "Epoch [46][50/100], loss_cls: 1.7777, depth_loss: 32.919 lr: 1.25000e-04, loss: 3.5233\n",
      "Epoch [46][55/100], loss_cls: 0.0039758, depth_loss: 11.634 lr: 1.25000e-04, loss: 3.4031\n",
      "Epoch [46][60/100], loss_cls: 0.00013505, depth_loss: 10.587 lr: 1.25000e-04, loss: 3.3893\n",
      "Epoch [46][65/100], loss_cls: 2.916, depth_loss: 24.388 lr: 1.25000e-04, loss: 5.2883\n",
      "Epoch [46][70/100], loss_cls: 0.85838, depth_loss: 11.451 lr: 1.25000e-04, loss: 2.6465\n",
      "Epoch [46][75/100], loss_cls: 0.00081685, depth_loss: 9.8769 lr: 1.25000e-04, loss: 4.8223\n",
      "Epoch [46][80/100], loss_cls: 8.0224e-05, depth_loss: 6.7096 lr: 1.25000e-04, loss: 3.3649\n",
      "Epoch [46][85/100], loss_cls: 0.38362, depth_loss: 21.681 lr: 1.25000e-04, loss: 3.7891\n",
      "Epoch [46][90/100], loss_cls: 0.58511, depth_loss: 21.937 lr: 1.25000e-04, loss: 3.1308\n",
      "Epoch [46][95/100], loss_cls: 4.1723e-06, depth_loss: 23.513 lr: 1.25000e-04, loss: 3.341\n",
      "Epoch [46][100/100], loss_cls: 5.6142, depth_loss: 10.757 lr: 1.25000e-04, loss: 4.6603\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 4.6603, val_loss: 3.8118\n",
      "Epoch [47][5/100], loss_cls: 0.00041319, depth_loss: 15.273 lr: 1.25000e-04, loss: 4.9141\n",
      "Epoch [47][10/100], loss_cls: 0.0002264, depth_loss: 11.802 lr: 1.25000e-04, loss: 2.9351\n",
      "Epoch [47][15/100], loss_cls: 3.9411, depth_loss: 14.304 lr: 1.25000e-04, loss: 7.2042\n",
      "Epoch [47][20/100], loss_cls: 0.43741, depth_loss: 12.282 lr: 1.25000e-04, loss: 3.8236\n",
      "Epoch [47][25/100], loss_cls: 0.64852, depth_loss: 18.706 lr: 1.25000e-04, loss: 3.5835\n",
      "Epoch [47][30/100], loss_cls: 0.72108, depth_loss: 42.704 lr: 1.25000e-04, loss: 5.2668\n",
      "Epoch [47][35/100], loss_cls: 5.9605e-08, depth_loss: 12.378 lr: 1.25000e-04, loss: 2.4039\n",
      "Epoch [47][40/100], loss_cls: 7.3845e-05, depth_loss: 30.42 lr: 1.25000e-04, loss: 4.2663\n",
      "Epoch [47][45/100], loss_cls: 0.0080847, depth_loss: 17.016 lr: 1.25000e-04, loss: 3.8648\n",
      "Epoch [47][50/100], loss_cls: 1.6635, depth_loss: 12.276 lr: 1.25000e-04, loss: 3.4413\n",
      "Epoch [47][55/100], loss_cls: 0.00016419, depth_loss: 13.575 lr: 1.25000e-04, loss: 4.3264\n",
      "Epoch [47][60/100], loss_cls: 0.0029037, depth_loss: 13.209 lr: 1.25000e-04, loss: 3.4728\n",
      "Epoch [47][65/100], loss_cls: 1.8247, depth_loss: 14.303 lr: 1.25000e-04, loss: 3.7959\n",
      "Epoch [47][70/100], loss_cls: 0.001492, depth_loss: 13.092 lr: 1.25000e-04, loss: 3.5537\n",
      "Epoch [47][75/100], loss_cls: 1.6093e-05, depth_loss: 8.7738 lr: 1.25000e-04, loss: 3.3887\n",
      "Epoch [47][80/100], loss_cls: 0.059137, depth_loss: 6.0434 lr: 1.25000e-04, loss: 4.0196\n",
      "Epoch [47][85/100], loss_cls: 0.001071, depth_loss: 14.484 lr: 1.25000e-04, loss: 4.2377\n",
      "Epoch [47][90/100], loss_cls: 1.4869, depth_loss: 18.41 lr: 1.25000e-04, loss: 3.8362\n",
      "Epoch [47][95/100], loss_cls: 0.13938, depth_loss: 11.533 lr: 1.25000e-04, loss: 2.2726\n",
      "Epoch [47][100/100], loss_cls: 0.0034887, depth_loss: 10.106 lr: 1.25000e-04, loss: 2.0819\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 1.0, train_loss: 2.0819, val_loss: 3.7884\n",
      "Epoch [48][5/100], loss_cls: 0.0013542, depth_loss: 12.444 lr: 1.25000e-04, loss: 3.5165\n",
      "Epoch [48][10/100], loss_cls: 0.011893, depth_loss: 27.71 lr: 1.25000e-04, loss: 5.058\n",
      "Epoch [48][15/100], loss_cls: 4.8698, depth_loss: 22.26 lr: 1.25000e-04, loss: 4.0977\n",
      "Epoch [48][20/100], loss_cls: 0.0013824, depth_loss: 11.826 lr: 1.25000e-04, loss: 4.7777\n",
      "Epoch [48][25/100], loss_cls: 0.00081151, depth_loss: 12.614 lr: 1.25000e-04, loss: 2.7305\n",
      "Epoch [48][30/100], loss_cls: 0.13867, depth_loss: 10.821 lr: 1.25000e-04, loss: 2.5402\n",
      "Epoch [48][35/100], loss_cls: 1.5253, depth_loss: 14.009 lr: 1.25000e-04, loss: 3.304\n",
      "Epoch [48][40/100], loss_cls: 0.028711, depth_loss: 6.3951 lr: 1.25000e-04, loss: 2.8734\n",
      "Epoch [48][45/100], loss_cls: 0.00080875, depth_loss: 11.839 lr: 1.25000e-04, loss: 2.7149\n",
      "Epoch [48][50/100], loss_cls: 0.10535, depth_loss: 8.1568 lr: 1.25000e-04, loss: 2.4271\n",
      "Epoch [48][55/100], loss_cls: 0.080658, depth_loss: 8.9901 lr: 1.25000e-04, loss: 2.6817\n",
      "Epoch [48][60/100], loss_cls: 0.087346, depth_loss: 14.3 lr: 1.25000e-04, loss: 3.0535\n",
      "Epoch [48][65/100], loss_cls: 0.26696, depth_loss: 21.994 lr: 1.25000e-04, loss: 3.1862\n",
      "Epoch [48][70/100], loss_cls: 0.010642, depth_loss: 8.757 lr: 1.25000e-04, loss: 3.6443\n",
      "Epoch [48][75/100], loss_cls: 1.4452, depth_loss: 29.742 lr: 1.25000e-04, loss: 3.2815\n",
      "Epoch [48][80/100], loss_cls: 0.073597, depth_loss: 13.768 lr: 1.25000e-04, loss: 2.6661\n",
      "Epoch [48][85/100], loss_cls: 1.3959, depth_loss: 25.211 lr: 1.25000e-04, loss: 3.3852\n",
      "Epoch [48][90/100], loss_cls: 0.39251, depth_loss: 15.219 lr: 1.25000e-04, loss: 4.6702\n",
      "Epoch [48][95/100], loss_cls: 0.0079525, depth_loss: 6.4119 lr: 1.25000e-04, loss: 2.4916\n",
      "Epoch [48][100/100], loss_cls: 1.4484e-05, depth_loss: 13.423 lr: 1.25000e-04, loss: 2.5036\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7143, top5_acc: 0.9429, train_loss: 2.5036, val_loss: 3.4546\n",
      "Epoch [49][5/100], loss_cls: 0.00062933, depth_loss: 14.298 lr: 1.25000e-04, loss: 3.1384\n",
      "Epoch [49][10/100], loss_cls: 1.8562, depth_loss: 15.325 lr: 1.25000e-04, loss: 3.5436\n",
      "Epoch [49][15/100], loss_cls: 0.93914, depth_loss: 12.61 lr: 1.25000e-04, loss: 2.2771\n",
      "Epoch [49][20/100], loss_cls: 0.18865, depth_loss: 18.0 lr: 1.25000e-04, loss: 3.8402\n",
      "Epoch [49][25/100], loss_cls: 0.0, depth_loss: 17.241 lr: 1.25000e-04, loss: 2.6499\n",
      "Epoch [49][30/100], loss_cls: 1.653, depth_loss: 16.271 lr: 1.25000e-04, loss: 4.8196\n",
      "Epoch [49][35/100], loss_cls: 0.43692, depth_loss: 32.565 lr: 1.25000e-04, loss: 4.4841\n",
      "Epoch [49][40/100], loss_cls: 0.046544, depth_loss: 14.999 lr: 1.25000e-04, loss: 3.8528\n",
      "Epoch [49][45/100], loss_cls: 0.0047239, depth_loss: 21.949 lr: 1.25000e-04, loss: 3.1377\n",
      "Epoch [49][50/100], loss_cls: 0.63622, depth_loss: 29.423 lr: 1.25000e-04, loss: 3.746\n",
      "Epoch [49][55/100], loss_cls: 0.038534, depth_loss: 12.831 lr: 1.25000e-04, loss: 2.9645\n",
      "Epoch [49][60/100], loss_cls: 0.10272, depth_loss: 12.692 lr: 1.25000e-04, loss: 2.4183\n",
      "Epoch [49][65/100], loss_cls: 0.0, depth_loss: 12.542 lr: 1.25000e-04, loss: 2.3598\n",
      "Epoch [49][70/100], loss_cls: 0.0019412, depth_loss: 6.9875 lr: 1.25000e-04, loss: 4.4958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49][75/100], loss_cls: 0.096894, depth_loss: 8.926 lr: 1.25000e-04, loss: 3.9166\n",
      "Epoch [49][80/100], loss_cls: 1.2954, depth_loss: 14.85 lr: 1.25000e-04, loss: 4.7167\n",
      "Epoch [49][85/100], loss_cls: 1.8596e-05, depth_loss: 23.595 lr: 1.25000e-04, loss: 2.5723\n",
      "Epoch [49][90/100], loss_cls: 0.064701, depth_loss: 18.801 lr: 1.25000e-04, loss: 4.6926\n",
      "Epoch [49][95/100], loss_cls: 0.0, depth_loss: 24.522 lr: 1.25000e-04, loss: 3.4999\n",
      "Epoch [49][100/100], loss_cls: 0.0022952, depth_loss: 14.969 lr: 1.25000e-04, loss: 2.9591\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7714, top5_acc: 0.9714, train_loss: 2.9591, val_loss: 3.109\n",
      "Epoch [50][5/100], loss_cls: 1.0049, depth_loss: 16.674 lr: 1.25000e-04, loss: 2.871\n",
      "Epoch [50][10/100], loss_cls: 2.044, depth_loss: 20.91 lr: 1.25000e-04, loss: 3.9998\n",
      "Epoch [50][15/100], loss_cls: 0.0055266, depth_loss: 26.357 lr: 1.25000e-04, loss: 3.6795\n",
      "Epoch [50][20/100], loss_cls: 0.00038984, depth_loss: 8.6447 lr: 1.25000e-04, loss: 4.1053\n",
      "Epoch [50][25/100], loss_cls: 0.19751, depth_loss: 11.109 lr: 1.25000e-04, loss: 2.3706\n",
      "Epoch [50][30/100], loss_cls: 0.00021811, depth_loss: 17.317 lr: 1.25000e-04, loss: 2.7658\n",
      "Epoch [50][35/100], loss_cls: 0.13788, depth_loss: 10.595 lr: 1.25000e-04, loss: 5.1946\n",
      "Epoch [50][40/100], loss_cls: 0.017958, depth_loss: 13.767 lr: 1.25000e-04, loss: 3.5279\n",
      "Epoch [50][45/100], loss_cls: 0.19558, depth_loss: 9.3548 lr: 1.25000e-04, loss: 2.7662\n",
      "Epoch [50][50/100], loss_cls: 4.3152e-05, depth_loss: 21.6 lr: 1.25000e-04, loss: 3.2151\n",
      "Epoch [50][55/100], loss_cls: 0.025945, depth_loss: 19.892 lr: 1.25000e-04, loss: 3.1034\n",
      "Epoch [50][60/100], loss_cls: 0.024298, depth_loss: 6.581 lr: 1.25000e-04, loss: 3.2063\n",
      "Epoch [50][65/100], loss_cls: 0.0, depth_loss: 9.0186 lr: 1.25000e-04, loss: 5.018\n",
      "Epoch [50][70/100], loss_cls: 0.00069856, depth_loss: 6.5279 lr: 1.25000e-04, loss: 1.876\n",
      "Epoch [50][75/100], loss_cls: 0.010662, depth_loss: 11.567 lr: 1.25000e-04, loss: 3.733\n",
      "Epoch [50][80/100], loss_cls: 4.5536e-05, depth_loss: 9.9889 lr: 1.25000e-04, loss: 3.3674\n",
      "Epoch [50][85/100], loss_cls: 0.16254, depth_loss: 6.4891 lr: 1.25000e-04, loss: 2.3293\n",
      "Epoch [50][90/100], loss_cls: 2.045, depth_loss: 16.121 lr: 1.25000e-04, loss: 2.9997\n",
      "Epoch [50][95/100], loss_cls: 0.10638, depth_loss: 8.2038 lr: 1.25000e-04, loss: 3.304\n",
      "Epoch [50][100/100], loss_cls: 0.002295, depth_loss: 9.0618 lr: 1.25000e-04, loss: 3.166\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.166, val_loss: 2.684\n",
      "Saving checkpoint at 50 epochs...\n",
      "Epoch [51][5/100], loss_cls: 0.00035011, depth_loss: 8.392 lr: 1.25000e-04, loss: 4.0265\n",
      "Epoch [51][10/100], loss_cls: 0.23032, depth_loss: 8.2853 lr: 1.25000e-04, loss: 3.0909\n",
      "Epoch [51][15/100], loss_cls: 0.15221, depth_loss: 14.689 lr: 1.25000e-04, loss: 3.7578\n",
      "Epoch [51][20/100], loss_cls: 0.0056965, depth_loss: 7.9595 lr: 1.25000e-04, loss: 3.1067\n",
      "Epoch [51][25/100], loss_cls: 0.0007203, depth_loss: 6.4585 lr: 1.25000e-04, loss: 3.2194\n",
      "Epoch [51][30/100], loss_cls: 0.00090897, depth_loss: 16.384 lr: 1.25000e-04, loss: 3.914\n",
      "Epoch [51][35/100], loss_cls: 0.07642, depth_loss: 17.835 lr: 1.25000e-04, loss: 3.6413\n",
      "Epoch [51][40/100], loss_cls: 0.5811, depth_loss: 6.0285 lr: 1.25000e-04, loss: 1.781\n",
      "Epoch [51][45/100], loss_cls: 0.085181, depth_loss: 9.8752 lr: 1.25000e-04, loss: 4.105\n",
      "Epoch [51][50/100], loss_cls: 1.9073e-06, depth_loss: 13.256 lr: 1.25000e-04, loss: 2.1519\n",
      "Epoch [51][55/100], loss_cls: 0.088401, depth_loss: 11.789 lr: 1.25000e-04, loss: 2.3526\n",
      "Epoch [51][60/100], loss_cls: 0.00055539, depth_loss: 10.94 lr: 1.25000e-04, loss: 2.8818\n",
      "Epoch [51][65/100], loss_cls: 3.236, depth_loss: 57.083 lr: 1.25000e-04, loss: 4.5743\n",
      "Epoch [51][70/100], loss_cls: 0.080181, depth_loss: 19.257 lr: 1.25000e-04, loss: 3.6432\n",
      "Epoch [51][75/100], loss_cls: 0.00043972, depth_loss: 19.919 lr: 1.25000e-04, loss: 3.8993\n",
      "Epoch [51][80/100], loss_cls: 0.002362, depth_loss: 11.536 lr: 1.25000e-04, loss: 3.9859\n",
      "Epoch [51][85/100], loss_cls: 0.64826, depth_loss: 13.827 lr: 1.25000e-04, loss: 4.7917\n",
      "Epoch [51][90/100], loss_cls: 0.0010491, depth_loss: 12.672 lr: 1.25000e-04, loss: 3.618\n",
      "Epoch [51][95/100], loss_cls: 0.00028955, depth_loss: 7.8761 lr: 1.25000e-04, loss: 3.2544\n",
      "Epoch [51][100/100], loss_cls: 0.18638, depth_loss: 16.483 lr: 1.25000e-04, loss: 2.8662\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.7714, top5_acc: 1.0, train_loss: 2.8662, val_loss: 3.5137\n",
      "Epoch [52][5/100], loss_cls: 0.013815, depth_loss: 7.8933 lr: 1.25000e-05, loss: 2.4313\n",
      "Epoch [52][10/100], loss_cls: 1.3242, depth_loss: 24.09 lr: 1.25000e-05, loss: 3.4224\n",
      "Epoch [52][15/100], loss_cls: 5.9605e-08, depth_loss: 15.468 lr: 1.25000e-05, loss: 3.963\n",
      "Epoch [52][20/100], loss_cls: 0.0, depth_loss: 13.162 lr: 1.25000e-05, loss: 3.7675\n",
      "Epoch [52][25/100], loss_cls: 1.0476, depth_loss: 13.129 lr: 1.25000e-05, loss: 2.476\n",
      "Epoch [52][30/100], loss_cls: 3.4571e-06, depth_loss: 14.993 lr: 1.25000e-05, loss: 2.5507\n",
      "Epoch [52][35/100], loss_cls: 4.9887e-05, depth_loss: 15.555 lr: 1.25000e-05, loss: 2.3001\n",
      "Epoch [52][40/100], loss_cls: 0.010794, depth_loss: 26.109 lr: 1.25000e-05, loss: 4.325\n",
      "Epoch [52][45/100], loss_cls: 0.0010267, depth_loss: 15.497 lr: 1.25000e-05, loss: 2.3832\n",
      "Epoch [52][50/100], loss_cls: 0.00012832, depth_loss: 6.7857 lr: 1.25000e-05, loss: 2.2657\n",
      "Epoch [52][55/100], loss_cls: 0.00038085, depth_loss: 9.9408 lr: 1.25000e-05, loss: 2.5876\n",
      "Epoch [52][60/100], loss_cls: 0.72205, depth_loss: 14.653 lr: 1.25000e-05, loss: 3.2892\n",
      "Epoch [52][65/100], loss_cls: 0.0013914, depth_loss: 12.641 lr: 1.25000e-05, loss: 2.3661\n",
      "Epoch [52][70/100], loss_cls: 0.53707, depth_loss: 11.652 lr: 1.25000e-05, loss: 3.145\n",
      "Epoch [52][75/100], loss_cls: 0.42079, depth_loss: 9.709 lr: 1.25000e-05, loss: 2.8136\n",
      "Epoch [52][80/100], loss_cls: 0.0043436, depth_loss: 25.107 lr: 1.25000e-05, loss: 3.6319\n",
      "Epoch [52][85/100], loss_cls: 0.00099729, depth_loss: 11.278 lr: 1.25000e-05, loss: 2.9555\n",
      "Epoch [52][90/100], loss_cls: 0.00091023, depth_loss: 8.7155 lr: 1.25000e-05, loss: 2.1773\n",
      "Epoch [52][95/100], loss_cls: 5.9008e-06, depth_loss: 7.047 lr: 1.25000e-05, loss: 2.6941\n",
      "Epoch [52][100/100], loss_cls: 8.094e-05, depth_loss: 12.201 lr: 1.25000e-05, loss: 3.0099\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 1.0, train_loss: 3.0099, val_loss: 3.054\n",
      "Epoch [53][5/100], loss_cls: 0.058096, depth_loss: 14.084 lr: 1.25000e-05, loss: 2.274\n",
      "Epoch [53][10/100], loss_cls: 0.00077539, depth_loss: 9.239 lr: 1.25000e-05, loss: 3.5193\n",
      "Epoch [53][15/100], loss_cls: 1.0607, depth_loss: 23.079 lr: 1.25000e-05, loss: 3.4076\n",
      "Epoch [53][20/100], loss_cls: 6.1806e-05, depth_loss: 9.9608 lr: 1.25000e-05, loss: 2.2721\n",
      "Epoch [53][25/100], loss_cls: 1.955e-05, depth_loss: 13.637 lr: 1.25000e-05, loss: 4.0145\n",
      "Epoch [53][30/100], loss_cls: 0.34788, depth_loss: 30.52 lr: 1.25000e-05, loss: 3.4278\n",
      "Epoch [53][35/100], loss_cls: 0.034122, depth_loss: 10.633 lr: 1.25000e-05, loss: 2.2437\n",
      "Epoch [53][40/100], loss_cls: 0.0033058, depth_loss: 12.891 lr: 1.25000e-05, loss: 2.5781\n",
      "Epoch [53][45/100], loss_cls: 0.00089295, depth_loss: 18.249 lr: 1.25000e-05, loss: 2.6591\n",
      "Epoch [53][50/100], loss_cls: 0.20297, depth_loss: 13.527 lr: 1.25000e-05, loss: 2.157\n",
      "Epoch [53][55/100], loss_cls: 1.7047e-05, depth_loss: 15.479 lr: 1.25000e-05, loss: 2.2344\n",
      "Epoch [53][60/100], loss_cls: 0.00058468, depth_loss: 6.8035 lr: 1.25000e-05, loss: 3.1724\n",
      "Epoch [53][65/100], loss_cls: 0.0034885, depth_loss: 6.2508 lr: 1.25000e-05, loss: 3.354\n",
      "Epoch [53][70/100], loss_cls: 0.017431, depth_loss: 7.2934 lr: 1.25000e-05, loss: 3.6628\n",
      "Epoch [53][75/100], loss_cls: 2.3367, depth_loss: 72.243 lr: 1.25000e-05, loss: 6.1051\n",
      "Epoch [53][80/100], loss_cls: 0.0033741, depth_loss: 16.683 lr: 1.25000e-05, loss: 2.8814\n",
      "Epoch [53][85/100], loss_cls: 0.00022296, depth_loss: 6.5552 lr: 1.25000e-05, loss: 1.7142\n",
      "Epoch [53][90/100], loss_cls: 0.024449, depth_loss: 8.0584 lr: 1.25000e-05, loss: 2.0381\n",
      "Epoch [53][95/100], loss_cls: 5.424e-06, depth_loss: 15.444 lr: 1.25000e-05, loss: 3.0158\n",
      "Epoch [53][100/100], loss_cls: 0.099331, depth_loss: 12.214 lr: 1.25000e-05, loss: 3.0214\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 3.0214, val_loss: 2.931\n",
      "Epoch [54][5/100], loss_cls: 0.00011264, depth_loss: 10.62 lr: 1.25000e-05, loss: 2.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54][10/100], loss_cls: 0.00084812, depth_loss: 7.8044 lr: 1.25000e-05, loss: 2.0141\n",
      "Epoch [54][15/100], loss_cls: 0.95886, depth_loss: 18.697 lr: 1.25000e-05, loss: 3.6439\n",
      "Epoch [54][20/100], loss_cls: 5.0068e-06, depth_loss: 12.201 lr: 1.25000e-05, loss: 2.1327\n",
      "Epoch [54][25/100], loss_cls: 0.0016625, depth_loss: 11.725 lr: 1.25000e-05, loss: 3.1742\n",
      "Epoch [54][30/100], loss_cls: 0.00050313, depth_loss: 12.959 lr: 1.25000e-05, loss: 2.1921\n",
      "Epoch [54][35/100], loss_cls: 0.96749, depth_loss: 11.592 lr: 1.25000e-05, loss: 2.2028\n",
      "Epoch [54][40/100], loss_cls: 0.24686, depth_loss: 13.272 lr: 1.25000e-05, loss: 2.0767\n",
      "Epoch [54][45/100], loss_cls: 0.011055, depth_loss: 21.078 lr: 1.25000e-05, loss: 2.4033\n",
      "Epoch [54][50/100], loss_cls: 4.345e-05, depth_loss: 9.8942 lr: 1.25000e-05, loss: 1.8253\n",
      "Epoch [54][55/100], loss_cls: 0.010467, depth_loss: 10.997 lr: 1.25000e-05, loss: 2.8469\n",
      "Epoch [54][60/100], loss_cls: 0.00039463, depth_loss: 9.7057 lr: 1.25000e-05, loss: 3.3621\n",
      "Epoch [54][65/100], loss_cls: 0.38901, depth_loss: 17.121 lr: 1.25000e-05, loss: 2.2449\n",
      "Epoch [54][70/100], loss_cls: 0.03804, depth_loss: 7.6022 lr: 1.25000e-05, loss: 2.8711\n",
      "Epoch [54][75/100], loss_cls: 0.11165, depth_loss: 7.5677 lr: 1.25000e-05, loss: 2.3259\n",
      "Epoch [54][80/100], loss_cls: 0.00024688, depth_loss: 11.037 lr: 1.25000e-05, loss: 3.428\n",
      "Epoch [54][85/100], loss_cls: 0.086054, depth_loss: 7.5398 lr: 1.25000e-05, loss: 2.3826\n",
      "Epoch [54][90/100], loss_cls: 0.00038644, depth_loss: 11.122 lr: 1.25000e-05, loss: 2.1972\n",
      "Epoch [54][95/100], loss_cls: 0.46853, depth_loss: 9.2998 lr: 1.25000e-05, loss: 3.6173\n",
      "Epoch [54][100/100], loss_cls: 1.6093e-05, depth_loss: 12.768 lr: 1.25000e-05, loss: 2.4917\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.4917, val_loss: 2.9107\n",
      "Epoch [55][5/100], loss_cls: 0.019691, depth_loss: 6.305 lr: 1.25000e-05, loss: 2.9143\n",
      "Epoch [55][10/100], loss_cls: 0.053128, depth_loss: 10.018 lr: 1.25000e-05, loss: 2.9905\n",
      "Epoch [55][15/100], loss_cls: 0.039757, depth_loss: 15.345 lr: 1.25000e-05, loss: 2.2656\n",
      "Epoch [55][20/100], loss_cls: 0.060539, depth_loss: 10.387 lr: 1.25000e-05, loss: 4.0311\n",
      "Epoch [55][25/100], loss_cls: 3.5763e-07, depth_loss: 12.762 lr: 1.25000e-05, loss: 2.1234\n",
      "Epoch [55][30/100], loss_cls: 3.6656e-05, depth_loss: 6.831 lr: 1.25000e-05, loss: 2.8641\n",
      "Epoch [55][35/100], loss_cls: 0.007809, depth_loss: 9.4427 lr: 1.25000e-05, loss: 2.1655\n",
      "Epoch [55][40/100], loss_cls: 0.013149, depth_loss: 8.9777 lr: 1.25000e-05, loss: 2.4591\n",
      "Epoch [55][45/100], loss_cls: 0.13577, depth_loss: 10.006 lr: 1.25000e-05, loss: 2.3536\n",
      "Epoch [55][50/100], loss_cls: 3.898e-05, depth_loss: 19.782 lr: 1.25000e-05, loss: 3.3289\n",
      "Epoch [55][55/100], loss_cls: 3.5763e-06, depth_loss: 15.07 lr: 1.25000e-05, loss: 3.5684\n",
      "Epoch [55][60/100], loss_cls: 0.011805, depth_loss: 17.758 lr: 1.25000e-05, loss: 2.6096\n",
      "Epoch [55][65/100], loss_cls: 0.0088463, depth_loss: 10.621 lr: 1.25000e-05, loss: 2.5825\n",
      "Epoch [55][70/100], loss_cls: 0.0317, depth_loss: 15.137 lr: 1.25000e-05, loss: 3.0399\n",
      "Epoch [55][75/100], loss_cls: 2.7031, depth_loss: 13.559 lr: 1.25000e-05, loss: 2.5664\n",
      "Epoch [55][80/100], loss_cls: 5.9605e-08, depth_loss: 8.0959 lr: 1.25000e-05, loss: 1.9522\n",
      "Epoch [55][85/100], loss_cls: 0.012724, depth_loss: 10.325 lr: 1.25000e-05, loss: 2.1042\n",
      "Epoch [55][90/100], loss_cls: 0.73165, depth_loss: 9.8894 lr: 1.25000e-05, loss: 2.3576\n",
      "Epoch [55][95/100], loss_cls: 0.0081335, depth_loss: 17.393 lr: 1.25000e-05, loss: 2.8985\n",
      "Epoch [55][100/100], loss_cls: 0.058936, depth_loss: 10.209 lr: 1.25000e-05, loss: 2.1423\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.1423, val_loss: 2.8278\n",
      "Epoch [56][5/100], loss_cls: 0.0028305, depth_loss: 5.032 lr: 1.25000e-05, loss: 3.0719\n",
      "Epoch [56][10/100], loss_cls: 0.0022701, depth_loss: 15.693 lr: 1.25000e-05, loss: 2.8582\n",
      "Epoch [56][15/100], loss_cls: 3.302e-05, depth_loss: 6.9827 lr: 1.25000e-05, loss: 2.5583\n",
      "Epoch [56][20/100], loss_cls: 6.7949e-06, depth_loss: 22.273 lr: 1.25000e-05, loss: 2.719\n",
      "Epoch [56][25/100], loss_cls: 0.00034971, depth_loss: 11.923 lr: 1.25000e-05, loss: 3.685\n",
      "Epoch [56][30/100], loss_cls: 0.00089779, depth_loss: 11.019 lr: 1.25000e-05, loss: 2.1558\n",
      "Epoch [56][35/100], loss_cls: 0.076533, depth_loss: 16.921 lr: 1.25000e-05, loss: 3.0836\n",
      "Epoch [56][40/100], loss_cls: 1.3145, depth_loss: 12.734 lr: 1.25000e-05, loss: 3.2014\n",
      "Epoch [56][45/100], loss_cls: 0.0017709, depth_loss: 7.2494 lr: 1.25000e-05, loss: 2.4266\n",
      "Epoch [56][50/100], loss_cls: 0.0001096, depth_loss: 11.176 lr: 1.25000e-05, loss: 3.0813\n",
      "Epoch [56][55/100], loss_cls: 1.6203, depth_loss: 31.635 lr: 1.25000e-05, loss: 3.0784\n",
      "Epoch [56][60/100], loss_cls: 0.024379, depth_loss: 8.1397 lr: 1.25000e-05, loss: 1.9897\n",
      "Epoch [56][65/100], loss_cls: 5.9605e-07, depth_loss: 10.878 lr: 1.25000e-05, loss: 3.1424\n",
      "Epoch [56][70/100], loss_cls: 0.0028039, depth_loss: 9.4448 lr: 1.25000e-05, loss: 2.1505\n",
      "Epoch [56][75/100], loss_cls: 0.47882, depth_loss: 11.69 lr: 1.25000e-05, loss: 2.2728\n",
      "Epoch [56][80/100], loss_cls: 0.00018993, depth_loss: 7.331 lr: 1.25000e-05, loss: 1.8237\n",
      "Epoch [56][85/100], loss_cls: 0.36109, depth_loss: 9.6699 lr: 1.25000e-05, loss: 2.8158\n",
      "Epoch [56][90/100], loss_cls: 0.041564, depth_loss: 15.095 lr: 1.25000e-05, loss: 2.8202\n",
      "Epoch [56][95/100], loss_cls: 0.00029458, depth_loss: 7.345 lr: 1.25000e-05, loss: 2.5839\n",
      "Epoch [56][100/100], loss_cls: 3.1291e-05, depth_loss: 11.222 lr: 1.25000e-05, loss: 2.7036\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 2.7036, val_loss: 2.7568\n",
      "Epoch [57][5/100], loss_cls: 1.9139, depth_loss: 12.556 lr: 1.25000e-05, loss: 2.5004\n",
      "Epoch [57][10/100], loss_cls: 0.0, depth_loss: 10.86 lr: 1.25000e-05, loss: 3.7208\n",
      "Epoch [57][15/100], loss_cls: 0.00041748, depth_loss: 9.3461 lr: 1.25000e-05, loss: 1.9554\n",
      "Epoch [57][20/100], loss_cls: 0.0024922, depth_loss: 19.238 lr: 1.25000e-05, loss: 2.4552\n",
      "Epoch [57][25/100], loss_cls: 1.7999, depth_loss: 33.468 lr: 1.25000e-05, loss: 3.9091\n",
      "Epoch [57][30/100], loss_cls: 5.8409e-05, depth_loss: 6.3083 lr: 1.25000e-05, loss: 3.3664\n",
      "Epoch [57][35/100], loss_cls: 0.00010775, depth_loss: 25.056 lr: 1.25000e-05, loss: 3.7321\n",
      "Epoch [57][40/100], loss_cls: 4.6191e-05, depth_loss: 9.0533 lr: 1.25000e-05, loss: 2.6208\n",
      "Epoch [57][45/100], loss_cls: 1.6093, depth_loss: 11.992 lr: 1.25000e-05, loss: 3.401\n",
      "Epoch [57][50/100], loss_cls: 4.1723e-07, depth_loss: 10.943 lr: 1.25000e-05, loss: 3.4749\n",
      "Epoch [57][55/100], loss_cls: 0.0025538, depth_loss: 12.624 lr: 1.25000e-05, loss: 3.5212\n",
      "Epoch [57][60/100], loss_cls: 0.043108, depth_loss: 10.06 lr: 1.25000e-05, loss: 2.7231\n",
      "Epoch [57][65/100], loss_cls: 0.00016431, depth_loss: 5.3649 lr: 1.25000e-05, loss: 1.6521\n",
      "Epoch [57][70/100], loss_cls: 7.3909e-06, depth_loss: 9.1437 lr: 1.25000e-05, loss: 2.4581\n",
      "Epoch [57][75/100], loss_cls: 4.0888e-05, depth_loss: 14.244 lr: 1.25000e-05, loss: 2.3922\n",
      "Epoch [57][80/100], loss_cls: 2.8192e-05, depth_loss: 10.857 lr: 1.25000e-05, loss: 2.1932\n",
      "Epoch [57][85/100], loss_cls: 1.9312e-05, depth_loss: 20.394 lr: 1.25000e-05, loss: 3.7776\n",
      "Epoch [57][90/100], loss_cls: 0.38417, depth_loss: 8.7591 lr: 1.25000e-05, loss: 2.8657\n",
      "Epoch [57][95/100], loss_cls: 0.00066117, depth_loss: 6.7226 lr: 1.25000e-05, loss: 2.569\n",
      "Epoch [57][100/100], loss_cls: 0.003457, depth_loss: 13.744 lr: 1.25000e-05, loss: 2.704\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 2.704, val_loss: 2.7638\n",
      "Epoch [58][5/100], loss_cls: 1.5159, depth_loss: 40.783 lr: 1.25000e-05, loss: 3.8073\n",
      "Epoch [58][10/100], loss_cls: 1.2428, depth_loss: 13.948 lr: 1.25000e-05, loss: 2.5048\n",
      "Epoch [58][15/100], loss_cls: 0.88015, depth_loss: 10.604 lr: 1.25000e-05, loss: 2.5881\n",
      "Epoch [58][20/100], loss_cls: 0.0097925, depth_loss: 19.693 lr: 1.25000e-05, loss: 3.6869\n",
      "Epoch [58][25/100], loss_cls: 0.0012116, depth_loss: 10.978 lr: 1.25000e-05, loss: 2.5218\n",
      "Epoch [58][30/100], loss_cls: 0.044358, depth_loss: 11.84 lr: 1.25000e-05, loss: 2.2707\n",
      "Epoch [58][35/100], loss_cls: 2.9802e-06, depth_loss: 9.6576 lr: 1.25000e-05, loss: 2.5786\n",
      "Epoch [58][40/100], loss_cls: 0.033068, depth_loss: 14.465 lr: 1.25000e-05, loss: 2.9283\n",
      "Epoch [58][45/100], loss_cls: 0.0014912, depth_loss: 10.514 lr: 1.25000e-05, loss: 2.9721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58][50/100], loss_cls: 0.00055687, depth_loss: 13.484 lr: 1.25000e-05, loss: 2.5501\n",
      "Epoch [58][55/100], loss_cls: 0.00011038, depth_loss: 10.628 lr: 1.25000e-05, loss: 4.3178\n",
      "Epoch [58][60/100], loss_cls: 1.6212e-05, depth_loss: 17.454 lr: 1.25000e-05, loss: 2.9097\n",
      "Epoch [58][65/100], loss_cls: 0.017458, depth_loss: 9.1222 lr: 1.25000e-05, loss: 2.0974\n",
      "Epoch [58][70/100], loss_cls: 2.688, depth_loss: 15.282 lr: 1.25000e-05, loss: 2.8827\n",
      "Epoch [58][75/100], loss_cls: 0.012625, depth_loss: 8.7055 lr: 1.25000e-05, loss: 2.125\n",
      "Epoch [58][80/100], loss_cls: 0.0059511, depth_loss: 9.0063 lr: 1.25000e-05, loss: 1.9673\n",
      "Epoch [58][85/100], loss_cls: 9.5897e-05, depth_loss: 11.131 lr: 1.25000e-05, loss: 2.2158\n",
      "Epoch [58][90/100], loss_cls: 0.16175, depth_loss: 24.561 lr: 1.25000e-05, loss: 3.9873\n",
      "Epoch [58][95/100], loss_cls: 0.076782, depth_loss: 11.33 lr: 1.25000e-05, loss: 2.3201\n",
      "Epoch [58][100/100], loss_cls: 0.22257, depth_loss: 14.939 lr: 1.25000e-05, loss: 2.9294\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.9294, val_loss: 2.7527\n",
      "Epoch [59][5/100], loss_cls: 3.308e-05, depth_loss: 8.0406 lr: 1.25000e-05, loss: 1.7693\n",
      "Epoch [59][10/100], loss_cls: 0.085738, depth_loss: 11.868 lr: 1.25000e-05, loss: 2.2171\n",
      "Epoch [59][15/100], loss_cls: 0.03705, depth_loss: 9.3547 lr: 1.25000e-05, loss: 2.8451\n",
      "Epoch [59][20/100], loss_cls: 0.056864, depth_loss: 7.1103 lr: 1.25000e-05, loss: 2.7266\n",
      "Epoch [59][25/100], loss_cls: 0.00023324, depth_loss: 13.59 lr: 1.25000e-05, loss: 2.2849\n",
      "Epoch [59][30/100], loss_cls: 0.0013895, depth_loss: 7.8578 lr: 1.25000e-05, loss: 3.0314\n",
      "Epoch [59][35/100], loss_cls: 2.0563e-05, depth_loss: 11.793 lr: 1.25000e-05, loss: 2.2451\n",
      "Epoch [59][40/100], loss_cls: 0.65692, depth_loss: 8.8302 lr: 1.25000e-05, loss: 2.8714\n",
      "Epoch [59][45/100], loss_cls: 0.0041683, depth_loss: 8.1851 lr: 1.25000e-05, loss: 3.0058\n",
      "Epoch [59][50/100], loss_cls: 0.0003229, depth_loss: 8.5233 lr: 1.25000e-05, loss: 2.7254\n",
      "Epoch [59][55/100], loss_cls: 0.008482, depth_loss: 10.416 lr: 1.25000e-05, loss: 2.2199\n",
      "Epoch [59][60/100], loss_cls: 0.00012784, depth_loss: 16.916 lr: 1.25000e-05, loss: 3.4927\n",
      "Epoch [59][65/100], loss_cls: 2.4438e-06, depth_loss: 8.6762 lr: 1.25000e-05, loss: 2.0705\n",
      "Epoch [59][70/100], loss_cls: 1.5318e-05, depth_loss: 13.605 lr: 1.25000e-05, loss: 3.3943\n",
      "Epoch [59][75/100], loss_cls: 0.0011102, depth_loss: 12.935 lr: 1.25000e-05, loss: 2.1057\n",
      "Epoch [59][80/100], loss_cls: 3.0159e-05, depth_loss: 9.6413 lr: 1.25000e-05, loss: 3.3023\n",
      "Epoch [59][85/100], loss_cls: 0.0035657, depth_loss: 10.903 lr: 1.25000e-05, loss: 2.936\n",
      "Epoch [59][90/100], loss_cls: 0.00031658, depth_loss: 10.936 lr: 1.25000e-05, loss: 2.6189\n",
      "Epoch [59][95/100], loss_cls: 3.0219e-05, depth_loss: 6.5409 lr: 1.25000e-05, loss: 3.2836\n",
      "Epoch [59][100/100], loss_cls: 0.0028756, depth_loss: 12.741 lr: 1.25000e-05, loss: 2.3628\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.3628, val_loss: 2.8197\n",
      "Epoch [60][5/100], loss_cls: 2.6702e-05, depth_loss: 8.1541 lr: 1.25000e-05, loss: 2.192\n",
      "Epoch [60][10/100], loss_cls: 3.5763e-07, depth_loss: 5.9316 lr: 1.25000e-05, loss: 1.9052\n",
      "Epoch [60][15/100], loss_cls: 0.82142, depth_loss: 20.155 lr: 1.25000e-05, loss: 3.3075\n",
      "Epoch [60][20/100], loss_cls: 0.28491, depth_loss: 7.2584 lr: 1.25000e-05, loss: 2.5715\n",
      "Epoch [60][25/100], loss_cls: 0.0019439, depth_loss: 9.605 lr: 1.25000e-05, loss: 2.4599\n",
      "Epoch [60][30/100], loss_cls: 0.050177, depth_loss: 10.965 lr: 1.25000e-05, loss: 2.9007\n",
      "Epoch [60][35/100], loss_cls: 0.08988, depth_loss: 10.742 lr: 1.25000e-05, loss: 6.7608\n",
      "Epoch [60][40/100], loss_cls: 0.056666, depth_loss: 7.27 lr: 1.25000e-05, loss: 2.7096\n",
      "Epoch [60][45/100], loss_cls: 3.2364e-05, depth_loss: 7.6698 lr: 1.25000e-05, loss: 1.8226\n",
      "Epoch [60][50/100], loss_cls: 0.033759, depth_loss: 15.359 lr: 1.25000e-05, loss: 3.635\n",
      "Epoch [60][55/100], loss_cls: 0.12556, depth_loss: 10.418 lr: 1.25000e-05, loss: 3.0175\n",
      "Epoch [60][60/100], loss_cls: 1.9575, depth_loss: 21.03 lr: 1.25000e-05, loss: 2.6105\n",
      "Epoch [60][65/100], loss_cls: 2.4378e-05, depth_loss: 8.043 lr: 1.25000e-05, loss: 2.8072\n",
      "Epoch [60][70/100], loss_cls: 0.0010792, depth_loss: 10.998 lr: 1.25000e-05, loss: 3.2301\n",
      "Epoch [60][75/100], loss_cls: 0.73981, depth_loss: 20.109 lr: 1.25000e-05, loss: 3.2186\n",
      "Epoch [60][80/100], loss_cls: 1.1921e-07, depth_loss: 12.882 lr: 1.25000e-05, loss: 1.9642\n",
      "Epoch [60][85/100], loss_cls: 4.7684e-07, depth_loss: 10.911 lr: 1.25000e-05, loss: 2.8175\n",
      "Epoch [60][90/100], loss_cls: 0.0017073, depth_loss: 13.843 lr: 1.25000e-05, loss: 3.1162\n",
      "Epoch [60][95/100], loss_cls: 0.00033171, depth_loss: 9.7065 lr: 1.25000e-05, loss: 2.45\n",
      "Epoch [60][100/100], loss_cls: 0.012886, depth_loss: 4.2662 lr: 1.25000e-05, loss: 1.8606\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 1.8606, val_loss: 2.7678\n",
      "Epoch [61][5/100], loss_cls: 6.1568e-05, depth_loss: 10.745 lr: 1.25000e-05, loss: 3.4018\n",
      "Epoch [61][10/100], loss_cls: 0.0001823, depth_loss: 13.671 lr: 1.25000e-05, loss: 2.5888\n",
      "Epoch [61][15/100], loss_cls: 1.353e-05, depth_loss: 17.477 lr: 1.25000e-05, loss: 3.8723\n",
      "Epoch [61][20/100], loss_cls: 0.76232, depth_loss: 11.373 lr: 1.25000e-05, loss: 3.1399\n",
      "Epoch [61][25/100], loss_cls: 0.0060309, depth_loss: 18.215 lr: 1.25000e-05, loss: 2.1257\n",
      "Epoch [61][30/100], loss_cls: 0.31781, depth_loss: 8.4816 lr: 1.25000e-05, loss: 2.3648\n",
      "Epoch [61][35/100], loss_cls: 1.793, depth_loss: 11.126 lr: 1.25000e-05, loss: 2.7302\n",
      "Epoch [61][40/100], loss_cls: 1.6171, depth_loss: 20.288 lr: 1.25000e-05, loss: 3.2525\n",
      "Epoch [61][45/100], loss_cls: 0.0014338, depth_loss: 11.051 lr: 1.25000e-05, loss: 3.7723\n",
      "Epoch [61][50/100], loss_cls: 0.011682, depth_loss: 7.7141 lr: 1.25000e-05, loss: 2.277\n",
      "Epoch [61][55/100], loss_cls: 0.00032581, depth_loss: 15.133 lr: 1.25000e-05, loss: 2.0683\n",
      "Epoch [61][60/100], loss_cls: 0.00084216, depth_loss: 8.3082 lr: 1.25000e-05, loss: 1.831\n",
      "Epoch [61][65/100], loss_cls: 1.2975, depth_loss: 16.89 lr: 1.25000e-05, loss: 2.8998\n",
      "Epoch [61][70/100], loss_cls: 0.070644, depth_loss: 10.927 lr: 1.25000e-05, loss: 1.9664\n",
      "Epoch [61][75/100], loss_cls: 0.019586, depth_loss: 16.857 lr: 1.25000e-05, loss: 3.0206\n",
      "Epoch [61][80/100], loss_cls: 0.00039431, depth_loss: 9.1679 lr: 1.25000e-05, loss: 2.7058\n",
      "Epoch [61][85/100], loss_cls: 2.11e-05, depth_loss: 5.7803 lr: 1.25000e-05, loss: 2.3611\n",
      "Epoch [61][90/100], loss_cls: 0.91727, depth_loss: 24.956 lr: 1.25000e-05, loss: 2.9835\n",
      "Epoch [61][95/100], loss_cls: 0.0067231, depth_loss: 8.3491 lr: 1.25000e-05, loss: 3.1025\n",
      "Epoch [61][100/100], loss_cls: 9.0598e-06, depth_loss: 7.1226 lr: 1.25000e-05, loss: 2.2917\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.2917, val_loss: 2.7049\n",
      "Epoch [62][5/100], loss_cls: 0.00045362, depth_loss: 13.755 lr: 1.25000e-05, loss: 2.5163\n",
      "Epoch [62][10/100], loss_cls: 0.00039818, depth_loss: 8.5815 lr: 1.25000e-05, loss: 1.8277\n",
      "Epoch [62][15/100], loss_cls: 0.0037799, depth_loss: 10.825 lr: 1.25000e-05, loss: 2.8512\n",
      "Epoch [62][20/100], loss_cls: 2.4139e-05, depth_loss: 10.403 lr: 1.25000e-05, loss: 1.8087\n",
      "Epoch [62][25/100], loss_cls: 0.0025595, depth_loss: 6.151 lr: 1.25000e-05, loss: 2.4252\n",
      "Epoch [62][30/100], loss_cls: 7.8678e-06, depth_loss: 16.434 lr: 1.25000e-05, loss: 2.545\n",
      "Epoch [62][35/100], loss_cls: 1.357, depth_loss: 11.95 lr: 1.25000e-05, loss: 2.5416\n",
      "Epoch [62][40/100], loss_cls: 1.6214, depth_loss: 8.0142 lr: 1.25000e-05, loss: 2.4976\n",
      "Epoch [62][45/100], loss_cls: 0.0012215, depth_loss: 18.133 lr: 1.25000e-05, loss: 3.279\n",
      "Epoch [62][50/100], loss_cls: 9.4174e-06, depth_loss: 10.594 lr: 1.25000e-05, loss: 2.2616\n",
      "Epoch [62][55/100], loss_cls: 0.0271, depth_loss: 15.397 lr: 1.25000e-05, loss: 2.8477\n",
      "Epoch [62][60/100], loss_cls: 1.772, depth_loss: 13.418 lr: 1.25000e-05, loss: 2.1784\n",
      "Epoch [62][65/100], loss_cls: 6.4011e-05, depth_loss: 11.172 lr: 1.25000e-05, loss: 4.0238\n",
      "Epoch [62][70/100], loss_cls: 1.4171, depth_loss: 26.352 lr: 1.25000e-05, loss: 4.9536\n",
      "Epoch [62][75/100], loss_cls: 3.5167e-06, depth_loss: 6.8123 lr: 1.25000e-05, loss: 3.0673\n",
      "Epoch [62][80/100], loss_cls: 0.14701, depth_loss: 27.046 lr: 1.25000e-05, loss: 3.2488\n",
      "Epoch [62][85/100], loss_cls: 0.031355, depth_loss: 6.5434 lr: 1.25000e-05, loss: 1.9061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62][90/100], loss_cls: 0.0008533, depth_loss: 13.825 lr: 1.25000e-05, loss: 2.8695\n",
      "Epoch [62][95/100], loss_cls: 0.0034314, depth_loss: 11.749 lr: 1.25000e-05, loss: 4.5167\n",
      "Epoch [62][100/100], loss_cls: 0.003151, depth_loss: 8.9075 lr: 1.25000e-05, loss: 1.9677\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 1.9677, val_loss: 2.7655\n",
      "Epoch [63][5/100], loss_cls: 0.0026104, depth_loss: 7.9113 lr: 1.25000e-05, loss: 2.7219\n",
      "Epoch [63][10/100], loss_cls: 0.00069229, depth_loss: 7.768 lr: 1.25000e-05, loss: 1.7591\n",
      "Epoch [63][15/100], loss_cls: 0.0011543, depth_loss: 11.314 lr: 1.25000e-05, loss: 1.9628\n",
      "Epoch [63][20/100], loss_cls: 0.05955, depth_loss: 11.285 lr: 1.25000e-05, loss: 2.2863\n",
      "Epoch [63][25/100], loss_cls: 5.126e-06, depth_loss: 6.6252 lr: 1.25000e-05, loss: 1.9198\n",
      "Epoch [63][30/100], loss_cls: 0.018501, depth_loss: 13.179 lr: 1.25000e-05, loss: 2.1088\n",
      "Epoch [63][35/100], loss_cls: 0.0012618, depth_loss: 9.2989 lr: 1.25000e-05, loss: 2.6242\n",
      "Epoch [63][40/100], loss_cls: 0.00067397, depth_loss: 10.665 lr: 1.25000e-05, loss: 2.6402\n",
      "Epoch [63][45/100], loss_cls: 1.6451e-05, depth_loss: 16.019 lr: 1.25000e-05, loss: 2.9388\n",
      "Epoch [63][50/100], loss_cls: 0.0029473, depth_loss: 19.926 lr: 1.25000e-05, loss: 2.7759\n",
      "Epoch [63][55/100], loss_cls: 6.9911e-05, depth_loss: 12.273 lr: 1.25000e-05, loss: 2.4794\n",
      "Epoch [63][60/100], loss_cls: 0.22484, depth_loss: 20.915 lr: 1.25000e-05, loss: 2.4055\n",
      "Epoch [63][65/100], loss_cls: 0.00033422, depth_loss: 12.413 lr: 1.25000e-05, loss: 2.4699\n",
      "Epoch [63][70/100], loss_cls: 0.50815, depth_loss: 9.4665 lr: 1.25000e-05, loss: 2.624\n",
      "Epoch [63][75/100], loss_cls: 0.042924, depth_loss: 16.083 lr: 1.25000e-05, loss: 3.0231\n",
      "Epoch [63][80/100], loss_cls: 0.35923, depth_loss: 16.041 lr: 1.25000e-05, loss: 2.4635\n",
      "Epoch [63][85/100], loss_cls: 0.0055234, depth_loss: 9.5386 lr: 1.25000e-05, loss: 2.0887\n",
      "Epoch [63][90/100], loss_cls: 0.51586, depth_loss: 18.049 lr: 1.25000e-05, loss: 3.1592\n",
      "Epoch [63][95/100], loss_cls: 0.00063749, depth_loss: 4.3161 lr: 1.25000e-05, loss: 4.6042\n",
      "Epoch [63][100/100], loss_cls: 1.5974e-05, depth_loss: 11.644 lr: 1.25000e-05, loss: 2.654\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8571, top5_acc: 0.9714, train_loss: 2.654, val_loss: 2.7997\n",
      "Epoch [64][5/100], loss_cls: 0.0043585, depth_loss: 7.6642 lr: 1.25000e-05, loss: 2.549\n",
      "Epoch [64][10/100], loss_cls: 0.00045839, depth_loss: 9.835 lr: 1.25000e-05, loss: 3.1644\n",
      "Epoch [64][15/100], loss_cls: 0.04185, depth_loss: 8.8517 lr: 1.25000e-05, loss: 1.6807\n",
      "Epoch [64][20/100], loss_cls: 1.3192, depth_loss: 11.641 lr: 1.25000e-05, loss: 2.4065\n",
      "Epoch [64][25/100], loss_cls: 4.0053e-05, depth_loss: 14.489 lr: 1.25000e-05, loss: 2.6127\n",
      "Epoch [64][30/100], loss_cls: 7.1819e-05, depth_loss: 9.4683 lr: 1.25000e-05, loss: 2.2942\n",
      "Epoch [64][35/100], loss_cls: 2.2588, depth_loss: 14.069 lr: 1.25000e-05, loss: 2.8767\n",
      "Epoch [64][40/100], loss_cls: 0.0011133, depth_loss: 8.1896 lr: 1.25000e-05, loss: 3.5775\n",
      "Epoch [64][45/100], loss_cls: 1.4829, depth_loss: 14.7 lr: 1.25000e-05, loss: 5.2527\n",
      "Epoch [64][50/100], loss_cls: 0.00048991, depth_loss: 14.861 lr: 1.25000e-05, loss: 3.7937\n",
      "Epoch [64][55/100], loss_cls: 0.00073158, depth_loss: 13.124 lr: 1.25000e-05, loss: 3.1786\n",
      "Epoch [64][60/100], loss_cls: 0.0082239, depth_loss: 20.202 lr: 1.25000e-05, loss: 4.0021\n",
      "Epoch [64][65/100], loss_cls: 0.11806, depth_loss: 14.923 lr: 1.25000e-05, loss: 2.5889\n",
      "Epoch [64][70/100], loss_cls: 0.0008427, depth_loss: 8.7696 lr: 1.25000e-05, loss: 2.8943\n",
      "Epoch [64][75/100], loss_cls: 0.0037288, depth_loss: 9.13 lr: 1.25000e-05, loss: 1.8981\n",
      "Epoch [64][80/100], loss_cls: 0.0026386, depth_loss: 7.3181 lr: 1.25000e-05, loss: 2.2893\n",
      "Epoch [64][85/100], loss_cls: 0.0035599, depth_loss: 9.4333 lr: 1.25000e-05, loss: 3.19\n",
      "Epoch [64][90/100], loss_cls: 0.00012337, depth_loss: 11.163 lr: 1.25000e-05, loss: 3.0378\n",
      "Epoch [64][95/100], loss_cls: 0.00010704, depth_loss: 15.149 lr: 1.25000e-05, loss: 1.9697\n",
      "Epoch [64][100/100], loss_cls: 0.0011815, depth_loss: 5.0436 lr: 1.25000e-05, loss: 2.1537\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.1537, val_loss: 2.7333\n",
      "Epoch [65][5/100], loss_cls: 0.053042, depth_loss: 16.692 lr: 1.25000e-05, loss: 1.9261\n",
      "Epoch [65][10/100], loss_cls: 0.019747, depth_loss: 4.4991 lr: 1.25000e-05, loss: 2.0186\n",
      "Epoch [65][15/100], loss_cls: 0.0017849, depth_loss: 12.186 lr: 1.25000e-05, loss: 3.6835\n",
      "Epoch [65][20/100], loss_cls: 0.00075693, depth_loss: 6.4892 lr: 1.25000e-05, loss: 3.6793\n",
      "Epoch [65][25/100], loss_cls: 0.0002249, depth_loss: 11.572 lr: 1.25000e-05, loss: 3.9256\n",
      "Epoch [65][30/100], loss_cls: 0.026251, depth_loss: 7.4155 lr: 1.25000e-05, loss: 2.2999\n",
      "Epoch [65][35/100], loss_cls: 1.7881e-07, depth_loss: 13.17 lr: 1.25000e-05, loss: 2.468\n",
      "Epoch [65][40/100], loss_cls: 0.0013627, depth_loss: 12.479 lr: 1.25000e-05, loss: 2.0416\n",
      "Epoch [65][45/100], loss_cls: 0.00019333, depth_loss: 5.0638 lr: 1.25000e-05, loss: 1.6873\n",
      "Epoch [65][50/100], loss_cls: 2.8014e-06, depth_loss: 3.8833 lr: 1.25000e-05, loss: 1.9371\n",
      "Epoch [65][55/100], loss_cls: 7.9274e-06, depth_loss: 5.2476 lr: 1.25000e-05, loss: 1.6563\n",
      "Epoch [65][60/100], loss_cls: 0.0028498, depth_loss: 5.9767 lr: 1.25000e-05, loss: 1.764\n",
      "Epoch [65][65/100], loss_cls: 4.6073e-05, depth_loss: 17.574 lr: 1.25000e-05, loss: 2.6221\n",
      "Epoch [65][70/100], loss_cls: 0.0015364, depth_loss: 17.27 lr: 1.25000e-05, loss: 3.942\n",
      "Epoch [65][75/100], loss_cls: 0.0017423, depth_loss: 12.351 lr: 1.25000e-05, loss: 2.6736\n",
      "Epoch [65][80/100], loss_cls: 3.2186e-05, depth_loss: 8.3693 lr: 1.25000e-05, loss: 2.355\n",
      "Epoch [65][85/100], loss_cls: 0.1436, depth_loss: 19.108 lr: 1.25000e-05, loss: 3.2383\n",
      "Epoch [65][90/100], loss_cls: 0.0075182, depth_loss: 32.033 lr: 1.25000e-05, loss: 2.9627\n",
      "Epoch [65][95/100], loss_cls: 0.00036352, depth_loss: 12.313 lr: 1.25000e-05, loss: 3.8031\n",
      "Epoch [65][100/100], loss_cls: 0.31938, depth_loss: 21.065 lr: 1.25000e-05, loss: 4.1739\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 4.1739, val_loss: 2.713\n",
      "Epoch [66][5/100], loss_cls: 0.00045459, depth_loss: 7.7251 lr: 1.25000e-05, loss: 2.376\n",
      "Epoch [66][10/100], loss_cls: 1.3972, depth_loss: 10.268 lr: 1.25000e-05, loss: 3.7232\n",
      "Epoch [66][15/100], loss_cls: 0.48677, depth_loss: 6.1244 lr: 1.25000e-05, loss: 2.8202\n",
      "Epoch [66][20/100], loss_cls: 0.00080712, depth_loss: 11.561 lr: 1.25000e-05, loss: 2.3569\n",
      "Epoch [66][25/100], loss_cls: 0.00025796, depth_loss: 16.077 lr: 1.25000e-05, loss: 3.7714\n",
      "Epoch [66][30/100], loss_cls: 0.00083727, depth_loss: 10.218 lr: 1.25000e-05, loss: 2.0455\n",
      "Epoch [66][35/100], loss_cls: 0.0016247, depth_loss: 9.7324 lr: 1.25000e-05, loss: 2.0853\n",
      "Epoch [66][40/100], loss_cls: 1.3709e-06, depth_loss: 11.59 lr: 1.25000e-05, loss: 3.3009\n",
      "Epoch [66][45/100], loss_cls: 0.018166, depth_loss: 5.5878 lr: 1.25000e-05, loss: 2.097\n",
      "Epoch [66][50/100], loss_cls: 0.0030393, depth_loss: 18.806 lr: 1.25000e-05, loss: 2.3076\n",
      "Epoch [66][55/100], loss_cls: 0.0003497, depth_loss: 15.357 lr: 1.25000e-05, loss: 2.0758\n",
      "Epoch [66][60/100], loss_cls: 0.00027536, depth_loss: 6.7056 lr: 1.25000e-05, loss: 2.4086\n",
      "Epoch [66][65/100], loss_cls: 0.0046355, depth_loss: 6.8292 lr: 1.25000e-05, loss: 1.9756\n",
      "Epoch [66][70/100], loss_cls: 5.388e-05, depth_loss: 7.3349 lr: 1.25000e-05, loss: 2.3592\n",
      "Epoch [66][75/100], loss_cls: 8.0877e-05, depth_loss: 8.7419 lr: 1.25000e-05, loss: 3.1106\n",
      "Epoch [66][80/100], loss_cls: 4.6489e-05, depth_loss: 6.7758 lr: 1.25000e-05, loss: 1.6266\n",
      "Epoch [66][85/100], loss_cls: 0.00038454, depth_loss: 10.426 lr: 1.25000e-05, loss: 2.0564\n",
      "Epoch [66][90/100], loss_cls: 0.012152, depth_loss: 13.604 lr: 1.25000e-05, loss: 2.5108\n",
      "Epoch [66][95/100], loss_cls: 0.0016937, depth_loss: 22.292 lr: 1.25000e-05, loss: 4.0016\n",
      "Epoch [66][100/100], loss_cls: 0.00049329, depth_loss: 15.268 lr: 1.25000e-05, loss: 2.3185\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.3185, val_loss: 2.724\n",
      "Epoch [67][5/100], loss_cls: 0.0010882, depth_loss: 4.9365 lr: 1.25000e-05, loss: 2.1049\n",
      "Epoch [67][10/100], loss_cls: 0.00078699, depth_loss: 16.028 lr: 1.25000e-05, loss: 2.4696\n",
      "Epoch [67][15/100], loss_cls: 0.84154, depth_loss: 18.916 lr: 1.25000e-05, loss: 2.7489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67][20/100], loss_cls: 0.0043005, depth_loss: 11.007 lr: 1.25000e-05, loss: 1.9134\n",
      "Epoch [67][25/100], loss_cls: 0.015867, depth_loss: 25.701 lr: 1.25000e-05, loss: 3.432\n",
      "Epoch [67][30/100], loss_cls: 0.00018212, depth_loss: 14.521 lr: 1.25000e-05, loss: 2.6165\n",
      "Epoch [67][35/100], loss_cls: 0.0583, depth_loss: 12.843 lr: 1.25000e-05, loss: 3.6304\n",
      "Epoch [67][40/100], loss_cls: 5.0841e-05, depth_loss: 12.001 lr: 1.25000e-05, loss: 2.5555\n",
      "Epoch [67][45/100], loss_cls: 0.067847, depth_loss: 10.543 lr: 1.25000e-05, loss: 2.0846\n",
      "Epoch [67][50/100], loss_cls: 0.095532, depth_loss: 9.645 lr: 1.25000e-05, loss: 2.0185\n",
      "Epoch [67][55/100], loss_cls: 0.00083466, depth_loss: 10.362 lr: 1.25000e-05, loss: 2.6069\n",
      "Epoch [67][60/100], loss_cls: 0.31205, depth_loss: 14.283 lr: 1.25000e-05, loss: 3.5126\n",
      "Epoch [67][65/100], loss_cls: 0.0090601, depth_loss: 7.3383 lr: 1.25000e-05, loss: 3.2387\n",
      "Epoch [67][70/100], loss_cls: 0.13298, depth_loss: 4.9063 lr: 1.25000e-05, loss: 2.3786\n",
      "Epoch [67][75/100], loss_cls: 0.0097207, depth_loss: 16.134 lr: 1.25000e-05, loss: 2.4627\n",
      "Epoch [67][80/100], loss_cls: 0.080926, depth_loss: 19.39 lr: 1.25000e-05, loss: 3.6633\n",
      "Epoch [67][85/100], loss_cls: 0.0025144, depth_loss: 7.4396 lr: 1.25000e-05, loss: 2.4501\n",
      "Epoch [67][90/100], loss_cls: 0.0020523, depth_loss: 24.089 lr: 1.25000e-05, loss: 2.8645\n",
      "Epoch [67][95/100], loss_cls: 1.0729e-06, depth_loss: 8.5093 lr: 1.25000e-05, loss: 2.4656\n",
      "Epoch [67][100/100], loss_cls: 2.3043, depth_loss: 27.067 lr: 1.25000e-05, loss: 4.3225\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 4.3225, val_loss: 2.897\n",
      "Epoch [68][5/100], loss_cls: 3.9159e-05, depth_loss: 14.637 lr: 1.25000e-05, loss: 2.5259\n",
      "Epoch [68][10/100], loss_cls: 0.0052232, depth_loss: 19.035 lr: 1.25000e-05, loss: 2.8384\n",
      "Epoch [68][15/100], loss_cls: 3.5763e-07, depth_loss: 13.24 lr: 1.25000e-05, loss: 1.8321\n",
      "Epoch [68][20/100], loss_cls: 0.016617, depth_loss: 8.9739 lr: 1.25000e-05, loss: 2.3851\n",
      "Epoch [68][25/100], loss_cls: 5.4952e-05, depth_loss: 14.324 lr: 1.25000e-05, loss: 4.4524\n",
      "Epoch [68][30/100], loss_cls: 0.0005608, depth_loss: 9.6214 lr: 1.25000e-05, loss: 2.2851\n",
      "Epoch [68][35/100], loss_cls: 0.78518, depth_loss: 12.579 lr: 1.25000e-05, loss: 2.4911\n",
      "Epoch [68][40/100], loss_cls: 2.1541, depth_loss: 18.727 lr: 1.25000e-05, loss: 3.1302\n",
      "Epoch [68][45/100], loss_cls: 0.0073397, depth_loss: 21.371 lr: 1.25000e-05, loss: 3.4942\n",
      "Epoch [68][50/100], loss_cls: 0.0014665, depth_loss: 14.39 lr: 1.25000e-05, loss: 2.422\n",
      "Epoch [68][55/100], loss_cls: 1.1672, depth_loss: 10.86 lr: 1.25000e-05, loss: 2.616\n",
      "Epoch [68][60/100], loss_cls: 0.00035531, depth_loss: 10.398 lr: 1.25000e-05, loss: 2.323\n",
      "Epoch [68][65/100], loss_cls: 0.0011253, depth_loss: 10.81 lr: 1.25000e-05, loss: 2.0582\n",
      "Epoch [68][70/100], loss_cls: 0.041848, depth_loss: 11.743 lr: 1.25000e-05, loss: 1.9341\n",
      "Epoch [68][75/100], loss_cls: 4.4703e-06, depth_loss: 16.103 lr: 1.25000e-05, loss: 3.6325\n",
      "Epoch [68][80/100], loss_cls: 0.00055623, depth_loss: 10.649 lr: 1.25000e-05, loss: 3.5363\n",
      "Epoch [68][85/100], loss_cls: 0.00010465, depth_loss: 10.456 lr: 1.25000e-05, loss: 1.889\n",
      "Epoch [68][90/100], loss_cls: 0.001609, depth_loss: 14.089 lr: 1.25000e-05, loss: 2.722\n",
      "Epoch [68][95/100], loss_cls: 0.034243, depth_loss: 12.557 lr: 1.25000e-05, loss: 2.4179\n",
      "Epoch [68][100/100], loss_cls: 0.0012562, depth_loss: 8.3705 lr: 1.25000e-05, loss: 2.5006\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 2.5006, val_loss: 2.7568\n",
      "Epoch [69][5/100], loss_cls: 0.0037442, depth_loss: 10.504 lr: 1.25000e-05, loss: 2.6451\n",
      "Epoch [69][10/100], loss_cls: 0.035299, depth_loss: 9.6021 lr: 1.25000e-05, loss: 2.6752\n",
      "Epoch [69][15/100], loss_cls: 1.4089, depth_loss: 8.626 lr: 1.25000e-05, loss: 2.8466\n",
      "Epoch [69][20/100], loss_cls: 0.0069607, depth_loss: 7.7387 lr: 1.25000e-05, loss: 2.8185\n",
      "Epoch [69][25/100], loss_cls: 0.045733, depth_loss: 13.282 lr: 1.25000e-05, loss: 2.277\n",
      "Epoch [69][30/100], loss_cls: 5.7277e-05, depth_loss: 7.2805 lr: 1.25000e-05, loss: 1.6998\n",
      "Epoch [69][35/100], loss_cls: 7.4203e-05, depth_loss: 14.356 lr: 1.25000e-05, loss: 2.6802\n",
      "Epoch [69][40/100], loss_cls: 0.017752, depth_loss: 9.9066 lr: 1.25000e-05, loss: 1.7839\n",
      "Epoch [69][45/100], loss_cls: 0.44502, depth_loss: 5.7876 lr: 1.25000e-05, loss: 2.3894\n",
      "Epoch [69][50/100], loss_cls: 0.00059182, depth_loss: 11.549 lr: 1.25000e-05, loss: 2.2021\n",
      "Epoch [69][55/100], loss_cls: 0.01679, depth_loss: 6.7658 lr: 1.25000e-05, loss: 2.1478\n",
      "Epoch [69][60/100], loss_cls: 0.0075103, depth_loss: 21.691 lr: 1.25000e-05, loss: 2.5649\n",
      "Epoch [69][65/100], loss_cls: 5.3644e-07, depth_loss: 11.684 lr: 1.25000e-05, loss: 1.9339\n",
      "Epoch [69][70/100], loss_cls: 0.26323, depth_loss: 18.851 lr: 1.25000e-05, loss: 2.7302\n",
      "Epoch [69][75/100], loss_cls: 0.00040622, depth_loss: 8.3125 lr: 1.25000e-05, loss: 1.9497\n",
      "Epoch [69][80/100], loss_cls: 0.0026165, depth_loss: 10.965 lr: 1.25000e-05, loss: 2.4587\n",
      "Epoch [69][85/100], loss_cls: 0.0010504, depth_loss: 6.9624 lr: 1.25000e-05, loss: 2.4773\n",
      "Epoch [69][90/100], loss_cls: 0.00018315, depth_loss: 7.8056 lr: 1.25000e-05, loss: 1.5468\n",
      "Epoch [69][95/100], loss_cls: 0.085632, depth_loss: 27.999 lr: 1.25000e-05, loss: 3.0067\n",
      "Epoch [69][100/100], loss_cls: 1.3075, depth_loss: 39.046 lr: 1.25000e-05, loss: 4.3172\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 4.3172, val_loss: 2.708\n",
      "Epoch [70][5/100], loss_cls: 0.035674, depth_loss: 12.159 lr: 1.25000e-05, loss: 1.5995\n",
      "Epoch [70][10/100], loss_cls: 0.21726, depth_loss: 33.644 lr: 1.25000e-05, loss: 3.3951\n",
      "Epoch [70][15/100], loss_cls: 2.7477e-05, depth_loss: 8.7809 lr: 1.25000e-05, loss: 3.6179\n",
      "Epoch [70][20/100], loss_cls: 0.0, depth_loss: 13.875 lr: 1.25000e-05, loss: 2.2236\n",
      "Epoch [70][25/100], loss_cls: 0.00181, depth_loss: 13.272 lr: 1.25000e-05, loss: 2.1998\n",
      "Epoch [70][30/100], loss_cls: 0.0, depth_loss: 10.342 lr: 1.25000e-05, loss: 2.7029\n",
      "Epoch [70][35/100], loss_cls: 0.00031883, depth_loss: 6.6981 lr: 1.25000e-05, loss: 1.8757\n",
      "Epoch [70][40/100], loss_cls: 0.00073061, depth_loss: 13.377 lr: 1.25000e-05, loss: 2.7536\n",
      "Epoch [70][45/100], loss_cls: 1.1802e-05, depth_loss: 13.28 lr: 1.25000e-05, loss: 1.6247\n",
      "Epoch [70][50/100], loss_cls: 0.00016484, depth_loss: 5.2252 lr: 1.25000e-05, loss: 2.7633\n",
      "Epoch [70][55/100], loss_cls: 0.00067213, depth_loss: 5.2938 lr: 1.25000e-05, loss: 2.2909\n",
      "Epoch [70][60/100], loss_cls: 4.0351e-05, depth_loss: 12.208 lr: 1.25000e-05, loss: 2.3426\n",
      "Epoch [70][65/100], loss_cls: 0.0013064, depth_loss: 5.9815 lr: 1.25000e-05, loss: 1.9478\n",
      "Epoch [70][70/100], loss_cls: 0.00011032, depth_loss: 8.5799 lr: 1.25000e-05, loss: 2.7618\n",
      "Epoch [70][75/100], loss_cls: 3.0338e-05, depth_loss: 10.025 lr: 1.25000e-05, loss: 1.7378\n",
      "Epoch [70][80/100], loss_cls: 0.97279, depth_loss: 9.7294 lr: 1.25000e-05, loss: 1.9082\n",
      "Epoch [70][85/100], loss_cls: 2.1875e-05, depth_loss: 12.788 lr: 1.25000e-05, loss: 1.9438\n",
      "Epoch [70][90/100], loss_cls: 0.061533, depth_loss: 10.978 lr: 1.25000e-05, loss: 4.2886\n",
      "Epoch [70][95/100], loss_cls: 0.0030063, depth_loss: 20.224 lr: 1.25000e-05, loss: 4.1403\n",
      "Epoch [70][100/100], loss_cls: 0.082213, depth_loss: 25.374 lr: 1.25000e-05, loss: 3.7767\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.7767, val_loss: 2.65\n",
      "Saving checkpoint at 70 epochs...\n",
      "Epoch [71][5/100], loss_cls: 0.0035656, depth_loss: 5.8092 lr: 1.25000e-05, loss: 2.2417\n",
      "Epoch [71][10/100], loss_cls: 0.0037878, depth_loss: 9.1861 lr: 1.25000e-05, loss: 2.0421\n",
      "Epoch [71][15/100], loss_cls: 0.020638, depth_loss: 8.1443 lr: 1.25000e-05, loss: 2.0952\n",
      "Epoch [71][20/100], loss_cls: 0.019491, depth_loss: 12.512 lr: 1.25000e-05, loss: 3.7878\n",
      "Epoch [71][25/100], loss_cls: 0.00016639, depth_loss: 12.967 lr: 1.25000e-05, loss: 1.7405\n",
      "Epoch [71][30/100], loss_cls: 0.00070654, depth_loss: 9.8715 lr: 1.25000e-05, loss: 3.3574\n",
      "Epoch [71][35/100], loss_cls: 0.0074089, depth_loss: 9.7098 lr: 1.25000e-05, loss: 3.1668\n",
      "Epoch [71][40/100], loss_cls: 0.044476, depth_loss: 11.887 lr: 1.25000e-05, loss: 2.808\n",
      "Epoch [71][45/100], loss_cls: 0.0004809, depth_loss: 19.727 lr: 1.25000e-05, loss: 2.873\n",
      "Epoch [71][50/100], loss_cls: 0.027195, depth_loss: 9.5054 lr: 1.25000e-05, loss: 2.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71][55/100], loss_cls: 0.0035828, depth_loss: 10.405 lr: 1.25000e-05, loss: 2.9392\n",
      "Epoch [71][60/100], loss_cls: 0.10845, depth_loss: 9.4838 lr: 1.25000e-05, loss: 2.0137\n",
      "Epoch [71][65/100], loss_cls: 0.0030402, depth_loss: 8.2444 lr: 1.25000e-05, loss: 2.6574\n",
      "Epoch [71][70/100], loss_cls: 4.5299e-06, depth_loss: 9.111 lr: 1.25000e-05, loss: 2.2491\n",
      "Epoch [71][75/100], loss_cls: 1.9211, depth_loss: 12.644 lr: 1.25000e-05, loss: 3.6772\n",
      "Epoch [71][80/100], loss_cls: 2.3424e-05, depth_loss: 14.008 lr: 1.25000e-05, loss: 3.6422\n",
      "Epoch [71][85/100], loss_cls: 0.50375, depth_loss: 29.297 lr: 1.25000e-05, loss: 3.2012\n",
      "Epoch [71][90/100], loss_cls: 3.8147e-06, depth_loss: 5.8344 lr: 1.25000e-05, loss: 2.4896\n",
      "Epoch [71][95/100], loss_cls: 1.4901e-05, depth_loss: 7.961 lr: 1.25000e-05, loss: 1.9779\n",
      "Epoch [71][100/100], loss_cls: 5.0901e-05, depth_loss: 7.124 lr: 1.25000e-05, loss: 2.198\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.198, val_loss: 2.6969\n",
      "Epoch [72][5/100], loss_cls: 6.4373e-06, depth_loss: 14.868 lr: 1.25000e-05, loss: 2.1135\n",
      "Epoch [72][10/100], loss_cls: 5.9244e-05, depth_loss: 18.758 lr: 1.25000e-05, loss: 2.3755\n",
      "Epoch [72][15/100], loss_cls: 0.00397, depth_loss: 24.185 lr: 1.25000e-05, loss: 2.7831\n",
      "Epoch [72][20/100], loss_cls: 2.8014e-06, depth_loss: 7.0789 lr: 1.25000e-05, loss: 2.1937\n",
      "Epoch [72][25/100], loss_cls: 0.83338, depth_loss: 16.664 lr: 1.25000e-05, loss: 2.622\n",
      "Epoch [72][30/100], loss_cls: 2.2949, depth_loss: 12.314 lr: 1.25000e-05, loss: 2.8171\n",
      "Epoch [72][35/100], loss_cls: 0.00010912, depth_loss: 7.5441 lr: 1.25000e-05, loss: 2.8688\n",
      "Epoch [72][40/100], loss_cls: 0.00013559, depth_loss: 8.2347 lr: 1.25000e-05, loss: 1.9949\n",
      "Epoch [72][45/100], loss_cls: 0.00011992, depth_loss: 7.2035 lr: 1.25000e-05, loss: 3.0269\n",
      "Epoch [72][50/100], loss_cls: 1.3351e-05, depth_loss: 9.1846 lr: 1.25000e-05, loss: 2.7113\n",
      "Epoch [72][55/100], loss_cls: 0.0024064, depth_loss: 20.1 lr: 1.25000e-05, loss: 2.8766\n",
      "Epoch [72][60/100], loss_cls: 0.37405, depth_loss: 8.6021 lr: 1.25000e-05, loss: 2.1659\n",
      "Epoch [72][65/100], loss_cls: 0.00019523, depth_loss: 19.876 lr: 1.25000e-05, loss: 2.4888\n",
      "Epoch [72][70/100], loss_cls: 0.0092427, depth_loss: 8.8995 lr: 1.25000e-05, loss: 3.4349\n",
      "Epoch [72][75/100], loss_cls: 0.00040825, depth_loss: 8.134 lr: 1.25000e-05, loss: 2.0048\n",
      "Epoch [72][80/100], loss_cls: 0.26154, depth_loss: 4.7896 lr: 1.25000e-05, loss: 5.502\n",
      "Epoch [72][85/100], loss_cls: 3.9219e-05, depth_loss: 7.8291 lr: 1.25000e-05, loss: 2.0883\n",
      "Epoch [72][90/100], loss_cls: 5.9605e-08, depth_loss: 8.2946 lr: 1.25000e-05, loss: 2.3933\n",
      "Epoch [72][95/100], loss_cls: 0.26507, depth_loss: 7.7273 lr: 1.25000e-05, loss: 2.4682\n",
      "Epoch [72][100/100], loss_cls: 0.0029602, depth_loss: 6.406 lr: 1.25000e-05, loss: 2.0277\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.0277, val_loss: 2.6622\n",
      "Epoch [73][5/100], loss_cls: 0.0019743, depth_loss: 10.711 lr: 1.25000e-05, loss: 4.3142\n",
      "Epoch [73][10/100], loss_cls: 0.0018559, depth_loss: 11.082 lr: 1.25000e-05, loss: 3.8688\n",
      "Epoch [73][15/100], loss_cls: 0.53108, depth_loss: 11.549 lr: 1.25000e-05, loss: 3.4211\n",
      "Epoch [73][20/100], loss_cls: 9.1366e-05, depth_loss: 7.7861 lr: 1.25000e-05, loss: 2.2182\n",
      "Epoch [73][25/100], loss_cls: 0.0066681, depth_loss: 11.01 lr: 1.25000e-05, loss: 3.8865\n",
      "Epoch [73][30/100], loss_cls: 0.28694, depth_loss: 14.026 lr: 1.25000e-05, loss: 4.2108\n",
      "Epoch [73][35/100], loss_cls: 0.00010037, depth_loss: 12.976 lr: 1.25000e-05, loss: 3.0381\n",
      "Epoch [73][40/100], loss_cls: 0.59642, depth_loss: 12.291 lr: 1.25000e-05, loss: 3.2652\n",
      "Epoch [73][45/100], loss_cls: 0.16415, depth_loss: 11.75 lr: 1.25000e-05, loss: 2.7201\n",
      "Epoch [73][50/100], loss_cls: 0.00027471, depth_loss: 19.11 lr: 1.25000e-05, loss: 2.5592\n",
      "Epoch [73][55/100], loss_cls: 0.69631, depth_loss: 11.617 lr: 1.25000e-05, loss: 2.2444\n",
      "Epoch [73][60/100], loss_cls: 0.0084514, depth_loss: 12.592 lr: 1.25000e-05, loss: 2.5213\n",
      "Epoch [73][65/100], loss_cls: 0.91582, depth_loss: 8.1354 lr: 1.25000e-05, loss: 2.637\n",
      "Epoch [73][70/100], loss_cls: 8.3143e-05, depth_loss: 10.461 lr: 1.25000e-05, loss: 4.3064\n",
      "Epoch [73][75/100], loss_cls: 0.076744, depth_loss: 39.903 lr: 1.25000e-05, loss: 3.5139\n",
      "Epoch [73][80/100], loss_cls: 0.014994, depth_loss: 18.641 lr: 1.25000e-05, loss: 2.9466\n",
      "Epoch [73][85/100], loss_cls: 0.00028665, depth_loss: 12.672 lr: 1.25000e-05, loss: 2.6676\n",
      "Epoch [73][90/100], loss_cls: 9.2142e-05, depth_loss: 9.2147 lr: 1.25000e-05, loss: 2.1492\n",
      "Epoch [73][95/100], loss_cls: 0.00066697, depth_loss: 8.1935 lr: 1.25000e-05, loss: 1.9039\n",
      "Epoch [73][100/100], loss_cls: 0.0, depth_loss: 7.7131 lr: 1.25000e-05, loss: 2.1022\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.1022, val_loss: 2.6733\n",
      "Epoch [74][5/100], loss_cls: 0.92154, depth_loss: 28.048 lr: 1.25000e-05, loss: 2.7294\n",
      "Epoch [74][10/100], loss_cls: 0.00093827, depth_loss: 9.4666 lr: 1.25000e-05, loss: 2.0465\n",
      "Epoch [74][15/100], loss_cls: 5.9543e-05, depth_loss: 11.368 lr: 1.25000e-05, loss: 4.5711\n",
      "Epoch [74][20/100], loss_cls: 0.24102, depth_loss: 12.465 lr: 1.25000e-05, loss: 2.4937\n",
      "Epoch [74][25/100], loss_cls: 1.0133e-06, depth_loss: 6.2443 lr: 1.25000e-05, loss: 4.7912\n",
      "Epoch [74][30/100], loss_cls: 4.4107e-06, depth_loss: 13.187 lr: 1.25000e-05, loss: 2.5992\n",
      "Epoch [74][35/100], loss_cls: 0.0021922, depth_loss: 13.325 lr: 1.25000e-05, loss: 3.8519\n",
      "Epoch [74][40/100], loss_cls: 4.1723e-07, depth_loss: 10.575 lr: 1.25000e-05, loss: 3.0514\n",
      "Epoch [74][45/100], loss_cls: 1.7881e-06, depth_loss: 8.8411 lr: 1.25000e-05, loss: 1.9892\n",
      "Epoch [74][50/100], loss_cls: 1.6241, depth_loss: 23.115 lr: 1.25000e-05, loss: 3.3305\n",
      "Epoch [74][55/100], loss_cls: 0.003978, depth_loss: 15.934 lr: 1.25000e-05, loss: 2.723\n",
      "Epoch [74][60/100], loss_cls: 9.179e-06, depth_loss: 19.63 lr: 1.25000e-05, loss: 2.5194\n",
      "Epoch [74][65/100], loss_cls: 0.057538, depth_loss: 19.567 lr: 1.25000e-05, loss: 2.3978\n",
      "Epoch [74][70/100], loss_cls: 0.0016637, depth_loss: 5.6118 lr: 1.25000e-05, loss: 3.0272\n",
      "Epoch [74][75/100], loss_cls: 1.7311, depth_loss: 29.575 lr: 1.25000e-05, loss: 4.22\n",
      "Epoch [74][80/100], loss_cls: 0.94225, depth_loss: 17.709 lr: 1.25000e-05, loss: 2.373\n",
      "Epoch [74][85/100], loss_cls: 0.00026845, depth_loss: 6.5405 lr: 1.25000e-05, loss: 2.9095\n",
      "Epoch [74][90/100], loss_cls: 0.0027974, depth_loss: 5.1878 lr: 1.25000e-05, loss: 1.689\n",
      "Epoch [74][95/100], loss_cls: 4.0589e-05, depth_loss: 6.2909 lr: 1.25000e-05, loss: 2.6298\n",
      "Epoch [74][100/100], loss_cls: 0.0043046, depth_loss: 6.8773 lr: 1.25000e-05, loss: 2.4388\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.4388, val_loss: 2.7604\n",
      "Epoch [75][5/100], loss_cls: 2.5034e-06, depth_loss: 15.001 lr: 1.25000e-05, loss: 2.5148\n",
      "Epoch [75][10/100], loss_cls: 1.4821, depth_loss: 4.4998 lr: 1.25000e-05, loss: 1.8273\n",
      "Epoch [75][15/100], loss_cls: 5.9605e-08, depth_loss: 7.696 lr: 1.25000e-05, loss: 1.8304\n",
      "Epoch [75][20/100], loss_cls: 0.00039122, depth_loss: 13.323 lr: 1.25000e-05, loss: 2.2653\n",
      "Epoch [75][25/100], loss_cls: 2.6757, depth_loss: 10.937 lr: 1.25000e-05, loss: 2.6231\n",
      "Epoch [75][30/100], loss_cls: 0.84225, depth_loss: 20.739 lr: 1.25000e-05, loss: 2.6955\n",
      "Epoch [75][35/100], loss_cls: 0.00027178, depth_loss: 6.1225 lr: 1.25000e-05, loss: 3.1274\n",
      "Epoch [75][40/100], loss_cls: 0.00030079, depth_loss: 7.0961 lr: 1.25000e-05, loss: 2.249\n",
      "Epoch [75][45/100], loss_cls: 0.039822, depth_loss: 12.637 lr: 1.25000e-05, loss: 1.9661\n",
      "Epoch [75][50/100], loss_cls: 0.0032927, depth_loss: 9.3045 lr: 1.25000e-05, loss: 1.7631\n",
      "Epoch [75][55/100], loss_cls: 2.3067e-05, depth_loss: 10.117 lr: 1.25000e-05, loss: 1.9301\n",
      "Epoch [75][60/100], loss_cls: 0.00010805, depth_loss: 10.832 lr: 1.25000e-05, loss: 2.5346\n",
      "Epoch [75][65/100], loss_cls: 7.176e-05, depth_loss: 19.461 lr: 1.25000e-05, loss: 2.3712\n",
      "Epoch [75][70/100], loss_cls: 0.053158, depth_loss: 14.876 lr: 1.25000e-05, loss: 3.5795\n",
      "Epoch [75][75/100], loss_cls: 0.086826, depth_loss: 22.27 lr: 1.25000e-05, loss: 2.8561\n",
      "Epoch [75][80/100], loss_cls: 5.3941e-05, depth_loss: 24.604 lr: 1.25000e-05, loss: 3.3459\n",
      "Epoch [75][85/100], loss_cls: 0.96984, depth_loss: 19.431 lr: 1.25000e-05, loss: 3.3487\n",
      "Epoch [75][90/100], loss_cls: 0.013565, depth_loss: 6.4588 lr: 1.25000e-05, loss: 3.3505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75][95/100], loss_cls: 0.0008215, depth_loss: 8.9846 lr: 1.25000e-05, loss: 2.5507\n",
      "Epoch [75][100/100], loss_cls: 0.0020626, depth_loss: 9.8648 lr: 1.25000e-05, loss: 1.6809\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 1.6809, val_loss: 2.6863\n",
      "Epoch [76][5/100], loss_cls: 7.0507e-05, depth_loss: 8.1622 lr: 1.25000e-05, loss: 2.7029\n",
      "Epoch [76][10/100], loss_cls: 0.15482, depth_loss: 8.535 lr: 1.25000e-05, loss: 4.7702\n",
      "Epoch [76][15/100], loss_cls: 0.0043115, depth_loss: 8.7074 lr: 1.25000e-05, loss: 2.8482\n",
      "Epoch [76][20/100], loss_cls: 0.00049569, depth_loss: 5.5473 lr: 1.25000e-05, loss: 2.3379\n",
      "Epoch [76][25/100], loss_cls: 0.0029741, depth_loss: 6.3151 lr: 1.25000e-05, loss: 1.8153\n",
      "Epoch [76][30/100], loss_cls: 5.9605e-08, depth_loss: 16.205 lr: 1.25000e-05, loss: 2.8808\n",
      "Epoch [76][35/100], loss_cls: 0.00026416, depth_loss: 5.6086 lr: 1.25000e-05, loss: 1.9478\n",
      "Epoch [76][40/100], loss_cls: 0.068474, depth_loss: 10.653 lr: 1.25000e-05, loss: 2.0057\n",
      "Epoch [76][45/100], loss_cls: 0.036312, depth_loss: 8.9369 lr: 1.25000e-05, loss: 3.6674\n",
      "Epoch [76][50/100], loss_cls: 0.0, depth_loss: 6.4486 lr: 1.25000e-05, loss: 2.4572\n",
      "Epoch [76][55/100], loss_cls: 5.7816e-06, depth_loss: 12.46 lr: 1.25000e-05, loss: 2.3159\n",
      "Epoch [76][60/100], loss_cls: 0.76573, depth_loss: 8.683 lr: 1.25000e-05, loss: 3.3316\n",
      "Epoch [76][65/100], loss_cls: 0.76153, depth_loss: 10.519 lr: 1.25000e-05, loss: 2.3573\n",
      "Epoch [76][70/100], loss_cls: 0.00012921, depth_loss: 10.595 lr: 1.25000e-05, loss: 1.891\n",
      "Epoch [76][75/100], loss_cls: 0.00017378, depth_loss: 8.8923 lr: 1.25000e-05, loss: 4.0282\n",
      "Epoch [76][80/100], loss_cls: 0.00071153, depth_loss: 12.713 lr: 1.25000e-05, loss: 2.348\n",
      "Epoch [76][85/100], loss_cls: 0.00027472, depth_loss: 17.674 lr: 1.25000e-05, loss: 3.3684\n",
      "Epoch [76][90/100], loss_cls: 9.0651e-05, depth_loss: 13.872 lr: 1.25000e-05, loss: 3.5963\n",
      "Epoch [76][95/100], loss_cls: 1.8643, depth_loss: 20.699 lr: 1.25000e-05, loss: 3.473\n",
      "Epoch [76][100/100], loss_cls: 0.79748, depth_loss: 16.287 lr: 1.25000e-05, loss: 3.9003\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.9003, val_loss: 2.8018\n",
      "Epoch [77][5/100], loss_cls: 0.012406, depth_loss: 17.642 lr: 1.25000e-05, loss: 2.7379\n",
      "Epoch [77][10/100], loss_cls: 0.00096627, depth_loss: 10.117 lr: 1.25000e-05, loss: 2.0981\n",
      "Epoch [77][15/100], loss_cls: 1.2332, depth_loss: 50.347 lr: 1.25000e-05, loss: 3.7227\n",
      "Epoch [77][20/100], loss_cls: 0.0018352, depth_loss: 9.1482 lr: 1.25000e-05, loss: 2.6785\n",
      "Epoch [77][25/100], loss_cls: 1.7762e-05, depth_loss: 12.608 lr: 1.25000e-05, loss: 2.8006\n",
      "Epoch [77][30/100], loss_cls: 0.00021751, depth_loss: 14.946 lr: 1.25000e-05, loss: 2.5087\n",
      "Epoch [77][35/100], loss_cls: 0.020101, depth_loss: 9.5736 lr: 1.25000e-05, loss: 2.5396\n",
      "Epoch [77][40/100], loss_cls: 0.00062123, depth_loss: 6.6442 lr: 1.25000e-05, loss: 2.7625\n",
      "Epoch [77][45/100], loss_cls: 0.00042968, depth_loss: 11.133 lr: 1.25000e-05, loss: 2.3398\n",
      "Epoch [77][50/100], loss_cls: 0.1394, depth_loss: 7.8546 lr: 1.25000e-05, loss: 2.4723\n",
      "Epoch [77][55/100], loss_cls: 0.0020996, depth_loss: 13.728 lr: 1.25000e-05, loss: 2.0799\n",
      "Epoch [77][60/100], loss_cls: 0.066419, depth_loss: 20.287 lr: 1.25000e-05, loss: 2.4179\n",
      "Epoch [77][65/100], loss_cls: 0.00013439, depth_loss: 7.7388 lr: 1.25000e-05, loss: 2.8726\n",
      "Epoch [77][70/100], loss_cls: 0.13968, depth_loss: 10.599 lr: 1.25000e-05, loss: 2.4737\n",
      "Epoch [77][75/100], loss_cls: 1.0311e-05, depth_loss: 12.123 lr: 1.25000e-05, loss: 2.3096\n",
      "Epoch [77][80/100], loss_cls: 0.0, depth_loss: 5.7864 lr: 1.25000e-05, loss: 3.7591\n",
      "Epoch [77][85/100], loss_cls: 0.18747, depth_loss: 8.8249 lr: 1.25000e-05, loss: 1.9295\n",
      "Epoch [77][90/100], loss_cls: 0.22017, depth_loss: 13.519 lr: 1.25000e-05, loss: 3.5764\n",
      "Epoch [77][95/100], loss_cls: 0.00014959, depth_loss: 7.3021 lr: 1.25000e-05, loss: 3.0665\n",
      "Epoch [77][100/100], loss_cls: 0.00075536, depth_loss: 8.0082 lr: 1.25000e-05, loss: 3.0244\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.0244, val_loss: 2.6359\n",
      "Saving checkpoint at 77 epochs...\n",
      "Epoch [78][5/100], loss_cls: 0.66491, depth_loss: 9.248 lr: 1.25000e-05, loss: 2.2628\n",
      "Epoch [78][10/100], loss_cls: 0.37504, depth_loss: 8.9299 lr: 1.25000e-05, loss: 2.2207\n",
      "Epoch [78][15/100], loss_cls: 0.00046284, depth_loss: 7.6716 lr: 1.25000e-05, loss: 3.8915\n",
      "Epoch [78][20/100], loss_cls: 0.0025765, depth_loss: 5.9745 lr: 1.25000e-05, loss: 1.9105\n",
      "Epoch [78][25/100], loss_cls: 0.14279, depth_loss: 22.685 lr: 1.25000e-05, loss: 2.6881\n",
      "Epoch [78][30/100], loss_cls: 0.00020126, depth_loss: 7.2328 lr: 1.25000e-05, loss: 4.4972\n",
      "Epoch [78][35/100], loss_cls: 0.0039545, depth_loss: 16.3 lr: 1.25000e-05, loss: 2.0996\n",
      "Epoch [78][40/100], loss_cls: 0.013771, depth_loss: 7.8237 lr: 1.25000e-05, loss: 1.7435\n",
      "Epoch [78][45/100], loss_cls: 0.00041861, depth_loss: 19.199 lr: 1.25000e-05, loss: 2.0991\n",
      "Epoch [78][50/100], loss_cls: 0.052589, depth_loss: 6.2133 lr: 1.25000e-05, loss: 1.7079\n",
      "Epoch [78][55/100], loss_cls: 0.24175, depth_loss: 14.209 lr: 1.25000e-05, loss: 2.3154\n",
      "Epoch [78][60/100], loss_cls: 0.0012402, depth_loss: 7.7725 lr: 1.25000e-05, loss: 1.8674\n",
      "Epoch [78][65/100], loss_cls: 0.42983, depth_loss: 32.301 lr: 1.25000e-05, loss: 3.3772\n",
      "Epoch [78][70/100], loss_cls: 0.00039693, depth_loss: 9.9554 lr: 1.25000e-05, loss: 1.7337\n",
      "Epoch [78][75/100], loss_cls: 1.1384e-05, depth_loss: 15.676 lr: 1.25000e-05, loss: 2.3292\n",
      "Epoch [78][80/100], loss_cls: 0.0040916, depth_loss: 10.509 lr: 1.25000e-05, loss: 2.9917\n",
      "Epoch [78][85/100], loss_cls: 0.5024, depth_loss: 11.439 lr: 1.25000e-05, loss: 2.2603\n",
      "Epoch [78][90/100], loss_cls: 0.00059492, depth_loss: 29.765 lr: 1.25000e-05, loss: 3.357\n",
      "Epoch [78][95/100], loss_cls: 0.00044138, depth_loss: 15.249 lr: 1.25000e-05, loss: 2.5531\n",
      "Epoch [78][100/100], loss_cls: 0.0041012, depth_loss: 9.2679 lr: 1.25000e-05, loss: 2.247\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.247, val_loss: 2.654\n",
      "Epoch [79][5/100], loss_cls: 0.0044034, depth_loss: 15.488 lr: 1.25000e-05, loss: 2.4962\n",
      "Epoch [79][10/100], loss_cls: 0.00015596, depth_loss: 8.2234 lr: 1.25000e-05, loss: 2.0843\n",
      "Epoch [79][15/100], loss_cls: 0.0071434, depth_loss: 10.321 lr: 1.25000e-05, loss: 2.221\n",
      "Epoch [79][20/100], loss_cls: 1.9431e-05, depth_loss: 8.2547 lr: 1.25000e-05, loss: 3.1443\n",
      "Epoch [79][25/100], loss_cls: 0.11149, depth_loss: 23.064 lr: 1.25000e-05, loss: 2.2176\n",
      "Epoch [79][30/100], loss_cls: 0.002294, depth_loss: 9.4602 lr: 1.25000e-05, loss: 2.3789\n",
      "Epoch [79][35/100], loss_cls: 3.6359e-06, depth_loss: 8.1079 lr: 1.25000e-05, loss: 2.6118\n",
      "Epoch [79][40/100], loss_cls: 1.6093e-06, depth_loss: 11.458 lr: 1.25000e-05, loss: 1.8515\n",
      "Epoch [79][45/100], loss_cls: 0.0022468, depth_loss: 23.731 lr: 1.25000e-05, loss: 2.452\n",
      "Epoch [79][50/100], loss_cls: 7.6294e-06, depth_loss: 6.4407 lr: 1.25000e-05, loss: 2.1668\n",
      "Epoch [79][55/100], loss_cls: 1.3053e-05, depth_loss: 7.6287 lr: 1.25000e-05, loss: 2.1972\n",
      "Epoch [79][60/100], loss_cls: 0.0012754, depth_loss: 13.114 lr: 1.25000e-05, loss: 2.7578\n",
      "Epoch [79][65/100], loss_cls: 0.00016931, depth_loss: 19.516 lr: 1.25000e-05, loss: 2.2017\n",
      "Epoch [79][70/100], loss_cls: 0.00095271, depth_loss: 9.2189 lr: 1.25000e-05, loss: 3.2088\n",
      "Epoch [79][75/100], loss_cls: 0.36584, depth_loss: 25.267 lr: 1.25000e-05, loss: 2.1763\n",
      "Epoch [79][80/100], loss_cls: 1.0133e-06, depth_loss: 8.8545 lr: 1.25000e-05, loss: 1.9214\n",
      "Epoch [79][85/100], loss_cls: 0.00056001, depth_loss: 11.963 lr: 1.25000e-05, loss: 2.223\n",
      "Epoch [79][90/100], loss_cls: 0.00031342, depth_loss: 12.317 lr: 1.25000e-05, loss: 2.0926\n",
      "Epoch [79][95/100], loss_cls: 0.0012396, depth_loss: 11.429 lr: 1.25000e-05, loss: 2.2506\n",
      "Epoch [79][100/100], loss_cls: 2.0861e-05, depth_loss: 7.8884 lr: 1.25000e-05, loss: 2.7408\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.7408, val_loss: 2.7751\n",
      "Epoch [80][5/100], loss_cls: 0.0047125, depth_loss: 7.9763 lr: 1.25000e-05, loss: 2.1157\n",
      "Epoch [80][10/100], loss_cls: 8.1658e-06, depth_loss: 6.5057 lr: 1.25000e-05, loss: 2.1251\n",
      "Epoch [80][15/100], loss_cls: 0.018539, depth_loss: 16.514 lr: 1.25000e-05, loss: 1.9215\n",
      "Epoch [80][20/100], loss_cls: 2.3842e-07, depth_loss: 15.18 lr: 1.25000e-05, loss: 2.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80][25/100], loss_cls: 4.0531e-06, depth_loss: 7.9365 lr: 1.25000e-05, loss: 1.9785\n",
      "Epoch [80][30/100], loss_cls: 4.3511e-06, depth_loss: 8.5307 lr: 1.25000e-05, loss: 1.9959\n",
      "Epoch [80][35/100], loss_cls: 0.13922, depth_loss: 7.8189 lr: 1.25000e-05, loss: 2.875\n",
      "Epoch [80][40/100], loss_cls: 0.00016716, depth_loss: 9.1286 lr: 1.25000e-05, loss: 2.2409\n",
      "Epoch [80][45/100], loss_cls: 1.2156, depth_loss: 13.384 lr: 1.25000e-05, loss: 3.1723\n",
      "Epoch [80][50/100], loss_cls: 3.6287, depth_loss: 6.4857 lr: 1.25000e-05, loss: 2.5983\n",
      "Epoch [80][55/100], loss_cls: 0.0021141, depth_loss: 14.328 lr: 1.25000e-05, loss: 3.0757\n",
      "Epoch [80][60/100], loss_cls: 2.4438e-06, depth_loss: 7.0236 lr: 1.25000e-05, loss: 2.1253\n",
      "Epoch [80][65/100], loss_cls: 0.00080022, depth_loss: 6.514 lr: 1.25000e-05, loss: 1.7312\n",
      "Epoch [80][70/100], loss_cls: 0.0003093, depth_loss: 5.2744 lr: 1.25000e-05, loss: 2.2002\n",
      "Epoch [80][75/100], loss_cls: 0.014956, depth_loss: 10.82 lr: 1.25000e-05, loss: 3.252\n",
      "Epoch [80][80/100], loss_cls: 0.019639, depth_loss: 10.173 lr: 1.25000e-05, loss: 2.6744\n",
      "Epoch [80][85/100], loss_cls: 0.0045782, depth_loss: 5.1445 lr: 1.25000e-05, loss: 2.3208\n",
      "Epoch [80][90/100], loss_cls: 0.015133, depth_loss: 11.485 lr: 1.25000e-05, loss: 1.9687\n",
      "Epoch [80][95/100], loss_cls: 0.015077, depth_loss: 5.3297 lr: 1.25000e-05, loss: 1.8563\n",
      "Epoch [80][100/100], loss_cls: 0.18309, depth_loss: 7.7195 lr: 1.25000e-05, loss: 1.9286\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 1.9286, val_loss: 2.8469\n",
      "Epoch [81][5/100], loss_cls: 0.00068981, depth_loss: 8.1283 lr: 1.25000e-05, loss: 2.624\n",
      "Epoch [81][10/100], loss_cls: 0.00023201, depth_loss: 9.0789 lr: 1.25000e-05, loss: 1.8727\n",
      "Epoch [81][15/100], loss_cls: 0.00024611, depth_loss: 12.549 lr: 1.25000e-05, loss: 3.6873\n",
      "Epoch [81][20/100], loss_cls: 1.915, depth_loss: 46.533 lr: 1.25000e-05, loss: 4.0992\n",
      "Epoch [81][25/100], loss_cls: 2.1458e-06, depth_loss: 8.2921 lr: 1.25000e-05, loss: 2.6093\n",
      "Epoch [81][30/100], loss_cls: 1.6093e-06, depth_loss: 12.508 lr: 1.25000e-05, loss: 2.6743\n",
      "Epoch [81][35/100], loss_cls: 0.027189, depth_loss: 15.435 lr: 1.25000e-05, loss: 2.3674\n",
      "Epoch [81][40/100], loss_cls: 5.9605e-08, depth_loss: 17.838 lr: 1.25000e-05, loss: 2.8008\n",
      "Epoch [81][45/100], loss_cls: 0.07394, depth_loss: 9.2936 lr: 1.25000e-05, loss: 2.1539\n",
      "Epoch [81][50/100], loss_cls: 8.1953e-05, depth_loss: 7.1245 lr: 1.25000e-05, loss: 2.2521\n",
      "Epoch [81][55/100], loss_cls: 2.3704, depth_loss: 12.619 lr: 1.25000e-05, loss: 2.5996\n",
      "Epoch [81][60/100], loss_cls: 0.0040268, depth_loss: 27.848 lr: 1.25000e-05, loss: 2.8503\n",
      "Epoch [81][65/100], loss_cls: 0.00013099, depth_loss: 8.1854 lr: 1.25000e-05, loss: 1.694\n",
      "Epoch [81][70/100], loss_cls: 0.051265, depth_loss: 22.193 lr: 1.25000e-05, loss: 3.2115\n",
      "Epoch [81][75/100], loss_cls: 1.3947e-05, depth_loss: 20.263 lr: 1.25000e-05, loss: 2.8793\n",
      "Epoch [81][80/100], loss_cls: 0.029253, depth_loss: 9.4521 lr: 1.25000e-05, loss: 2.1518\n",
      "Epoch [81][85/100], loss_cls: 3.8743e-06, depth_loss: 5.553 lr: 1.25000e-05, loss: 2.6565\n",
      "Epoch [81][90/100], loss_cls: 0.00077764, depth_loss: 9.8294 lr: 1.25000e-05, loss: 2.5407\n",
      "Epoch [81][95/100], loss_cls: 1.0378, depth_loss: 14.402 lr: 1.25000e-05, loss: 3.1779\n",
      "Epoch [81][100/100], loss_cls: 7.3909e-06, depth_loss: 13.423 lr: 1.25000e-05, loss: 2.7197\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.7197, val_loss: 2.8794\n",
      "Epoch [82][5/100], loss_cls: 1.198e-05, depth_loss: 6.6634 lr: 1.25000e-05, loss: 4.0385\n",
      "Epoch [82][10/100], loss_cls: 2.9504e-05, depth_loss: 11.612 lr: 1.25000e-05, loss: 2.8983\n",
      "Epoch [82][15/100], loss_cls: 0.025384, depth_loss: 10.115 lr: 1.25000e-05, loss: 2.3352\n",
      "Epoch [82][20/100], loss_cls: 1.9491e-05, depth_loss: 10.062 lr: 1.25000e-05, loss: 1.8105\n",
      "Epoch [82][25/100], loss_cls: 0.0054362, depth_loss: 22.511 lr: 1.25000e-05, loss: 2.4781\n",
      "Epoch [82][30/100], loss_cls: 6.02e-06, depth_loss: 11.72 lr: 1.25000e-05, loss: 2.2131\n",
      "Epoch [82][35/100], loss_cls: 0.047442, depth_loss: 7.9124 lr: 1.25000e-05, loss: 2.0966\n",
      "Epoch [82][40/100], loss_cls: 0.00040707, depth_loss: 6.2297 lr: 1.25000e-05, loss: 3.5948\n",
      "Epoch [82][45/100], loss_cls: 0.0029957, depth_loss: 5.2013 lr: 1.25000e-05, loss: 2.9987\n",
      "Epoch [82][50/100], loss_cls: 3.308e-05, depth_loss: 8.0372 lr: 1.25000e-05, loss: 1.747\n",
      "Epoch [82][55/100], loss_cls: 4.5595e-05, depth_loss: 12.951 lr: 1.25000e-05, loss: 2.45\n",
      "Epoch [82][60/100], loss_cls: 8.8214e-06, depth_loss: 6.8439 lr: 1.25000e-05, loss: 2.4414\n",
      "Epoch [82][65/100], loss_cls: 0.00027023, depth_loss: 15.507 lr: 1.25000e-05, loss: 2.6875\n",
      "Epoch [82][70/100], loss_cls: 0.00052937, depth_loss: 9.1868 lr: 1.25000e-05, loss: 1.7762\n",
      "Epoch [82][75/100], loss_cls: 0.0032068, depth_loss: 5.6571 lr: 1.25000e-05, loss: 3.2915\n",
      "Epoch [82][80/100], loss_cls: 0.029323, depth_loss: 9.0064 lr: 1.25000e-05, loss: 2.6253\n",
      "Epoch [82][85/100], loss_cls: 0.1475, depth_loss: 13.492 lr: 1.25000e-05, loss: 2.239\n",
      "Epoch [82][90/100], loss_cls: 0.0026376, depth_loss: 5.8055 lr: 1.25000e-05, loss: 2.2266\n",
      "Epoch [82][95/100], loss_cls: 0.00058418, depth_loss: 6.1954 lr: 1.25000e-05, loss: 2.838\n",
      "Epoch [82][100/100], loss_cls: 6.2522e-05, depth_loss: 8.972 lr: 1.25000e-05, loss: 3.1101\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.1101, val_loss: 2.6907\n",
      "Epoch [83][5/100], loss_cls: 0.00045666, depth_loss: 10.154 lr: 1.25000e-05, loss: 2.6458\n",
      "Epoch [83][10/100], loss_cls: 1.1921e-07, depth_loss: 8.0497 lr: 1.25000e-05, loss: 1.7571\n",
      "Epoch [83][15/100], loss_cls: 0.0063614, depth_loss: 10.673 lr: 1.25000e-05, loss: 2.188\n",
      "Epoch [83][20/100], loss_cls: 0.036709, depth_loss: 14.528 lr: 1.25000e-05, loss: 2.4283\n",
      "Epoch [83][25/100], loss_cls: 0.056581, depth_loss: 8.7802 lr: 1.25000e-05, loss: 3.1592\n",
      "Epoch [83][30/100], loss_cls: 2.7477e-05, depth_loss: 10.658 lr: 1.25000e-05, loss: 1.797\n",
      "Epoch [83][35/100], loss_cls: 0.0031034, depth_loss: 11.63 lr: 1.25000e-05, loss: 2.8943\n",
      "Epoch [83][40/100], loss_cls: 0.00063913, depth_loss: 12.237 lr: 1.25000e-05, loss: 2.6812\n",
      "Epoch [83][45/100], loss_cls: 0.0052047, depth_loss: 10.743 lr: 1.25000e-05, loss: 3.0506\n",
      "Epoch [83][50/100], loss_cls: 0.081038, depth_loss: 8.7652 lr: 1.25000e-05, loss: 2.2139\n",
      "Epoch [83][55/100], loss_cls: 1.2696e-05, depth_loss: 5.4895 lr: 1.25000e-05, loss: 1.9397\n",
      "Epoch [83][60/100], loss_cls: 0.00064101, depth_loss: 7.4441 lr: 1.25000e-05, loss: 2.1188\n",
      "Epoch [83][65/100], loss_cls: 0.62827, depth_loss: 22.442 lr: 1.25000e-05, loss: 2.5431\n",
      "Epoch [83][70/100], loss_cls: 0.0053301, depth_loss: 8.5666 lr: 1.25000e-05, loss: 3.1455\n",
      "Epoch [83][75/100], loss_cls: 0.025948, depth_loss: 12.741 lr: 1.25000e-05, loss: 2.5481\n",
      "Epoch [83][80/100], loss_cls: 0.38444, depth_loss: 6.3674 lr: 1.25000e-05, loss: 2.3874\n",
      "Epoch [83][85/100], loss_cls: 2.7061, depth_loss: 7.2144 lr: 1.25000e-05, loss: 3.4042\n",
      "Epoch [83][90/100], loss_cls: 9.2975e-05, depth_loss: 9.437 lr: 1.25000e-05, loss: 3.1021\n",
      "Epoch [83][95/100], loss_cls: 0.0034658, depth_loss: 6.4273 lr: 1.25000e-05, loss: 2.1925\n",
      "Epoch [83][100/100], loss_cls: 0.016231, depth_loss: 12.872 lr: 1.25000e-05, loss: 1.963\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 1.0, train_loss: 1.963, val_loss: 2.621\n",
      "Saving checkpoint at 83 epochs...\n",
      "Epoch [84][5/100], loss_cls: 0.56153, depth_loss: 8.7339 lr: 1.25000e-05, loss: 2.5338\n",
      "Epoch [84][10/100], loss_cls: 0.0046534, depth_loss: 13.757 lr: 1.25000e-05, loss: 2.46\n",
      "Epoch [84][15/100], loss_cls: 0.11515, depth_loss: 48.022 lr: 1.25000e-05, loss: 4.4636\n",
      "Epoch [84][20/100], loss_cls: 0.00047786, depth_loss: 7.6075 lr: 1.25000e-05, loss: 2.4734\n",
      "Epoch [84][25/100], loss_cls: 0.001173, depth_loss: 12.705 lr: 1.25000e-05, loss: 3.371\n",
      "Epoch [84][30/100], loss_cls: 0.054462, depth_loss: 15.276 lr: 1.25000e-05, loss: 2.6022\n",
      "Epoch [84][35/100], loss_cls: 0.021853, depth_loss: 9.5656 lr: 1.25000e-05, loss: 1.99\n",
      "Epoch [84][40/100], loss_cls: 0.00016818, depth_loss: 11.642 lr: 1.25000e-05, loss: 2.7605\n",
      "Epoch [84][45/100], loss_cls: 0.00061736, depth_loss: 8.6287 lr: 1.25000e-05, loss: 2.8465\n",
      "Epoch [84][50/100], loss_cls: 0.0, depth_loss: 8.2653 lr: 1.25000e-05, loss: 2.1222\n",
      "Epoch [84][55/100], loss_cls: 9.7155e-06, depth_loss: 16.598 lr: 1.25000e-05, loss: 3.0731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84][60/100], loss_cls: 0.018004, depth_loss: 11.299 lr: 1.25000e-05, loss: 2.7194\n",
      "Epoch [84][65/100], loss_cls: 0.45388, depth_loss: 5.9812 lr: 1.25000e-05, loss: 3.4728\n",
      "Epoch [84][70/100], loss_cls: 0.00022879, depth_loss: 7.0064 lr: 1.25000e-05, loss: 2.8467\n",
      "Epoch [84][75/100], loss_cls: 1.2981, depth_loss: 7.4675 lr: 1.25000e-05, loss: 2.5909\n",
      "Epoch [84][80/100], loss_cls: 4.5715e-05, depth_loss: 11.367 lr: 1.25000e-05, loss: 2.8168\n",
      "Epoch [84][85/100], loss_cls: 0.54589, depth_loss: 20.342 lr: 1.25000e-05, loss: 2.5406\n",
      "Epoch [84][90/100], loss_cls: 0.0028644, depth_loss: 5.913 lr: 1.25000e-05, loss: 1.485\n",
      "Epoch [84][95/100], loss_cls: 1.5001, depth_loss: 10.202 lr: 1.25000e-05, loss: 3.0482\n",
      "Epoch [84][100/100], loss_cls: 4.0531e-06, depth_loss: 8.5726 lr: 1.25000e-05, loss: 2.0705\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.0705, val_loss: 2.6109\n",
      "Saving checkpoint at 84 epochs...\n",
      "Epoch [85][5/100], loss_cls: 0.00014173, depth_loss: 5.5484 lr: 1.25000e-05, loss: 2.936\n",
      "Epoch [85][10/100], loss_cls: 0.0005052, depth_loss: 10.616 lr: 1.25000e-05, loss: 2.3004\n",
      "Epoch [85][15/100], loss_cls: 0.00011843, depth_loss: 11.002 lr: 1.25000e-05, loss: 2.4813\n",
      "Epoch [85][20/100], loss_cls: 0.00025695, depth_loss: 9.4796 lr: 1.25000e-05, loss: 2.0009\n",
      "Epoch [85][25/100], loss_cls: 5.2509e-05, depth_loss: 6.4765 lr: 1.25000e-05, loss: 3.6206\n",
      "Epoch [85][30/100], loss_cls: 2.1338e-05, depth_loss: 6.4575 lr: 1.25000e-05, loss: 2.0918\n",
      "Epoch [85][35/100], loss_cls: 9.8943e-06, depth_loss: 6.3264 lr: 1.25000e-05, loss: 1.99\n",
      "Epoch [85][40/100], loss_cls: 0.10302, depth_loss: 10.02 lr: 1.25000e-05, loss: 2.221\n",
      "Epoch [85][45/100], loss_cls: 0.0053126, depth_loss: 6.8994 lr: 1.25000e-05, loss: 2.662\n",
      "Epoch [85][50/100], loss_cls: 0.0064831, depth_loss: 10.24 lr: 1.25000e-05, loss: 2.8349\n",
      "Epoch [85][55/100], loss_cls: 0.0059745, depth_loss: 7.8661 lr: 1.25000e-05, loss: 1.908\n",
      "Epoch [85][60/100], loss_cls: 2.1601, depth_loss: 10.051 lr: 1.25000e-05, loss: 1.9961\n",
      "Epoch [85][65/100], loss_cls: 3.6656e-05, depth_loss: 6.717 lr: 1.25000e-05, loss: 2.8859\n",
      "Epoch [85][70/100], loss_cls: 0.11343, depth_loss: 8.6577 lr: 1.25000e-05, loss: 2.2\n",
      "Epoch [85][75/100], loss_cls: 0.0032138, depth_loss: 6.4939 lr: 1.25000e-05, loss: 2.0602\n",
      "Epoch [85][80/100], loss_cls: 0.011389, depth_loss: 7.3391 lr: 1.25000e-05, loss: 2.4314\n",
      "Epoch [85][85/100], loss_cls: 0.19049, depth_loss: 17.003 lr: 1.25000e-05, loss: 2.9669\n",
      "Epoch [85][90/100], loss_cls: 0.0002417, depth_loss: 8.3617 lr: 1.25000e-05, loss: 2.6028\n",
      "Epoch [85][95/100], loss_cls: 0.0020208, depth_loss: 15.201 lr: 1.25000e-05, loss: 3.257\n",
      "Epoch [85][100/100], loss_cls: 4.7444e-05, depth_loss: 10.315 lr: 1.25000e-05, loss: 2.0237\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.0237, val_loss: 2.6196\n",
      "Epoch [86][5/100], loss_cls: 0.0060328, depth_loss: 16.939 lr: 1.25000e-05, loss: 2.2124\n",
      "Epoch [86][10/100], loss_cls: 4.2437e-05, depth_loss: 8.1307 lr: 1.25000e-05, loss: 2.4145\n",
      "Epoch [86][15/100], loss_cls: 1.5717, depth_loss: 5.6474 lr: 1.25000e-05, loss: 1.8373\n",
      "Epoch [86][20/100], loss_cls: 0.00026404, depth_loss: 14.124 lr: 1.25000e-05, loss: 2.6332\n",
      "Epoch [86][25/100], loss_cls: 0.0, depth_loss: 6.991 lr: 1.25000e-05, loss: 2.7067\n",
      "Epoch [86][30/100], loss_cls: 3.3975e-06, depth_loss: 9.1604 lr: 1.25000e-05, loss: 3.3909\n",
      "Epoch [86][35/100], loss_cls: 0.0001037, depth_loss: 8.933 lr: 1.25000e-05, loss: 2.2758\n",
      "Epoch [86][40/100], loss_cls: 0.0024895, depth_loss: 5.899 lr: 1.25000e-05, loss: 2.1627\n",
      "Epoch [86][45/100], loss_cls: 0.013056, depth_loss: 10.476 lr: 1.25000e-05, loss: 1.8086\n",
      "Epoch [86][50/100], loss_cls: 0.00049924, depth_loss: 12.359 lr: 1.25000e-05, loss: 1.7917\n",
      "Epoch [86][55/100], loss_cls: 6.1212e-05, depth_loss: 8.019 lr: 1.25000e-05, loss: 2.5406\n",
      "Epoch [86][60/100], loss_cls: 3.3139e-05, depth_loss: 15.011 lr: 1.25000e-05, loss: 2.2501\n",
      "Epoch [86][65/100], loss_cls: 0.15913, depth_loss: 20.482 lr: 1.25000e-05, loss: 4.5794\n",
      "Epoch [86][70/100], loss_cls: 0.00037847, depth_loss: 7.9329 lr: 1.25000e-05, loss: 1.6139\n",
      "Epoch [86][75/100], loss_cls: 0.00022015, depth_loss: 9.5174 lr: 1.25000e-05, loss: 3.1133\n",
      "Epoch [86][80/100], loss_cls: 0.0024162, depth_loss: 6.7275 lr: 1.25000e-05, loss: 1.8505\n",
      "Epoch [86][85/100], loss_cls: 0.0091229, depth_loss: 16.643 lr: 1.25000e-05, loss: 2.7753\n",
      "Epoch [86][90/100], loss_cls: 0.00016502, depth_loss: 11.446 lr: 1.25000e-05, loss: 2.1891\n",
      "Epoch [86][95/100], loss_cls: 0.92845, depth_loss: 8.2052 lr: 1.25000e-05, loss: 2.1267\n",
      "Epoch [86][100/100], loss_cls: 0.00012009, depth_loss: 22.162 lr: 1.25000e-05, loss: 3.0325\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.0325, val_loss: 2.7379\n",
      "Epoch [87][5/100], loss_cls: 0.0017934, depth_loss: 10.925 lr: 1.25000e-05, loss: 2.0877\n",
      "Epoch [87][10/100], loss_cls: 0.001906, depth_loss: 10.016 lr: 1.25000e-05, loss: 3.4926\n",
      "Epoch [87][15/100], loss_cls: 0.007009, depth_loss: 12.768 lr: 1.25000e-05, loss: 1.9739\n",
      "Epoch [87][20/100], loss_cls: 0.00034538, depth_loss: 8.283 lr: 1.25000e-05, loss: 2.6043\n",
      "Epoch [87][25/100], loss_cls: 0.057588, depth_loss: 17.788 lr: 1.25000e-05, loss: 2.9088\n",
      "Epoch [87][30/100], loss_cls: 8.5823e-05, depth_loss: 13.279 lr: 1.25000e-05, loss: 3.1038\n",
      "Epoch [87][35/100], loss_cls: 0.00027083, depth_loss: 13.068 lr: 1.25000e-05, loss: 2.7991\n",
      "Epoch [87][40/100], loss_cls: 1.4007e-05, depth_loss: 11.891 lr: 1.25000e-05, loss: 1.7896\n",
      "Epoch [87][45/100], loss_cls: 3.1978, depth_loss: 13.753 lr: 1.25000e-05, loss: 2.9858\n",
      "Epoch [87][50/100], loss_cls: 0.0013143, depth_loss: 9.3856 lr: 1.25000e-05, loss: 2.0069\n",
      "Epoch [87][55/100], loss_cls: 4.5299e-06, depth_loss: 13.207 lr: 1.25000e-05, loss: 2.375\n",
      "Epoch [87][60/100], loss_cls: 1.6212e-05, depth_loss: 6.2521 lr: 1.25000e-05, loss: 2.2667\n",
      "Epoch [87][65/100], loss_cls: 0.045546, depth_loss: 9.0805 lr: 1.25000e-05, loss: 1.8329\n",
      "Epoch [87][70/100], loss_cls: 0.00092351, depth_loss: 16.218 lr: 1.25000e-05, loss: 2.4955\n",
      "Epoch [87][75/100], loss_cls: 0.51025, depth_loss: 6.0227 lr: 1.25000e-05, loss: 2.2367\n",
      "Epoch [87][80/100], loss_cls: 0.00011812, depth_loss: 8.883 lr: 1.25000e-05, loss: 2.3392\n",
      "Epoch [87][85/100], loss_cls: 2.4438e-06, depth_loss: 28.478 lr: 1.25000e-05, loss: 3.4845\n",
      "Epoch [87][90/100], loss_cls: 0.0022588, depth_loss: 5.5086 lr: 1.25000e-05, loss: 2.91\n",
      "Epoch [87][95/100], loss_cls: 5.394e-05, depth_loss: 15.316 lr: 1.25000e-05, loss: 3.3589\n",
      "Epoch [87][100/100], loss_cls: 0.0043023, depth_loss: 13.131 lr: 1.25000e-05, loss: 2.2466\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.2466, val_loss: 2.8144\n",
      "Epoch [88][5/100], loss_cls: 0.019521, depth_loss: 12.036 lr: 1.25000e-05, loss: 2.9483\n",
      "Epoch [88][10/100], loss_cls: 0.083042, depth_loss: 13.86 lr: 1.25000e-05, loss: 2.6958\n",
      "Epoch [88][15/100], loss_cls: 0.97135, depth_loss: 33.687 lr: 1.25000e-05, loss: 3.682\n",
      "Epoch [88][20/100], loss_cls: 0.00011425, depth_loss: 6.8087 lr: 1.25000e-05, loss: 3.1238\n",
      "Epoch [88][25/100], loss_cls: 0.00051526, depth_loss: 16.194 lr: 1.25000e-05, loss: 2.2592\n",
      "Epoch [88][30/100], loss_cls: 0.92034, depth_loss: 8.7914 lr: 1.25000e-05, loss: 1.7833\n",
      "Epoch [88][35/100], loss_cls: 5.8412e-06, depth_loss: 6.1986 lr: 1.25000e-05, loss: 2.1402\n",
      "Epoch [88][40/100], loss_cls: 0.00019022, depth_loss: 9.4527 lr: 1.25000e-05, loss: 3.2891\n",
      "Epoch [88][45/100], loss_cls: 4.5418e-05, depth_loss: 7.1255 lr: 1.25000e-05, loss: 2.5785\n",
      "Epoch [88][50/100], loss_cls: 0.0037326, depth_loss: 13.329 lr: 1.25000e-05, loss: 2.8594\n",
      "Epoch [88][55/100], loss_cls: 0.17766, depth_loss: 32.809 lr: 1.25000e-05, loss: 3.0519\n",
      "Epoch [88][60/100], loss_cls: 0.00036602, depth_loss: 10.956 lr: 1.25000e-05, loss: 2.8172\n",
      "Epoch [88][65/100], loss_cls: 0.0001009, depth_loss: 7.2374 lr: 1.25000e-05, loss: 1.5383\n",
      "Epoch [88][70/100], loss_cls: 0.0023212, depth_loss: 16.109 lr: 1.25000e-05, loss: 2.7892\n",
      "Epoch [88][75/100], loss_cls: 0.00010865, depth_loss: 8.2941 lr: 1.25000e-05, loss: 2.0835\n",
      "Epoch [88][80/100], loss_cls: 0.053782, depth_loss: 16.542 lr: 1.25000e-05, loss: 3.0577\n",
      "Epoch [88][85/100], loss_cls: 0.0010824, depth_loss: 7.0147 lr: 1.25000e-05, loss: 2.0942\n",
      "Epoch [88][90/100], loss_cls: 1.3292e-05, depth_loss: 8.5232 lr: 1.25000e-05, loss: 1.6715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88][95/100], loss_cls: 0.61735, depth_loss: 9.3129 lr: 1.25000e-05, loss: 2.4265\n",
      "Epoch [88][100/100], loss_cls: 0.0017603, depth_loss: 15.478 lr: 1.25000e-05, loss: 3.0308\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.0308, val_loss: 2.6973\n",
      "Epoch [89][5/100], loss_cls: 0.0030994, depth_loss: 8.5538 lr: 1.25000e-05, loss: 1.9543\n",
      "Epoch [89][10/100], loss_cls: 0.28669, depth_loss: 15.187 lr: 1.25000e-05, loss: 2.4544\n",
      "Epoch [89][15/100], loss_cls: 0.76941, depth_loss: 16.075 lr: 1.25000e-05, loss: 1.9111\n",
      "Epoch [89][20/100], loss_cls: 0.00013571, depth_loss: 9.0497 lr: 1.25000e-05, loss: 1.9338\n",
      "Epoch [89][25/100], loss_cls: 7.8081e-06, depth_loss: 6.8521 lr: 1.25000e-05, loss: 1.8326\n",
      "Epoch [89][30/100], loss_cls: 0.00067159, depth_loss: 15.901 lr: 1.25000e-05, loss: 2.2147\n",
      "Epoch [89][35/100], loss_cls: 1.8835e-05, depth_loss: 10.204 lr: 1.25000e-05, loss: 3.4738\n",
      "Epoch [89][40/100], loss_cls: 0.16756, depth_loss: 11.059 lr: 1.25000e-05, loss: 3.6777\n",
      "Epoch [89][45/100], loss_cls: 0.12472, depth_loss: 12.642 lr: 1.25000e-05, loss: 3.5865\n",
      "Epoch [89][50/100], loss_cls: 0.0027241, depth_loss: 13.612 lr: 1.25000e-05, loss: 2.3524\n",
      "Epoch [89][55/100], loss_cls: 0.82516, depth_loss: 10.255 lr: 1.25000e-05, loss: 2.3193\n",
      "Epoch [89][60/100], loss_cls: 0.23284, depth_loss: 18.429 lr: 1.25000e-05, loss: 3.2899\n",
      "Epoch [89][65/100], loss_cls: 0.0010822, depth_loss: 11.265 lr: 1.25000e-05, loss: 2.3566\n",
      "Epoch [89][70/100], loss_cls: 1.4233, depth_loss: 13.457 lr: 1.25000e-05, loss: 3.5126\n",
      "Epoch [89][75/100], loss_cls: 0.00061963, depth_loss: 6.8857 lr: 1.25000e-05, loss: 1.3687\n",
      "Epoch [89][80/100], loss_cls: 1.503, depth_loss: 15.186 lr: 1.25000e-05, loss: 2.9159\n",
      "Epoch [89][85/100], loss_cls: 1.078, depth_loss: 33.24 lr: 1.25000e-05, loss: 4.0084\n",
      "Epoch [89][90/100], loss_cls: 2.1458e-06, depth_loss: 20.277 lr: 1.25000e-05, loss: 2.298\n",
      "Epoch [89][95/100], loss_cls: 0.0008809, depth_loss: 5.9989 lr: 1.25000e-05, loss: 2.2586\n",
      "Epoch [89][100/100], loss_cls: 5.0066e-05, depth_loss: 9.3536 lr: 1.25000e-05, loss: 1.7155\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 1.7155, val_loss: 2.7663\n",
      "Epoch [90][5/100], loss_cls: 3.4451e-05, depth_loss: 4.6538 lr: 1.25000e-05, loss: 2.492\n",
      "Epoch [90][10/100], loss_cls: 0.0004606, depth_loss: 12.863 lr: 1.25000e-05, loss: 4.5871\n",
      "Epoch [90][15/100], loss_cls: 0.0041467, depth_loss: 23.668 lr: 1.25000e-05, loss: 2.9234\n",
      "Epoch [90][20/100], loss_cls: 0.010532, depth_loss: 12.343 lr: 1.25000e-05, loss: 2.1782\n",
      "Epoch [90][25/100], loss_cls: 0.21972, depth_loss: 18.221 lr: 1.25000e-05, loss: 2.5556\n",
      "Epoch [90][30/100], loss_cls: 2.9801e-05, depth_loss: 8.4928 lr: 1.25000e-05, loss: 1.9166\n",
      "Epoch [90][35/100], loss_cls: 0.01301, depth_loss: 11.263 lr: 1.25000e-05, loss: 2.1704\n",
      "Epoch [90][40/100], loss_cls: 0.0005296, depth_loss: 7.8889 lr: 1.25000e-05, loss: 1.9221\n",
      "Epoch [90][45/100], loss_cls: 3.5763e-07, depth_loss: 5.2111 lr: 1.25000e-05, loss: 1.6373\n",
      "Epoch [90][50/100], loss_cls: 0.54118, depth_loss: 13.178 lr: 1.25000e-05, loss: 1.8166\n",
      "Epoch [90][55/100], loss_cls: 0.0046002, depth_loss: 8.4599 lr: 1.25000e-05, loss: 1.8969\n",
      "Epoch [90][60/100], loss_cls: 3.2901e-05, depth_loss: 7.6515 lr: 1.25000e-05, loss: 1.7935\n",
      "Epoch [90][65/100], loss_cls: 0.0047519, depth_loss: 5.9474 lr: 1.25000e-05, loss: 3.2846\n",
      "Epoch [90][70/100], loss_cls: 0.2412, depth_loss: 7.2266 lr: 1.25000e-05, loss: 2.9047\n",
      "Epoch [90][75/100], loss_cls: 0.015329, depth_loss: 5.8 lr: 1.25000e-05, loss: 2.3432\n",
      "Epoch [90][80/100], loss_cls: 0.00029273, depth_loss: 11.526 lr: 1.25000e-05, loss: 3.2674\n",
      "Epoch [90][85/100], loss_cls: 0.71655, depth_loss: 19.529 lr: 1.25000e-05, loss: 3.1253\n",
      "Epoch [90][90/100], loss_cls: 0.00034362, depth_loss: 12.647 lr: 1.25000e-05, loss: 4.4704\n",
      "Epoch [90][95/100], loss_cls: 0.00061498, depth_loss: 10.658 lr: 1.25000e-05, loss: 2.8431\n",
      "Epoch [90][100/100], loss_cls: 0.79493, depth_loss: 12.444 lr: 1.25000e-05, loss: 2.9596\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 2.9596, val_loss: 2.6678\n",
      "Epoch [91][5/100], loss_cls: 2.2709e-05, depth_loss: 8.4239 lr: 1.25000e-05, loss: 2.3151\n",
      "Epoch [91][10/100], loss_cls: 0.035558, depth_loss: 22.82 lr: 1.25000e-05, loss: 2.6113\n",
      "Epoch [91][15/100], loss_cls: 0.00018837, depth_loss: 17.606 lr: 1.25000e-05, loss: 2.4561\n",
      "Epoch [91][20/100], loss_cls: 0.047934, depth_loss: 15.217 lr: 1.25000e-05, loss: 2.0185\n",
      "Epoch [91][25/100], loss_cls: 0.0089442, depth_loss: 11.737 lr: 1.25000e-05, loss: 2.175\n",
      "Epoch [91][30/100], loss_cls: 0.00038418, depth_loss: 8.0903 lr: 1.25000e-05, loss: 2.8694\n",
      "Epoch [91][35/100], loss_cls: 9.5363e-05, depth_loss: 17.041 lr: 1.25000e-05, loss: 3.0701\n",
      "Epoch [91][40/100], loss_cls: 0.03347, depth_loss: 11.34 lr: 1.25000e-05, loss: 1.9257\n",
      "Epoch [91][45/100], loss_cls: 0.0011934, depth_loss: 5.1934 lr: 1.25000e-05, loss: 4.6828\n",
      "Epoch [91][50/100], loss_cls: 0.33657, depth_loss: 16.504 lr: 1.25000e-05, loss: 2.752\n",
      "Epoch [91][55/100], loss_cls: 0.00076438, depth_loss: 12.677 lr: 1.25000e-05, loss: 2.5489\n",
      "Epoch [91][60/100], loss_cls: 0.00014929, depth_loss: 8.0979 lr: 1.25000e-05, loss: 2.7335\n",
      "Epoch [91][65/100], loss_cls: 7.1343e-05, depth_loss: 10.237 lr: 1.25000e-05, loss: 1.8544\n",
      "Epoch [91][70/100], loss_cls: 0.0010258, depth_loss: 27.575 lr: 1.25000e-05, loss: 3.4405\n",
      "Epoch [91][75/100], loss_cls: 0.0024726, depth_loss: 17.039 lr: 1.25000e-05, loss: 2.2472\n",
      "Epoch [91][80/100], loss_cls: 0.00013529, depth_loss: 13.334 lr: 1.25000e-05, loss: 2.3201\n",
      "Epoch [91][85/100], loss_cls: 1.8584, depth_loss: 127.0 lr: 1.25000e-05, loss: 7.4204\n",
      "Epoch [91][90/100], loss_cls: 0.0013342, depth_loss: 6.9332 lr: 1.25000e-05, loss: 2.6975\n",
      "Epoch [91][95/100], loss_cls: 0.80466, depth_loss: 22.716 lr: 1.25000e-05, loss: 2.4413\n",
      "Epoch [91][100/100], loss_cls: 3.0994e-05, depth_loss: 10.899 lr: 1.25000e-05, loss: 2.0012\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.0012, val_loss: 2.5935\n",
      "Saving checkpoint at 91 epochs...\n",
      "Epoch [92][5/100], loss_cls: 0.0037263, depth_loss: 11.868 lr: 1.25000e-05, loss: 2.9573\n",
      "Epoch [92][10/100], loss_cls: 1.2159e-05, depth_loss: 7.0469 lr: 1.25000e-05, loss: 2.8959\n",
      "Epoch [92][15/100], loss_cls: 0.0054646, depth_loss: 7.0424 lr: 1.25000e-05, loss: 2.6757\n",
      "Epoch [92][20/100], loss_cls: 0.00018625, depth_loss: 9.6906 lr: 1.25000e-05, loss: 1.8095\n",
      "Epoch [92][25/100], loss_cls: 0.014464, depth_loss: 6.5318 lr: 1.25000e-05, loss: 2.0304\n",
      "Epoch [92][30/100], loss_cls: 0.0017665, depth_loss: 12.692 lr: 1.25000e-05, loss: 2.7871\n",
      "Epoch [92][35/100], loss_cls: 1.8313, depth_loss: 17.56 lr: 1.25000e-05, loss: 3.0338\n",
      "Epoch [92][40/100], loss_cls: 0.00027268, depth_loss: 10.053 lr: 1.25000e-05, loss: 2.0308\n",
      "Epoch [92][45/100], loss_cls: 1.4173, depth_loss: 11.442 lr: 1.25000e-05, loss: 3.6841\n",
      "Epoch [92][50/100], loss_cls: 8.9407e-07, depth_loss: 7.1763 lr: 1.25000e-05, loss: 2.3865\n",
      "Epoch [92][55/100], loss_cls: 7.6294e-06, depth_loss: 7.9506 lr: 1.25000e-05, loss: 3.3872\n",
      "Epoch [92][60/100], loss_cls: 3.2424e-05, depth_loss: 5.4925 lr: 1.25000e-05, loss: 1.9294\n",
      "Epoch [92][65/100], loss_cls: 0.039184, depth_loss: 5.698 lr: 1.25000e-05, loss: 2.361\n",
      "Epoch [92][70/100], loss_cls: 8.583e-06, depth_loss: 15.275 lr: 1.25000e-05, loss: 2.5331\n",
      "Epoch [92][75/100], loss_cls: 0.0081041, depth_loss: 7.4633 lr: 1.25000e-05, loss: 3.0664\n",
      "Epoch [92][80/100], loss_cls: 0.0009395, depth_loss: 8.5162 lr: 1.25000e-05, loss: 1.8501\n",
      "Epoch [92][85/100], loss_cls: 0.00081016, depth_loss: 11.914 lr: 1.25000e-05, loss: 2.3822\n",
      "Epoch [92][90/100], loss_cls: 0.049687, depth_loss: 7.2788 lr: 1.25000e-05, loss: 2.0872\n",
      "Epoch [92][95/100], loss_cls: 0.011439, depth_loss: 9.3084 lr: 1.25000e-05, loss: 2.1415\n",
      "Epoch [92][100/100], loss_cls: 1.2226, depth_loss: 23.555 lr: 1.25000e-05, loss: 3.2007\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.2007, val_loss: 2.6412\n",
      "Epoch [93][5/100], loss_cls: 0.0033188, depth_loss: 4.5351 lr: 1.25000e-05, loss: 2.3214\n",
      "Epoch [93][10/100], loss_cls: 0.00082377, depth_loss: 6.7576 lr: 1.25000e-05, loss: 3.1375\n",
      "Epoch [93][15/100], loss_cls: 1.6212e-05, depth_loss: 10.867 lr: 1.25000e-05, loss: 2.97\n",
      "Epoch [93][20/100], loss_cls: 0.014926, depth_loss: 7.2408 lr: 1.25000e-05, loss: 2.3298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93][25/100], loss_cls: 0.00072974, depth_loss: 11.787 lr: 1.25000e-05, loss: 1.5308\n",
      "Epoch [93][30/100], loss_cls: 4.1723e-07, depth_loss: 7.2311 lr: 1.25000e-05, loss: 2.8042\n",
      "Epoch [93][35/100], loss_cls: 0.006242, depth_loss: 10.108 lr: 1.25000e-05, loss: 3.0967\n",
      "Epoch [93][40/100], loss_cls: 5.4836e-06, depth_loss: 13.143 lr: 1.25000e-05, loss: 1.9388\n",
      "Epoch [93][45/100], loss_cls: 0.0026677, depth_loss: 6.8645 lr: 1.25000e-05, loss: 2.3685\n",
      "Epoch [93][50/100], loss_cls: 1.3485, depth_loss: 19.69 lr: 1.25000e-05, loss: 2.6409\n",
      "Epoch [93][55/100], loss_cls: 0.016438, depth_loss: 16.952 lr: 1.25000e-05, loss: 2.2846\n",
      "Epoch [93][60/100], loss_cls: 0.57794, depth_loss: 20.051 lr: 1.25000e-05, loss: 3.1067\n",
      "Epoch [93][65/100], loss_cls: 0.0005427, depth_loss: 6.5175 lr: 1.25000e-05, loss: 1.6373\n",
      "Epoch [93][70/100], loss_cls: 0.01983, depth_loss: 6.1187 lr: 1.25000e-05, loss: 1.7452\n",
      "Epoch [93][75/100], loss_cls: 1.8358e-05, depth_loss: 6.8162 lr: 1.25000e-05, loss: 2.1225\n",
      "Epoch [93][80/100], loss_cls: 0.0017357, depth_loss: 8.6104 lr: 1.25000e-05, loss: 4.4254\n",
      "Epoch [93][85/100], loss_cls: 0.20491, depth_loss: 32.672 lr: 1.25000e-05, loss: 3.551\n",
      "Epoch [93][90/100], loss_cls: 2.1612, depth_loss: 39.435 lr: 1.25000e-05, loss: 3.7211\n",
      "Epoch [93][95/100], loss_cls: 1.6689e-05, depth_loss: 6.0033 lr: 1.25000e-05, loss: 1.5919\n",
      "Epoch [93][100/100], loss_cls: 0.0099399, depth_loss: 8.7643 lr: 1.25000e-05, loss: 2.3558\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.3558, val_loss: 2.627\n",
      "Epoch [94][5/100], loss_cls: 7.0151e-05, depth_loss: 8.2428 lr: 1.25000e-05, loss: 2.0355\n",
      "Epoch [94][10/100], loss_cls: 0.00013278, depth_loss: 7.64 lr: 1.25000e-05, loss: 3.7298\n",
      "Epoch [94][15/100], loss_cls: 5.126e-06, depth_loss: 13.838 lr: 1.25000e-05, loss: 2.2546\n",
      "Epoch [94][20/100], loss_cls: 0.30493, depth_loss: 6.1158 lr: 1.25000e-05, loss: 2.1261\n",
      "Epoch [94][25/100], loss_cls: 0.00026774, depth_loss: 10.64 lr: 1.25000e-05, loss: 2.5799\n",
      "Epoch [94][30/100], loss_cls: 0.0031527, depth_loss: 9.8405 lr: 1.25000e-05, loss: 2.0676\n",
      "Epoch [94][35/100], loss_cls: 1.9017, depth_loss: 6.1691 lr: 1.25000e-05, loss: 4.2401\n",
      "Epoch [94][40/100], loss_cls: 5.2926e-05, depth_loss: 8.5729 lr: 1.25000e-05, loss: 1.5723\n",
      "Epoch [94][45/100], loss_cls: 8.2905e-05, depth_loss: 5.1133 lr: 1.25000e-05, loss: 1.4513\n",
      "Epoch [94][50/100], loss_cls: 0.0011538, depth_loss: 5.9075 lr: 1.25000e-05, loss: 1.9857\n",
      "Epoch [94][55/100], loss_cls: 6.9494e-05, depth_loss: 7.9478 lr: 1.25000e-05, loss: 2.1025\n",
      "Epoch [94][60/100], loss_cls: 0.00034779, depth_loss: 6.2586 lr: 1.25000e-05, loss: 1.4106\n",
      "Epoch [94][65/100], loss_cls: 1.2186, depth_loss: 33.574 lr: 1.25000e-05, loss: 3.8809\n",
      "Epoch [94][70/100], loss_cls: 0.0098192, depth_loss: 10.727 lr: 1.25000e-05, loss: 1.5934\n",
      "Epoch [94][75/100], loss_cls: 0.26893, depth_loss: 14.724 lr: 1.25000e-05, loss: 2.9182\n",
      "Epoch [94][80/100], loss_cls: 0.00030199, depth_loss: 11.224 lr: 1.25000e-05, loss: 2.0483\n",
      "Epoch [94][85/100], loss_cls: 0.0014985, depth_loss: 11.542 lr: 1.25000e-05, loss: 2.1856\n",
      "Epoch [94][90/100], loss_cls: 0.65439, depth_loss: 23.557 lr: 1.25000e-05, loss: 3.5697\n",
      "Epoch [94][95/100], loss_cls: 0.0010393, depth_loss: 23.023 lr: 1.25000e-05, loss: 2.3579\n",
      "Epoch [94][100/100], loss_cls: 0.00050833, depth_loss: 5.5488 lr: 1.25000e-05, loss: 1.618\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 1.618, val_loss: 2.6567\n",
      "Epoch [95][5/100], loss_cls: 0.00014417, depth_loss: 9.2949 lr: 1.25000e-05, loss: 1.7024\n",
      "Epoch [95][10/100], loss_cls: 0.077948, depth_loss: 7.8781 lr: 1.25000e-05, loss: 2.6426\n",
      "Epoch [95][15/100], loss_cls: 0.0011464, depth_loss: 10.234 lr: 1.25000e-05, loss: 1.7873\n",
      "Epoch [95][20/100], loss_cls: 0.058539, depth_loss: 11.651 lr: 1.25000e-05, loss: 2.522\n",
      "Epoch [95][25/100], loss_cls: 3.2782e-06, depth_loss: 10.419 lr: 1.25000e-05, loss: 2.1457\n",
      "Epoch [95][30/100], loss_cls: 5.722e-06, depth_loss: 9.626 lr: 1.25000e-05, loss: 2.572\n",
      "Epoch [95][35/100], loss_cls: 1.1921e-07, depth_loss: 5.2371 lr: 1.25000e-05, loss: 3.0593\n",
      "Epoch [95][40/100], loss_cls: 9.7742e-05, depth_loss: 8.192 lr: 1.25000e-05, loss: 2.9017\n",
      "Epoch [95][45/100], loss_cls: 5.3582e-05, depth_loss: 14.052 lr: 1.25000e-05, loss: 3.2391\n",
      "Epoch [95][50/100], loss_cls: 1.4365e-05, depth_loss: 11.865 lr: 1.25000e-05, loss: 1.94\n",
      "Epoch [95][55/100], loss_cls: 2.6917, depth_loss: 5.3613 lr: 1.25000e-05, loss: 2.555\n",
      "Epoch [95][60/100], loss_cls: 0.00032333, depth_loss: 11.396 lr: 1.25000e-05, loss: 1.8775\n",
      "Epoch [95][65/100], loss_cls: 0.00024777, depth_loss: 9.8467 lr: 1.25000e-05, loss: 1.9121\n",
      "Epoch [95][70/100], loss_cls: 0.0079833, depth_loss: 6.2659 lr: 1.25000e-05, loss: 2.0534\n",
      "Epoch [95][75/100], loss_cls: 0.00010621, depth_loss: 15.286 lr: 1.25000e-05, loss: 1.9203\n",
      "Epoch [95][80/100], loss_cls: 0.00018314, depth_loss: 9.0506 lr: 1.25000e-05, loss: 2.5479\n",
      "Epoch [95][85/100], loss_cls: 0.0007076, depth_loss: 6.9227 lr: 1.25000e-05, loss: 3.4504\n",
      "Epoch [95][90/100], loss_cls: 0.0024112, depth_loss: 12.275 lr: 1.25000e-05, loss: 3.3145\n",
      "Epoch [95][95/100], loss_cls: 0.31394, depth_loss: 27.084 lr: 1.25000e-05, loss: 3.7195\n",
      "Epoch [95][100/100], loss_cls: 0.0040023, depth_loss: 11.393 lr: 1.25000e-05, loss: 4.3859\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 4.3859, val_loss: 2.6121\n",
      "Epoch [96][5/100], loss_cls: 0.0001394, depth_loss: 10.082 lr: 1.25000e-05, loss: 2.3569\n",
      "Epoch [96][10/100], loss_cls: 0.73141, depth_loss: 15.176 lr: 1.25000e-05, loss: 2.7782\n",
      "Epoch [96][15/100], loss_cls: 5.8648e-05, depth_loss: 19.513 lr: 1.25000e-05, loss: 2.6509\n",
      "Epoch [96][20/100], loss_cls: 0.0036501, depth_loss: 14.244 lr: 1.25000e-05, loss: 2.0679\n",
      "Epoch [96][25/100], loss_cls: 0.0010019, depth_loss: 20.785 lr: 1.25000e-05, loss: 4.3764\n",
      "Epoch [96][30/100], loss_cls: 0.081292, depth_loss: 18.034 lr: 1.25000e-05, loss: 3.9875\n",
      "Epoch [96][35/100], loss_cls: 0.13455, depth_loss: 9.2444 lr: 1.25000e-05, loss: 2.4181\n",
      "Epoch [96][40/100], loss_cls: 0.0047257, depth_loss: 6.95 lr: 1.25000e-05, loss: 1.567\n",
      "Epoch [96][45/100], loss_cls: 0.044698, depth_loss: 24.938 lr: 1.25000e-05, loss: 2.1094\n",
      "Epoch [96][50/100], loss_cls: 0.0093477, depth_loss: 10.725 lr: 1.25000e-05, loss: 3.659\n",
      "Epoch [96][55/100], loss_cls: 1.9431e-05, depth_loss: 8.7769 lr: 1.25000e-05, loss: 1.8955\n",
      "Epoch [96][60/100], loss_cls: 0.70701, depth_loss: 7.4557 lr: 1.25000e-05, loss: 2.5993\n",
      "Epoch [96][65/100], loss_cls: 0.00010758, depth_loss: 9.9573 lr: 1.25000e-05, loss: 1.708\n",
      "Epoch [96][70/100], loss_cls: 0.0065549, depth_loss: 13.471 lr: 1.25000e-05, loss: 3.0751\n",
      "Epoch [96][75/100], loss_cls: 0.0014733, depth_loss: 7.0166 lr: 1.25000e-05, loss: 1.9772\n",
      "Epoch [96][80/100], loss_cls: 0.00027483, depth_loss: 6.1191 lr: 1.25000e-05, loss: 2.6504\n",
      "Epoch [96][85/100], loss_cls: 0.0002827, depth_loss: 15.382 lr: 1.25000e-05, loss: 2.0314\n",
      "Epoch [96][90/100], loss_cls: 0.0014142, depth_loss: 6.2718 lr: 1.25000e-05, loss: 1.974\n",
      "Epoch [96][95/100], loss_cls: 0.00025709, depth_loss: 16.089 lr: 1.25000e-05, loss: 3.1039\n",
      "Epoch [96][100/100], loss_cls: 0.0017533, depth_loss: 13.386 lr: 1.25000e-05, loss: 3.0214\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 3.0214, val_loss: 2.6523\n",
      "Epoch [97][5/100], loss_cls: 0.0013855, depth_loss: 10.435 lr: 1.25000e-05, loss: 2.4403\n",
      "Epoch [97][10/100], loss_cls: 0.00051591, depth_loss: 15.007 lr: 1.25000e-05, loss: 3.9808\n",
      "Epoch [97][15/100], loss_cls: 0.0009203, depth_loss: 6.8809 lr: 1.25000e-05, loss: 1.6586\n",
      "Epoch [97][20/100], loss_cls: 6.4727e-05, depth_loss: 5.0719 lr: 1.25000e-05, loss: 2.9473\n",
      "Epoch [97][25/100], loss_cls: 0.0031328, depth_loss: 8.7508 lr: 1.25000e-05, loss: 3.0712\n",
      "Epoch [97][30/100], loss_cls: 7.7302e-05, depth_loss: 5.0316 lr: 1.25000e-05, loss: 1.5502\n",
      "Epoch [97][35/100], loss_cls: 0.00019101, depth_loss: 5.286 lr: 1.25000e-05, loss: 1.5638\n",
      "Epoch [97][40/100], loss_cls: 0.00070916, depth_loss: 10.891 lr: 1.25000e-05, loss: 2.4996\n",
      "Epoch [97][45/100], loss_cls: 0.0040732, depth_loss: 9.2192 lr: 1.25000e-05, loss: 2.793\n",
      "Epoch [97][50/100], loss_cls: 8.8267e-05, depth_loss: 15.816 lr: 1.25000e-05, loss: 2.3082\n",
      "Epoch [97][55/100], loss_cls: 0.0057013, depth_loss: 10.987 lr: 1.25000e-05, loss: 2.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97][60/100], loss_cls: 0.0011539, depth_loss: 18.441 lr: 1.25000e-05, loss: 2.8249\n",
      "Epoch [97][65/100], loss_cls: 1.1412, depth_loss: 22.95 lr: 1.25000e-05, loss: 4.2271\n",
      "Epoch [97][70/100], loss_cls: 0.006056, depth_loss: 7.6871 lr: 1.25000e-05, loss: 2.2675\n",
      "Epoch [97][75/100], loss_cls: 0.00023127, depth_loss: 7.0918 lr: 1.25000e-05, loss: 2.0532\n",
      "Epoch [97][80/100], loss_cls: 0.00011026, depth_loss: 9.387 lr: 1.25000e-05, loss: 2.2011\n",
      "Epoch [97][85/100], loss_cls: 3.0577e-05, depth_loss: 5.7686 lr: 1.25000e-05, loss: 2.5085\n",
      "Epoch [97][90/100], loss_cls: 4.4821e-05, depth_loss: 13.868 lr: 1.25000e-05, loss: 2.2358\n",
      "Epoch [97][95/100], loss_cls: 2.7656e-05, depth_loss: 12.461 lr: 1.25000e-05, loss: 2.4304\n",
      "Epoch [97][100/100], loss_cls: 0.71404, depth_loss: 19.784 lr: 1.25000e-05, loss: 1.995\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 1.995, val_loss: 2.6627\n",
      "Epoch [98][5/100], loss_cls: 0.013766, depth_loss: 8.0234 lr: 1.25000e-05, loss: 2.7161\n",
      "Epoch [98][10/100], loss_cls: 0.00099958, depth_loss: 7.534 lr: 1.25000e-05, loss: 1.907\n",
      "Epoch [98][15/100], loss_cls: 8.8982e-05, depth_loss: 12.654 lr: 1.25000e-05, loss: 1.4442\n",
      "Epoch [98][20/100], loss_cls: 7.5697e-06, depth_loss: 10.406 lr: 1.25000e-05, loss: 2.8453\n",
      "Epoch [98][25/100], loss_cls: 1.789, depth_loss: 11.462 lr: 1.25000e-05, loss: 2.5116\n",
      "Epoch [98][30/100], loss_cls: 0.90973, depth_loss: 10.482 lr: 1.25000e-05, loss: 2.2796\n",
      "Epoch [98][35/100], loss_cls: 0.010466, depth_loss: 15.506 lr: 1.25000e-05, loss: 2.3018\n",
      "Epoch [98][40/100], loss_cls: 1.5239, depth_loss: 11.206 lr: 1.25000e-05, loss: 2.5528\n",
      "Epoch [98][45/100], loss_cls: 0.00022889, depth_loss: 14.248 lr: 1.25000e-05, loss: 2.7042\n",
      "Epoch [98][50/100], loss_cls: 0.73947, depth_loss: 9.9939 lr: 1.25000e-05, loss: 3.3548\n",
      "Epoch [98][55/100], loss_cls: 0.0019159, depth_loss: 5.4269 lr: 1.25000e-05, loss: 2.0984\n",
      "Epoch [98][60/100], loss_cls: 4.6073e-05, depth_loss: 7.3262 lr: 1.25000e-05, loss: 2.1288\n",
      "Epoch [98][65/100], loss_cls: 0.030199, depth_loss: 32.683 lr: 1.25000e-05, loss: 3.6442\n",
      "Epoch [98][70/100], loss_cls: 0.020668, depth_loss: 6.1126 lr: 1.25000e-05, loss: 1.8414\n",
      "Epoch [98][75/100], loss_cls: 0.011292, depth_loss: 11.49 lr: 1.25000e-05, loss: 3.2143\n",
      "Epoch [98][80/100], loss_cls: 0.005132, depth_loss: 13.73 lr: 1.25000e-05, loss: 1.8874\n",
      "Epoch [98][85/100], loss_cls: 2.9802e-07, depth_loss: 8.8489 lr: 1.25000e-05, loss: 1.6183\n",
      "Epoch [98][90/100], loss_cls: 0.0012809, depth_loss: 5.2516 lr: 1.25000e-05, loss: 1.7299\n",
      "Epoch [98][95/100], loss_cls: 0.00013219, depth_loss: 18.589 lr: 1.25000e-05, loss: 2.9589\n",
      "Epoch [98][100/100], loss_cls: 7.2717e-06, depth_loss: 8.7111 lr: 1.25000e-05, loss: 2.9663\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.9663, val_loss: 2.6195\n",
      "Epoch [99][5/100], loss_cls: 0.00067082, depth_loss: 5.6304 lr: 1.25000e-05, loss: 1.777\n",
      "Epoch [99][10/100], loss_cls: 2.4259e-05, depth_loss: 11.594 lr: 1.25000e-05, loss: 2.0099\n",
      "Epoch [99][15/100], loss_cls: 0.0034984, depth_loss: 7.8944 lr: 1.25000e-05, loss: 2.0382\n",
      "Epoch [99][20/100], loss_cls: 9.2381e-05, depth_loss: 4.4054 lr: 1.25000e-05, loss: 1.9672\n",
      "Epoch [99][25/100], loss_cls: 0.055484, depth_loss: 11.569 lr: 1.25000e-05, loss: 2.3634\n",
      "Epoch [99][30/100], loss_cls: 0.00036006, depth_loss: 7.9264 lr: 1.25000e-05, loss: 2.3605\n",
      "Epoch [99][35/100], loss_cls: 0.0036781, depth_loss: 13.267 lr: 1.25000e-05, loss: 2.4969\n",
      "Epoch [99][40/100], loss_cls: 0.0058544, depth_loss: 14.733 lr: 1.25000e-05, loss: 2.0045\n",
      "Epoch [99][45/100], loss_cls: 0.00035059, depth_loss: 10.516 lr: 1.25000e-05, loss: 2.9344\n",
      "Epoch [99][50/100], loss_cls: 0.0024903, depth_loss: 10.352 lr: 1.25000e-05, loss: 2.0235\n",
      "Epoch [99][55/100], loss_cls: 0.43996, depth_loss: 16.451 lr: 1.25000e-05, loss: 3.5664\n",
      "Epoch [99][60/100], loss_cls: 0.00020721, depth_loss: 11.261 lr: 1.25000e-05, loss: 1.7817\n",
      "Epoch [99][65/100], loss_cls: 0.099435, depth_loss: 10.435 lr: 1.25000e-05, loss: 2.0834\n",
      "Epoch [99][70/100], loss_cls: 0.97394, depth_loss: 9.9044 lr: 1.25000e-05, loss: 1.9283\n",
      "Epoch [99][75/100], loss_cls: 5.9605e-08, depth_loss: 11.509 lr: 1.25000e-05, loss: 3.2099\n",
      "Epoch [99][80/100], loss_cls: 3.0577e-05, depth_loss: 7.3796 lr: 1.25000e-05, loss: 2.4261\n",
      "Epoch [99][85/100], loss_cls: 0.00014375, depth_loss: 10.351 lr: 1.25000e-05, loss: 2.4709\n",
      "Epoch [99][90/100], loss_cls: 9.2983e-06, depth_loss: 15.085 lr: 1.25000e-05, loss: 2.2069\n",
      "Epoch [99][95/100], loss_cls: 2.8536, depth_loss: 14.213 lr: 1.25000e-05, loss: 2.5853\n",
      "Epoch [99][100/100], loss_cls: 0.00034591, depth_loss: 7.7657 lr: 1.25000e-05, loss: 2.1725\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8286, top5_acc: 0.9714, train_loss: 2.1725, val_loss: 2.6488\n",
      "Epoch [100][5/100], loss_cls: 4.6908e-05, depth_loss: 8.2498 lr: 1.25000e-05, loss: 3.6041\n",
      "Epoch [100][10/100], loss_cls: 0.00038834, depth_loss: 6.5634 lr: 1.25000e-05, loss: 1.6932\n",
      "Epoch [100][15/100], loss_cls: 0.0028521, depth_loss: 12.324 lr: 1.25000e-05, loss: 1.8335\n",
      "Epoch [100][20/100], loss_cls: 0.81477, depth_loss: 11.215 lr: 1.25000e-05, loss: 1.6729\n",
      "Epoch [100][25/100], loss_cls: 7.2891e-05, depth_loss: 15.104 lr: 1.25000e-05, loss: 2.6374\n",
      "Epoch [100][30/100], loss_cls: 0.00010102, depth_loss: 7.4482 lr: 1.25000e-05, loss: 2.521\n",
      "Epoch [100][35/100], loss_cls: 0.0028312, depth_loss: 6.5206 lr: 1.25000e-05, loss: 1.7017\n",
      "Epoch [100][40/100], loss_cls: 0.00018087, depth_loss: 6.6945 lr: 1.25000e-05, loss: 2.3179\n",
      "Epoch [100][45/100], loss_cls: 0.069264, depth_loss: 16.98 lr: 1.25000e-05, loss: 3.0592\n",
      "Epoch [100][50/100], loss_cls: 0.0056193, depth_loss: 9.5932 lr: 1.25000e-05, loss: 3.296\n",
      "Epoch [100][55/100], loss_cls: 0.0090018, depth_loss: 9.3463 lr: 1.25000e-05, loss: 2.0292\n",
      "Epoch [100][60/100], loss_cls: 0.018062, depth_loss: 18.762 lr: 1.25000e-05, loss: 2.5158\n",
      "Epoch [100][65/100], loss_cls: 0.96412, depth_loss: 23.255 lr: 1.25000e-05, loss: 3.6231\n",
      "Epoch [100][70/100], loss_cls: 0.0011089, depth_loss: 9.139 lr: 1.25000e-05, loss: 2.2828\n",
      "Epoch [100][75/100], loss_cls: 1.0073e-05, depth_loss: 9.1336 lr: 1.25000e-05, loss: 7.4763\n",
      "Epoch [100][80/100], loss_cls: 0.00039339, depth_loss: 10.492 lr: 1.25000e-05, loss: 2.191\n",
      "Epoch [100][85/100], loss_cls: 0.012637, depth_loss: 21.097 lr: 1.25000e-05, loss: 2.8371\n",
      "Epoch [100][90/100], loss_cls: 0.036054, depth_loss: 12.541 lr: 1.25000e-05, loss: 2.0307\n",
      "Epoch [100][95/100], loss_cls: 0.00026452, depth_loss: 17.078 lr: 1.25000e-05, loss: 2.8035\n",
      "Epoch [100][100/100], loss_cls: 2.8013e-05, depth_loss: 12.048 lr: 1.25000e-05, loss: 2.92\n",
      "Evaluating top_k_accuracy...\n",
      "top1_acc: 0.8, top5_acc: 0.9714, train_loss: 2.92, val_loss: 2.7404\n"
     ]
    }
   ],
   "source": [
    "# Setup wandb\n",
    "# wandb.watch(model, log_freq=10)\n",
    "\n",
    "def top_k_accuracy(scores, labels, topk=(1, )):\n",
    "    \"\"\"Calculate top k accuracy score.\n",
    "    Args:\n",
    "        scores (list[np.ndarray]): Prediction scores for each class.\n",
    "        labels (list[int]): Ground truth labels.\n",
    "        topk (tuple[int]): K value for top_k_accuracy. Default: (1, ).\n",
    "    Returns:\n",
    "        list[float]: Top k accuracy score for each k.\n",
    "    \"\"\"\n",
    "    res = np.zeros(len(topk))\n",
    "    labels = np.array(labels)[:, np.newaxis]\n",
    "    for i, k in enumerate(topk):\n",
    "        max_k_preds = np.argsort(scores, axis=1)[:, -k:][:, ::-1]\n",
    "        match_array = np.logical_or.reduce(max_k_preds == labels, axis=1)\n",
    "        topk_acc_score = match_array.sum() / match_array.shape[0]\n",
    "        res[i] = topk_acc_score\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index, interval=5):\n",
    "    \"\"\"Run one epoch for training.\n",
    "    Args:\n",
    "        epoch_index (int): Current epoch.\n",
    "        interval (int): Frequency at which to print logs.\n",
    "    Returns:\n",
    "        last_loss (float): Loss value for the last batch.\n",
    "    \"\"\"\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, x in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        images, targets = x['imgs'].to(device), x['label'].to(device)\n",
    "        images = images.reshape((-1, ) + images.shape[2:])\n",
    "        targets = targets.reshape(-1, )\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        cls_score, predicted_depth = model(images)\n",
    "        \n",
    "        # Estimate depth using MiDaS\n",
    "        depth = estimate_depth(images)\n",
    "        \n",
    "        # Get losses\n",
    "        loss_cls_score = loss_cls(cls_score, targets)\n",
    "        loss_depth_score = loss_depth(predicted_depth, depth)\n",
    "        loss = 0.8 * loss_cls_score + 0.2 * loss_depth_score\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), max_norm=40, norm_type=2.0)\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % interval == interval-1:\n",
    "            last_loss = running_loss / interval  # loss per batch\n",
    "            print(\n",
    "                f'Epoch [{epoch_index}][{i+1}/{len(train_loader)}], loss_cls: {loss_cls_score.item():.5}, depth_loss: {loss_depth_score.item():.5} lr: {scheduler.get_last_lr()[0]:.5e}, loss: {last_loss:.5}')\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss, scheduler.get_last_lr()[0]\n",
    "\n",
    "\n",
    "def validate():\n",
    "    \"\"\"Run one epoch for validation.\n",
    "    Returns:\n",
    "        avg_vloss (float): Validation loss value for the last batch.\n",
    "        top1_acc (float): Top-1 accuracy in decimal.\n",
    "        top5_acc (float): Top-5 accuracy in decimal.\n",
    "    \"\"\"\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = np.zeros(2)\n",
    "\n",
    "    print('Evaluating top_k_accuracy...')\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, x in enumerate(test_loader):\n",
    "            vimages, vtargets = x['imgs'].to(device), x['label'].to(device)\n",
    "            vimages = vimages.reshape((-1, ) + vimages.shape[2:])\n",
    "            vtargets = vtargets.reshape(-1, )\n",
    "            \n",
    "            # Make predictions for this batch\n",
    "            cls_score, predicted_depth = model(vimages)\n",
    "\n",
    "            # Estimate depth using MiDaS\n",
    "            depth = estimate_depth(vimages)\n",
    "\n",
    "            # Get losses\n",
    "            loss_cls_score = loss_cls(cls_score, vtargets)\n",
    "            loss_depth_score = loss_depth(predicted_depth, depth)\n",
    "            vloss = 0.8 * loss_cls_score + 0.2 * loss_depth_score\n",
    "            \n",
    "            running_vloss += vloss\n",
    "\n",
    "            running_vacc += top_k_accuracy(cls_score.detach().cpu().numpy(),\n",
    "                                           vtargets.detach().cpu().numpy(), topk=(1, 5))\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "\n",
    "    acc = running_vacc/len(test_loader)\n",
    "    top1_acc = acc[0].item()\n",
    "    top5_acc = acc[1].item()\n",
    "\n",
    "    return (avg_vloss, top1_acc, top5_acc)\n",
    "\n",
    "\n",
    "# Train Loop\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Turn on gradient tracking and do a forward pass\n",
    "    model.train(True)\n",
    "    avg_loss, learning_rate = train_one_epoch(epoch+1)\n",
    "\n",
    "    # Turn off  gradients for reporting\n",
    "    model.train(False)\n",
    "\n",
    "    avg_vloss, top1_acc, top5_acc = validate()\n",
    "\n",
    "    print(\n",
    "        f'top1_acc: {top1_acc:.4}, top5_acc: {top5_acc:.4}, train_loss: {avg_loss:.5}, val_loss: {avg_vloss:.5}')\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = work_dir + f'epoch_{epoch+1}.pth'\n",
    "        print(f'Saving checkpoint at {epoch+1} epochs...')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "     # Adjust learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Track wandb\n",
    "    wandb.log({'train/loss': avg_loss,\n",
    "               'train/learning_rate': learning_rate,\n",
    "               'val/loss': avg_vloss,\n",
    "               'val/top1_accuracy': top1_acc,\n",
    "               'val/top5_accuracy': top5_acc})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataloader",
   "language": "python",
   "name": "dataloader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
