{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2eb630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myuser1/miniconda3/envs/MDE/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from depth.models import build_depther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c28dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
    "model = dict(\n",
    "    type='DepthEncoderDecoder',\n",
    "    backbone=dict(\n",
    "        type='SwinTransformer',\n",
    "        pretrain_img_size=224,\n",
    "        embed_dims=96,\n",
    "        patch_size=4,\n",
    "        window_size=7,\n",
    "        mlp_ratio=4,\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[3, 6, 12, 24],\n",
    "        strides=(4, 2, 2, 2),\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        patch_norm=True,\n",
    "        drop_rate=0.0,\n",
    "        attn_drop_rate=0.0,\n",
    "        drop_path_rate=0.3,\n",
    "        use_abs_pos_embed=False,\n",
    "        act_cfg=dict(type='GELU'),\n",
    "        norm_cfg=dict(type='LN', requires_grad=True),\n",
    "        pretrain_style='official'),\n",
    "    decode_head=dict(\n",
    "        type='BinsFormerDecodeHead',\n",
    "        class_num=25,\n",
    "        in_channels=[96, 192, 384, 768],\n",
    "        channels=256,\n",
    "        n_bins=64,\n",
    "        index=[0, 1, 2, 3],\n",
    "        trans_index=[1, 2, 3],\n",
    "        loss_decode=dict(type='SigLoss', valid_mask=True, loss_weight=10),\n",
    "        with_loss_chamfer=False,\n",
    "        loss_chamfer=dict(type='BinsChamferLoss', loss_weight=0.1),\n",
    "        classify=True,\n",
    "        loss_class=dict(type='CrossEntropyLoss', loss_weight=0.01),\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        transformer_encoder=dict(\n",
    "            type='PureMSDEnTransformer',\n",
    "            num_feature_levels=3,\n",
    "            encoder=dict(\n",
    "                type='DetrTransformerEncoder',\n",
    "                num_layers=6,\n",
    "                transformerlayers=dict(\n",
    "                    type='BaseTransformerLayer',\n",
    "                    attn_cfgs=dict(\n",
    "                        type='MultiScaleDeformableAttention',\n",
    "                        embed_dims=256,\n",
    "                        num_levels=3,\n",
    "                        num_points=8),\n",
    "                    feedforward_channels=1024,\n",
    "                    ffn_dropout=0.1,\n",
    "                    operation_order=('self_attn', 'norm', 'ffn', 'norm')))),\n",
    "        positional_encoding=dict(\n",
    "            type='SinePositionalEncoding', num_feats=128, normalize=True),\n",
    "        transformer_decoder=dict(\n",
    "            type='PixelTransformerDecoder',\n",
    "            return_intermediate=True,\n",
    "            num_layers=9,\n",
    "            num_feature_levels=3,\n",
    "            hidden_dim=256,\n",
    "            transformerlayers=dict(\n",
    "                type='PixelTransformerDecoderLayer',\n",
    "                attn_cfgs=dict(\n",
    "                    type='MultiheadAttention',\n",
    "                    embed_dims=256,\n",
    "                    num_heads=8,\n",
    "                    dropout=0.0),\n",
    "                ffn_cfgs=dict(feedforward_channels=2048, ffn_drop=0.0),\n",
    "                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n",
    "                                 'ffn', 'norm')),\n",
    "            operation='//'),\n",
    "        conv_dim=256,\n",
    "        min_depth=0.001,\n",
    "        max_depth=10),\n",
    "    train_cfg=dict(aux_loss=True, aux_index=[2, 5], aux_weight=[0.25, 0.5]),\n",
    "    test_cfg=dict(mode='whole'),\n",
    "    pretrained=\n",
    "    'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae9a679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'DepthEncoderDecoder',\n",
       " 'backbone': {'type': 'SwinTransformer',\n",
       "  'pretrain_img_size': 224,\n",
       "  'embed_dims': 96,\n",
       "  'patch_size': 4,\n",
       "  'window_size': 7,\n",
       "  'mlp_ratio': 4,\n",
       "  'depths': [2, 2, 6, 2],\n",
       "  'num_heads': [3, 6, 12, 24],\n",
       "  'strides': (4, 2, 2, 2),\n",
       "  'out_indices': (0, 1, 2, 3),\n",
       "  'qkv_bias': True,\n",
       "  'qk_scale': None,\n",
       "  'patch_norm': True,\n",
       "  'drop_rate': 0.0,\n",
       "  'attn_drop_rate': 0.0,\n",
       "  'drop_path_rate': 0.3,\n",
       "  'use_abs_pos_embed': False,\n",
       "  'act_cfg': {'type': 'GELU'},\n",
       "  'norm_cfg': {'type': 'LN', 'requires_grad': True},\n",
       "  'pretrain_style': 'official'},\n",
       " 'decode_head': {'type': 'BinsFormerDecodeHead',\n",
       "  'class_num': 25,\n",
       "  'in_channels': [96, 192, 384, 768],\n",
       "  'channels': 256,\n",
       "  'n_bins': 64,\n",
       "  'index': [0, 1, 2, 3],\n",
       "  'trans_index': [1, 2, 3],\n",
       "  'loss_decode': {'type': 'SigLoss', 'valid_mask': True, 'loss_weight': 10},\n",
       "  'with_loss_chamfer': False,\n",
       "  'loss_chamfer': {'type': 'BinsChamferLoss', 'loss_weight': 0.1},\n",
       "  'classify': True,\n",
       "  'loss_class': {'type': 'CrossEntropyLoss', 'loss_weight': 0.01},\n",
       "  'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       "  'transformer_encoder': {'type': 'PureMSDEnTransformer',\n",
       "   'num_feature_levels': 3,\n",
       "   'encoder': {'type': 'DetrTransformerEncoder',\n",
       "    'num_layers': 6,\n",
       "    'transformerlayers': {'type': 'BaseTransformerLayer',\n",
       "     'attn_cfgs': {'type': 'MultiScaleDeformableAttention',\n",
       "      'embed_dims': 256,\n",
       "      'num_levels': 3,\n",
       "      'num_points': 8},\n",
       "     'feedforward_channels': 1024,\n",
       "     'ffn_dropout': 0.1,\n",
       "     'operation_order': ('self_attn', 'norm', 'ffn', 'norm')}}},\n",
       "  'positional_encoding': {'type': 'SinePositionalEncoding',\n",
       "   'num_feats': 128,\n",
       "   'normalize': True},\n",
       "  'transformer_decoder': {'type': 'PixelTransformerDecoder',\n",
       "   'return_intermediate': True,\n",
       "   'num_layers': 9,\n",
       "   'num_feature_levels': 3,\n",
       "   'hidden_dim': 256,\n",
       "   'transformerlayers': {'type': 'PixelTransformerDecoderLayer',\n",
       "    'attn_cfgs': {'type': 'MultiheadAttention',\n",
       "     'embed_dims': 256,\n",
       "     'num_heads': 8,\n",
       "     'dropout': 0.0},\n",
       "    'ffn_cfgs': {'feedforward_channels': 2048, 'ffn_drop': 0.0},\n",
       "    'operation_order': ('cross_attn',\n",
       "     'norm',\n",
       "     'self_attn',\n",
       "     'norm',\n",
       "     'ffn',\n",
       "     'norm')},\n",
       "   'operation': '//'},\n",
       "  'conv_dim': 256,\n",
       "  'min_depth': 0.001,\n",
       "  'max_depth': 10},\n",
       " 'train_cfg': {'aux_loss': True,\n",
       "  'aux_index': [2, 5],\n",
       "  'aux_weight': [0.25, 0.5]},\n",
       " 'test_cfg': {'mode': 'whole'},\n",
       " 'pretrained': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ec3a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_depther' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m depthformer \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_depther\u001b[49m(model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_depther' is not defined"
     ]
    }
   ],
   "source": [
    "depthformer = build_depther(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153a0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'a': 1}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wlasl)",
   "language": "python",
   "name": "wlasl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
